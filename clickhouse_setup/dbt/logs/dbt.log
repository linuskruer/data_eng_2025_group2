[0m12:54:22.423531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA801E67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA80F54050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA81587D90>]}


============================== 12:54:22.432888 | 3c6faee1-628b-425b-b3c9-8e5cfc8b5c59 ==============================
[0m12:54:22.432888 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:54:22.433927 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt debug', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'target_path': 'None', 'log_format': 'default', 'cache_selected_only': 'False', 'warn_error': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'write_json': 'True'}
[0m12:54:22.465278 [info ] [MainThread]: dbt version: 1.10.13
[0m12:54:22.466410 [info ] [MainThread]: python version: 3.13.7
[0m12:54:22.467183 [info ] [MainThread]: python path: C:\Users\ayeshaateeq\AppData\Local\Programs\Python\Python313\python.exe
[0m12:54:22.467865 [info ] [MainThread]: os info: Windows-11-10.0.26200-SP0
[0m12:54:22.551252 [info ] [MainThread]: Using profiles dir at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt
[0m12:54:22.551864 [info ] [MainThread]: Using profiles.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\profiles.yml
[0m12:54:22.552368 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\dbt_project.yml
[0m12:54:22.681740 [info ] [MainThread]: Configuration:
[0m12:54:22.682392 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:54:22.682762 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:54:22.683105 [info ] [MainThread]: Required dependencies:
[0m12:54:22.683395 [debug] [MainThread]: Executing "git --help"
[0m12:54:22.719938 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:54:22.720724 [debug] [MainThread]: STDERR: "b''"
[0m12:54:22.721151 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:54:22.721716 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:54:22.722236 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:54:22.722719 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "clickhouse_profile", target "dev" invalid: True is not of type 'string'


[0m12:54:22.723749 [debug] [MainThread]: Command `dbt debug` failed at 12:54:22.723584 after 0.48 seconds
[0m12:54:22.724206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA80865CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA828E0950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DA81414380>]}
[0m12:54:22.724654 [debug] [MainThread]: Flushing usage events
[0m12:54:23.884408 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:54:36.934269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028429DC27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002842AB24050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002842B13FC50>]}


============================== 12:54:36.939395 | 12854739-0f46-4ccb-b9e4-40fbfdbb5f19 ==============================
[0m12:54:36.939395 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:54:36.940108 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'no_print': 'None', 'printer_width': '80', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'invocation_command': 'dbt debug', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m12:54:36.958807 [info ] [MainThread]: dbt version: 1.10.13
[0m12:54:36.959365 [info ] [MainThread]: python version: 3.13.7
[0m12:54:36.959732 [info ] [MainThread]: python path: C:\Users\ayeshaateeq\AppData\Local\Programs\Python\Python313\python.exe
[0m12:54:36.960043 [info ] [MainThread]: os info: Windows-11-10.0.26200-SP0
[0m12:54:37.062781 [info ] [MainThread]: Using profiles dir at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt
[0m12:54:37.063861 [info ] [MainThread]: Using profiles.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\profiles.yml
[0m12:54:37.064491 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\dbt_project.yml
[0m12:54:37.256860 [info ] [MainThread]: Configuration:
[0m12:54:37.257653 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:54:37.258147 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:54:37.258745 [info ] [MainThread]: Required dependencies:
[0m12:54:37.259321 [debug] [MainThread]: Executing "git --help"
[0m12:54:37.312438 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:54:37.313081 [debug] [MainThread]: STDERR: "b''"
[0m12:54:37.313694 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:54:37.314749 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:54:37.315194 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:54:37.315684 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "clickhouse_profile", target "dev" invalid: True is not of type 'string'


[0m12:54:37.316510 [debug] [MainThread]: Command `dbt debug` failed at 12:54:37.316411 after 0.58 seconds
[0m12:54:37.316813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002842A439CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002842C45C5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002842AFE4380>]}
[0m12:54:37.317150 [debug] [MainThread]: Flushing usage events
[0m12:54:38.104026 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:54:53.084077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5561967B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F556EF4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F55750FC50>]}


============================== 12:54:53.089890 | 35d96269-7c41-4db4-a5a6-e89a2ab5947c ==============================
[0m12:54:53.089890 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:54:53.090826 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'target_path': 'None', 'no_print': 'None', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt debug', 'printer_width': '80', 'write_json': 'True'}
[0m12:54:53.113802 [info ] [MainThread]: dbt version: 1.10.13
[0m12:54:53.114285 [info ] [MainThread]: python version: 3.13.7
[0m12:54:53.114880 [info ] [MainThread]: python path: C:\Users\ayeshaateeq\AppData\Local\Programs\Python\Python313\python.exe
[0m12:54:53.115487 [info ] [MainThread]: os info: Windows-11-10.0.26200-SP0
[0m12:54:53.209328 [info ] [MainThread]: Using profiles dir at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt
[0m12:54:53.210140 [info ] [MainThread]: Using profiles.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\profiles.yml
[0m12:54:53.210879 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\dbt_project.yml
[0m12:54:53.350973 [info ] [MainThread]: Configuration:
[0m12:54:53.351631 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:54:53.352002 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:54:53.352420 [info ] [MainThread]: Required dependencies:
[0m12:54:53.352969 [debug] [MainThread]: Executing "git --help"
[0m12:54:53.422774 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:54:53.423330 [debug] [MainThread]: STDERR: "b''"
[0m12:54:53.423639 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:54:53.424108 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:54:53.424416 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:54:53.424679 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "clickhouse_profile", target "dev" invalid: 'false' is not of type 'boolean'


[0m12:54:53.425328 [debug] [MainThread]: Command `dbt debug` failed at 12:54:53.425240 after 0.51 seconds
[0m12:54:53.425839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F556805CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F55884C5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5573B4380>]}
[0m12:54:53.426384 [debug] [MainThread]: Flushing usage events
[0m12:54:54.177338 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:55:18.330533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D94F527B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D95CB4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D962CFC50>]}


============================== 12:55:18.338543 | 1a8776b6-74bb-4904-9a2d-9c3756379a76 ==============================
[0m12:55:18.338543 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:55:18.339521 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'write_json': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'invocation_command': 'dbt debug', 'cache_selected_only': 'False', 'warn_error': 'None', 'static_parser': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m12:55:18.372743 [info ] [MainThread]: dbt version: 1.10.13
[0m12:55:18.373524 [info ] [MainThread]: python version: 3.13.7
[0m12:55:18.374081 [info ] [MainThread]: python path: C:\Users\ayeshaateeq\AppData\Local\Programs\Python\Python313\python.exe
[0m12:55:18.374659 [info ] [MainThread]: os info: Windows-11-10.0.26200-SP0
[0m12:55:18.479479 [info ] [MainThread]: Using profiles dir at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt
[0m12:55:18.480315 [info ] [MainThread]: Using profiles.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\profiles.yml
[0m12:55:18.481317 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\dbt_project.yml
[0m12:55:18.482817 [info ] [MainThread]: adapter type: clickhouse
[0m12:55:18.483281 [info ] [MainThread]: adapter version: 1.9.5
[0m12:55:18.628606 [info ] [MainThread]: Configuration:
[0m12:55:18.629389 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:55:18.630186 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:55:18.630784 [info ] [MainThread]: Required dependencies:
[0m12:55:18.631505 [debug] [MainThread]: Executing "git --help"
[0m12:55:18.676382 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:55:18.677051 [debug] [MainThread]: STDERR: "b''"
[0m12:55:18.677637 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:55:18.678563 [info ] [MainThread]: Connection:
[0m12:55:18.679215 [info ] [MainThread]:   driver: None
[0m12:55:18.679745 [info ] [MainThread]:   host: localhost
[0m12:55:18.680743 [info ] [MainThread]:   port: 9000
[0m12:55:18.681414 [info ] [MainThread]:   user: default
[0m12:55:18.681879 [info ] [MainThread]:   schema: default
[0m12:55:18.682299 [info ] [MainThread]:   retries: 1
[0m12:55:18.682602 [info ] [MainThread]:   cluster: None
[0m12:55:18.682989 [info ] [MainThread]:   database_engine: None
[0m12:55:18.683419 [info ] [MainThread]:   cluster_mode: False
[0m12:55:18.683819 [info ] [MainThread]:   secure: False
[0m12:55:18.684187 [info ] [MainThread]:   verify: True
[0m12:55:18.684745 [info ] [MainThread]:   client_cert: None
[0m12:55:18.685281 [info ] [MainThread]:   client_cert_key: None
[0m12:55:18.685975 [info ] [MainThread]:   connect_timeout: 10
[0m12:55:18.686414 [info ] [MainThread]:   send_receive_timeout: 300
[0m12:55:18.686765 [info ] [MainThread]:   sync_request_timeout: 5
[0m12:55:18.687114 [info ] [MainThread]:   compress_block_size: 1048576
[0m12:55:18.687796 [info ] [MainThread]:   compression: 
[0m12:55:18.688341 [info ] [MainThread]:   check_exchange: True
[0m12:55:18.688829 [info ] [MainThread]:   custom_settings: None
[0m12:55:18.689246 [info ] [MainThread]:   use_lw_deletes: False
[0m12:55:18.689639 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m12:55:18.690082 [info ] [MainThread]:   tcp_keepalive: False
[0m12:55:18.690835 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:55:18.980001 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m12:55:18.980900 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:55:19.957137 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m12:55:20.006223 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:55:20.131158 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:55:20.131716 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:55:20.132379 [debug] [MainThread]: Command `dbt debug` succeeded at 12:55:20.132281 after 1.99 seconds
[0m12:55:20.132651 [debug] [MainThread]: Connection 'debug' was left open.
[0m12:55:20.132865 [debug] [MainThread]: On debug: Close
[0m12:55:20.133293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D975B3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D986971D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D97545BF0>]}
[0m12:55:20.133595 [debug] [MainThread]: Flushing usage events
[0m12:55:20.880954 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:55:36.170633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF86A427B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF877A4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87DC3C50>]}


============================== 12:55:36.176932 | b473bf47-cfdc-449d-a8eb-97e92279033e ==============================
[0m12:55:36.176932 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:55:36.177924 [debug] [MainThread]: running dbt with arguments {'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'log_format': 'default', 'cache_selected_only': 'False', 'write_json': 'True', 'invocation_command': 'dbt run --models silver', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m12:55:36.178358 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
Usage of `--models`, `--model`, and `-m` is deprecated in favor of `--select` or
`-s`.
[0m12:55:36.179068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b473bf47-cfdc-449d-a8eb-97e92279033e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87E68180>]}
[0m12:55:36.581979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b473bf47-cfdc-449d-a8eb-97e92279033e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87C66AD0>]}
[0m12:55:36.698318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b473bf47-cfdc-449d-a8eb-97e92279033e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87C75950>]}
[0m12:55:36.701940 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:55:36.936767 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:55:36.938250 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:55:36.941828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b473bf47-cfdc-449d-a8eb-97e92279033e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87E8E5D0>]}
[0m12:55:42.032128 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.ebay_weather_analytics.silver_ebay_data' (models\silver\silver_ebay_data.sql) depends on a source named 'bronze.ebay_raw_data' which was not found
[0m12:55:42.032991 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- ModelParamUsageDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m12:55:42.033754 [debug] [MainThread]: Command `dbt run` failed at 12:55:42.033659 after 6.07 seconds
[0m12:55:42.034015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87CDFE70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF897AE270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF87EB0FC0>]}
[0m12:55:42.034254 [debug] [MainThread]: Flushing usage events
[0m12:55:42.864665 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:56:10.265215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F21ED27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F22C24050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F2323FC50>]}


============================== 12:56:10.270951 | 07a5f7cc-5e46-4f66-8721-31357a4f2c2e ==============================
[0m12:56:10.270951 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:56:10.271889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_format': 'default', 'use_colors': 'True', 'no_print': 'None', 'write_json': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'partial_parse': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'invocation_command': 'dbt run --select silver', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m12:56:10.555814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F225CC8A0>]}
[0m12:56:10.631118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F2097F680>]}
[0m12:56:10.632583 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:56:10.799058 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:56:10.799870 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:56:10.800690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F2476C050>]}
[0m12:56:12.657821 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- seeds.ebay_weather_analytics
- snapshots.ebay_weather_analytics
[0m12:56:12.668026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24B409B0>]}
[0m12:56:12.767871 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:12.788507 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:12.828502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24AF4AD0>]}
[0m12:56:12.828945 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:56:12.829353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24D8EC30>]}
[0m12:56:12.830968 [info ] [MainThread]: 
[0m12:56:12.832167 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:56:12.832805 [info ] [MainThread]: 
[0m12:56:12.833460 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:56:12.838405 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:56:12.848630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:13.535998 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:56:13.581615 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:13.630937 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m12:56:13.635979 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:14.127802 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:56:14.206498 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:56:14.208392 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default, now list__default_dbt_test__audit)
[0m12:56:14.210826 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:56:14.274061 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:14.276592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24CF2810>]}
[0m12:56:14.318899 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:14.319539 [info ] [Thread-1 (]: 1 of 2 START sql table model `default`.`silver_ebay_data` ...................... [RUN]
[0m12:56:14.320360 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.silver_ebay_data'
[0m12:56:14.320662 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:14.329167 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.silver_ebay_data"
[0m12:56:14.332201 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:14.356607 [debug] [Thread-1 (]: Creating new relation silver_ebay_data
[0m12:56:14.397863 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:56:14.896295 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

            

    
        create table `default`.`silver_ebay_data`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Silver Layer Models for dbt
-- These models clean and standardize the bronze data

-- Silver: Clean eBay Data


SELECT 
    collection_timestamp,
    timezone,
    weather_category,
    product_type,
    price,
    currency,
    seller_feedback_percentage,
    seller_feedback_score,
    -- Parse JSON location data
    JSONExtractString(item_location, 'postalCode') as postal_code,
    JSONExtractString(item_location, 'country') as country,
    seller_location,
    shipping_cost,
    free_shipping,
    condition,
    buying_options,
    title_length,
    item_id,
    marketplace_id,
    execution_date,
    data_source,
    created_at,
    updated_at,
    -- Add data quality flags
    CASE 
        WHEN price <= 0 THEN 1 
        ELSE 0 
    END as price_quality_flag,
    CASE 
        WHEN seller_feedback_percentage < 0 OR seller_feedback_percentage > 100 THEN 1 
        ELSE 0 
    END as feedback_quality_flag
FROM `bronze`.`ebay_raw_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
          )
        
        ...
[0m12:56:14.967453 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:56:14.980488 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

    select name, type from system.columns where table = 'silver_ebay_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:15.030666 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:15.034561 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.silver_ebay_data"
[0m12:56:15.038181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

  
    
    
    
        
         


        insert into `default`.`silver_ebay_data`
        ("collection_timestamp", "timezone", "weather_category", "product_type", "price", "currency", "seller_feedback_percentage", "seller_feedback_score", "postal_code", "country", "seller_location", "shipping_cost", "free_shipping", "condition", "buying_options", "title_length", "item_id", "marketplace_id", "execution_date", "data_source", "created_at", "updated_at", "price_quality_flag", "feedback_quality_flag")-- Silver Layer Models for dbt
-- These models clean and standardize the bronze data

-- Silver: Clean eBay Data


SELECT 
    collection_timestamp,
    timezone,
    weather_category,
    product_type,
    price,
    currency,
    seller_feedback_percentage,
    seller_feedback_score,
    -- Parse JSON location data
    JSONExtractString(item_location, 'postalCode') as postal_code,
    JSONExtractString(item_location, 'country') as country,
    seller_location,
    shipping_cost,
    free_shipping,
    condition,
    buying_options,
    title_length,
    item_id,
    marketplace_id,
    execution_date,
    data_source,
    created_at,
    updated_at,
    -- Add data quality flags
    CASE 
        WHEN price <= 0 THEN 1 
        ELSE 0 
    END as price_quality_flag,
    CASE 
        WHEN seller_feedback_percentage < 0 OR seller_feedback_percentage > 100 THEN 1 
        ELSE 0 
    END as feedback_quality_flag
FROM `bronze`.`ebay_raw_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  ...
[0m12:56:15.101407 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:15.143592 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24E6AC50>]}
[0m12:56:15.145294 [info ] [Thread-1 (]: 1 of 2 OK created sql table model `default`.`silver_ebay_data` ................. [[32mOK[0m in 0.82s]
[0m12:56:15.146554 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:15.147071 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.silver_weather_data
[0m12:56:15.147880 [info ] [Thread-1 (]: 2 of 2 START sql table model `default`.`silver_weather_data` ................... [RUN]
[0m12:56:15.148915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.silver_ebay_data, now model.ebay_weather_analytics.silver_weather_data)
[0m12:56:15.149636 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.silver_weather_data
[0m12:56:15.154777 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.silver_weather_data"
[0m12:56:15.157724 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.silver_weather_data
[0m12:56:15.170431 [debug] [Thread-1 (]: Creating new relation silver_weather_data
[0m12:56:15.172801 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_weather_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_weather_data"} */

            

    
        create table `default`.`silver_weather_data`
        
  
        
  engine = MergeTree()
        order by ((time, latitude, longitude))
        
        partition by (toYYYYMM(time))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Silver: Clean Weather Data


SELECT 
    latitude,
    longitude,
    elevation,
    utc_offset_seconds,
    timezone,
    timezone_abbreviation,
    time,
    weather_code,
    temperature_2m,
    relative_humidity_2m,
    cloudcover,
    rain,
    sunshine_duration,
    windspeed_10m,
    data_source,
    created_at,
    updated_at,
    -- Add weather buckets
    CASE 
        WHEN temperature_2m >= 32 THEN 'Extreme Heat'
        WHEN temperature_2m <= -5 THEN 'Extreme Cold'
        WHEN rain > 10 THEN 'Heavy Rain'
        WHEN rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END as weather_bucket,
    -- Add data quality flags
    CASE 
        WHEN temperature_2m < -50 OR temperature_2m > 60 THEN 1 
        ELSE 0 
    END as temperature_quality_flag,
    CASE 
        WHEN rain < 0 THEN 1 
        ELSE 0 
    END as rain_quality_flag
FROM `bronze`.`weather_raw_data`
WHERE time IS NOT NULL
  AND latitude IS NOT NULL
  AND longitude IS NOT NULL
          )
        
        ...
[0m12:56:15.237279 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_weather_data"} */

            

    
        create table `default`.`silver_weather_data`
        
  
        
  engine = MergeTree()
        order by ((time, latitude, longitude))
        
        partition by (toYYYYMM(time))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Silver: Clean Weather Data


SELECT 
    latitude,
    longitude,
    elevation,
    utc_offset_seconds,
    timezone,
    timezone_abbreviation,
    time,
    weather_code,
    temperature_2m,
    relative_humidity_2m,
    cloudcover,
    rain,
    sunshine_duration,
    windspeed_10m,
    data_source,
    created_at,
    updated_at,
    -- Add weather buckets
    CASE 
        WHEN temperature_2m >= 32 THEN 'Extreme Heat'
        WHEN temperature_2m <= -5 THEN 'Extreme Cold'
        WHEN rain > 10 THEN 'Heavy Rain'
        WHEN rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END as weather_bucket,
    -- Add data quality flags
    CASE 
        WHEN temperature_2m < -50 OR temperature_2m > 60 THEN 1 
        ELSE 0 
    END as temperature_quality_flag,
    CASE 
        WHEN rain < 0 THEN 1 
        ELSE 0 
    END as rain_quality_flag
FROM `bronze`.`weather_raw_data`
WHERE time IS NOT NULL
  AND latitude IS NOT NULL
  AND longitude IS NOT NULL
          )
        
        
[0m12:56:15.323604 [debug] [Thread-1 (]: Database Error in model silver_weather_data (models\silver\silver_weather_data.sql)
  Code: 47.
  DB::Exception: Unknown expression identifier `latitude` in scope SELECT latitude, longitude, elevation, utc_offset_seconds, timezone, timezone_abbreviation, time, weather_code, temperature_2m, relative_humidity_2m, cloudcover, rain, sunshine_duration, windspeed_10m, data_source, created_at, updated_at, multiIf(temperature_2m >= 32, 'Extreme Heat', temperature_2m <= -5, 'Extreme Cold', rain > 10, 'Heavy Rain', rain > 0, 'Light Rain', 'Normal') AS weather_bucket, multiIf((temperature_2m < -50) OR (temperature_2m > 60), 1, 0) AS temperature_quality_flag, multiIf(rain < 0, 1, 0) AS rain_quality_flag FROM bronze.weather_raw_data WHERE (time IS NOT NULL) AND (latitude IS NOT NULL) AND (longitude IS NOT NULL). Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  8. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  9. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  10. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  11. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  12. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  13. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  14. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  15. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  16. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  17. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  18. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  19. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  20. DB::TCPHandler::run() @ 0x0000000019e4f119
  21. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  22. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  23. Poco::PooledThread::run() @ 0x000000001ef15b87
  24. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  25. ? @ 0x0000000000094ac3
  26. ? @ 0x0000000000125a74
[0m12:56:15.325163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07a5f7cc-5e46-4f66-8721-31357a4f2c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F26D40A50>]}
[0m12:56:15.326759 [error] [Thread-1 (]: 2 of 2 ERROR creating sql table model `default`.`silver_weather_data` .......... [[31mERROR[0m in 0.18s]
[0m12:56:15.328230 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.silver_weather_data
[0m12:56:15.329854 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.silver_weather_data' to be skipped because of status 'error'.  Reason: Database Error in model silver_weather_data (models\silver\silver_weather_data.sql)
  Code: 47.
  DB::Exception: Unknown expression identifier `latitude` in scope SELECT latitude, longitude, elevation, utc_offset_seconds, timezone, timezone_abbreviation, time, weather_code, temperature_2m, relative_humidity_2m, cloudcover, rain, sunshine_duration, windspeed_10m, data_source, created_at, updated_at, multiIf(temperature_2m >= 32, 'Extreme Heat', temperature_2m <= -5, 'Extreme Cold', rain > 10, 'Heavy Rain', rain > 0, 'Light Rain', 'Normal') AS weather_bucket, multiIf((temperature_2m < -50) OR (temperature_2m > 60), 1, 0) AS temperature_quality_flag, multiIf(rain < 0, 1, 0) AS rain_quality_flag FROM bronze.weather_raw_data WHERE (time IS NOT NULL) AND (latitude IS NOT NULL) AND (longitude IS NOT NULL). Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  8. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  9. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  10. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  11. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  12. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  13. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  14. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  15. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  16. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  17. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  18. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  19. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  20. DB::TCPHandler::run() @ 0x0000000019e4f119
  21. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  22. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  23. Poco::PooledThread::run() @ 0x000000001ef15b87
  24. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  25. ? @ 0x0000000000094ac3
  26. ? @ 0x0000000000125a74.
[0m12:56:15.335021 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:56:15.337285 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:56:15.338001 [debug] [MainThread]: On list_: Close
[0m12:56:15.339229 [debug] [MainThread]: Connection 'list__default_dbt_test__audit' was left open.
[0m12:56:15.340269 [debug] [MainThread]: On list__default_dbt_test__audit: Close
[0m12:56:15.343108 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.silver_weather_data' was left open.
[0m12:56:15.344457 [debug] [MainThread]: On model.ebay_weather_analytics.silver_weather_data: Close
[0m12:56:15.345382 [info ] [MainThread]: 
[0m12:56:15.346208 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 2.51 seconds (2.51s).
[0m12:56:15.348717 [debug] [MainThread]: Command end result
[0m12:56:15.403260 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:15.407205 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:15.414847 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:56:15.415657 [info ] [MainThread]: 
[0m12:56:15.416989 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:56:15.417727 [info ] [MainThread]: 
[0m12:56:15.418690 [error] [MainThread]: [31mFailure in model silver_weather_data (models\silver\silver_weather_data.sql)[0m
[0m12:56:15.419755 [error] [MainThread]:   Database Error in model silver_weather_data (models\silver\silver_weather_data.sql)
  Code: 47.
  DB::Exception: Unknown expression identifier `latitude` in scope SELECT latitude, longitude, elevation, utc_offset_seconds, timezone, timezone_abbreviation, time, weather_code, temperature_2m, relative_humidity_2m, cloudcover, rain, sunshine_duration, windspeed_10m, data_source, created_at, updated_at, multiIf(temperature_2m >= 32, 'Extreme Heat', temperature_2m <= -5, 'Extreme Cold', rain > 10, 'Heavy Rain', rain > 0, 'Light Rain', 'Normal') AS weather_bucket, multiIf((temperature_2m < -50) OR (temperature_2m > 60), 1, 0) AS temperature_quality_flag, multiIf(rain < 0, 1, 0) AS rain_quality_flag FROM bronze.weather_raw_data WHERE (time IS NOT NULL) AND (latitude IS NOT NULL) AND (longitude IS NOT NULL). Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  8. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  9. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  10. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  11. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  12. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  13. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  14. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  15. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  16. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  17. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  18. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  19. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  20. DB::TCPHandler::run() @ 0x0000000019e4f119
  21. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  22. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  23. Poco::PooledThread::run() @ 0x000000001ef15b87
  24. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  25. ? @ 0x0000000000094ac3
  26. ? @ 0x0000000000125a74
[0m12:56:15.421371 [info ] [MainThread]: 
[0m12:56:15.422823 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\silver\silver_weather_data.sql
[0m12:56:15.423847 [info ] [MainThread]: 
[0m12:56:15.424555 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m12:56:15.426020 [debug] [MainThread]: Command `dbt run` failed at 12:56:15.425697 after 5.33 seconds
[0m12:56:15.426784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24DDD0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F24E925D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F242C8590>]}
[0m12:56:15.427425 [debug] [MainThread]: Flushing usage events
[0m12:56:16.207160 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:56:34.735268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA38A27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA45F4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA4C13C50>]}


============================== 12:56:34.741002 | 4a960716-a439-47f2-8802-b464d454c7b7 ==============================
[0m12:56:34.741002 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:56:34.741860 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'no_print': 'None', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select silver', 'printer_width': '80', 'target_path': 'None'}
[0m12:56:35.015010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA3F9C8A0>]}
[0m12:56:35.130648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA234F680>]}
[0m12:56:35.133678 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:56:35.462159 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:56:35.676267 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:56:35.677212 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\silver\silver_weather_data.sql
[0m12:56:36.015700 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- seeds.ebay_weather_analytics
- snapshots.ebay_weather_analytics
[0m12:56:36.043296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA6103A50>]}
[0m12:56:36.286515 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:36.289862 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:36.331827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA3964C80>]}
[0m12:56:36.332391 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:56:36.333028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA5F44E50>]}
[0m12:56:36.335443 [info ] [MainThread]: 
[0m12:56:36.336036 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:56:36.336511 [info ] [MainThread]: 
[0m12:56:36.337162 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:56:36.344860 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:56:36.353914 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:37.046664 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:56:37.092852 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:37.144255 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m12:56:37.149039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:37.698077 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:56:37.763275 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:37.764428 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m12:56:37.765727 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:56:37.816101 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:37.818485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA80C2680>]}
[0m12:56:37.826087 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:37.826844 [info ] [Thread-1 (]: 1 of 2 START sql table model `default`.`silver_ebay_data` ...................... [RUN]
[0m12:56:37.828064 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.silver_ebay_data'
[0m12:56:37.828687 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:37.834027 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.silver_ebay_data"
[0m12:56:37.834959 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:37.901588 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:56:38.427679 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

            

    
        create table `default`.`silver_ebay_data__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Silver Layer Models for dbt
-- These models clean and standardize the bronze data

-- Silver: Clean eBay Data


SELECT 
    collection_timestamp,
    timezone,
    weather_category,
    product_type,
    price,
    currency,
    seller_feedback_percentage,
    seller_feedback_score,
    -- Parse JSON location data
    JSONExtractString(item_location, 'postalCode') as postal_code,
    JSONExtractString(item_location, 'country') as country,
    seller_location,
    shipping_cost,
    free_shipping,
    condition,
    buying_options,
    title_length,
    item_id,
    marketplace_id,
    execution_date,
    data_source,
    created_at,
    updated_at,
    -- Add data quality flags
    CASE 
        WHEN price <= 0 THEN 1 
        ELSE 0 
    END as price_quality_flag,
    CASE 
        WHEN seller_feedback_percentage < 0 OR seller_feedback_percentage > 100 THEN 1 
        ELSE 0 
    END as feedback_quality_flag
FROM `bronze`.`ebay_raw_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
          )
        
        ...
[0m12:56:38.492375 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:38.523955 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

    select name, type from system.columns where table = 'silver_ebay_data__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:38.575736 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:38.584892 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.silver_ebay_data"
[0m12:56:38.586512 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */

  
    
    
    
        
         


        insert into `default`.`silver_ebay_data__dbt_backup`
        ("collection_timestamp", "timezone", "weather_category", "product_type", "price", "currency", "seller_feedback_percentage", "seller_feedback_score", "postal_code", "country", "seller_location", "shipping_cost", "free_shipping", "condition", "buying_options", "title_length", "item_id", "marketplace_id", "execution_date", "data_source", "created_at", "updated_at", "price_quality_flag", "feedback_quality_flag")-- Silver Layer Models for dbt
-- These models clean and standardize the bronze data

-- Silver: Clean eBay Data


SELECT 
    collection_timestamp,
    timezone,
    weather_category,
    product_type,
    price,
    currency,
    seller_feedback_percentage,
    seller_feedback_score,
    -- Parse JSON location data
    JSONExtractString(item_location, 'postalCode') as postal_code,
    JSONExtractString(item_location, 'country') as country,
    seller_location,
    shipping_cost,
    free_shipping,
    condition,
    buying_options,
    title_length,
    item_id,
    marketplace_id,
    execution_date,
    data_source,
    created_at,
    updated_at,
    -- Add data quality flags
    CASE 
        WHEN price <= 0 THEN 1 
        ELSE 0 
    END as price_quality_flag,
    CASE 
        WHEN seller_feedback_percentage < 0 OR seller_feedback_percentage > 100 THEN 1 
        ELSE 0 
    END as feedback_quality_flag
FROM `bronze`.`ebay_raw_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  ...
[0m12:56:38.649560 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:38.656489 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */
EXCHANGE TABLES `default`.`silver_ebay_data__dbt_backup` AND `default`.`silver_ebay_data` 
  
  ...
[0m12:56:38.702402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:38.734826 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_ebay_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_ebay_data"} */
drop table if exists `default`.`silver_ebay_data__dbt_backup` 
  ...
[0m12:56:38.781920 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:38.786460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA6457A10>]}
[0m12:56:38.787453 [info ] [Thread-1 (]: 1 of 2 OK created sql table model `default`.`silver_ebay_data` ................. [[32mOK[0m in 0.96s]
[0m12:56:38.788783 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.silver_ebay_data
[0m12:56:38.789630 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.silver_weather_data
[0m12:56:38.790324 [info ] [Thread-1 (]: 2 of 2 START sql table model `default`.`silver_weather_data` ................... [RUN]
[0m12:56:38.791973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.silver_ebay_data, now model.ebay_weather_analytics.silver_weather_data)
[0m12:56:38.792398 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.silver_weather_data
[0m12:56:38.795615 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.silver_weather_data"
[0m12:56:38.796630 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.silver_weather_data
[0m12:56:38.798421 [debug] [Thread-1 (]: Creating new relation silver_weather_data
[0m12:56:38.799382 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_weather_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_weather_data"} */

            

    
        create table `default`.`silver_weather_data`
        
  
        
  engine = MergeTree()
        order by ((time))
        
        partition by (toYYYYMM(time))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Silver: Clean Weather Data


SELECT 
    time,
    weather_code_wmo_code,
    temperature_2m_c,
    relative_humidity_2m_percent,
    cloudcover_percent,
    rain_mm,
    sunshine_duration_s,
    windspeed_10m_kmh,
    data_source,
    created_at,
    updated_at,
    -- Add weather buckets
    CASE 
        WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
        WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
        WHEN rain_mm > 10 THEN 'Heavy Rain'
        WHEN rain_mm > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END as weather_bucket,
    -- Add data quality flags
    CASE 
        WHEN temperature_2m_c < -50 OR temperature_2m_c > 60 THEN 1 
        ELSE 0 
    END as temperature_quality_flag,
    CASE 
        WHEN rain_mm < 0 THEN 1 
        ELSE 0 
    END as rain_quality_flag
FROM `bronze`.`weather_raw_data`
WHERE time IS NOT NULL
          )
        
        ...
[0m12:56:38.860653 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:38.864298 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_weather_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_weather_data"} */

    select name, type from system.columns where table = 'silver_weather_data'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:38.913668 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:38.916352 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.silver_weather_data"
[0m12:56:38.917751 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.silver_weather_data: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.silver_weather_data"} */

  
    
    
    
        
         


        insert into `default`.`silver_weather_data`
        ("time", "weather_code_wmo_code", "temperature_2m_c", "relative_humidity_2m_percent", "cloudcover_percent", "rain_mm", "sunshine_duration_s", "windspeed_10m_kmh", "data_source", "created_at", "updated_at", "weather_bucket", "temperature_quality_flag", "rain_quality_flag")-- Silver: Clean Weather Data


SELECT 
    time,
    weather_code_wmo_code,
    temperature_2m_c,
    relative_humidity_2m_percent,
    cloudcover_percent,
    rain_mm,
    sunshine_duration_s,
    windspeed_10m_kmh,
    data_source,
    created_at,
    updated_at,
    -- Add weather buckets
    CASE 
        WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
        WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
        WHEN rain_mm > 10 THEN 'Heavy Rain'
        WHEN rain_mm > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END as weather_bucket,
    -- Add data quality flags
    CASE 
        WHEN temperature_2m_c < -50 OR temperature_2m_c > 60 THEN 1 
        ELSE 0 
    END as temperature_quality_flag,
    CASE 
        WHEN rain_mm < 0 THEN 1 
        ELSE 0 
    END as rain_quality_flag
FROM `bronze`.`weather_raw_data`
WHERE time IS NOT NULL
  ...
[0m12:56:38.972410 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:38.974229 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a960716-a439-47f2-8802-b464d454c7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA81290D0>]}
[0m12:56:38.975271 [info ] [Thread-1 (]: 2 of 2 OK created sql table model `default`.`silver_weather_data` .............. [[32mOK[0m in 0.18s]
[0m12:56:38.976592 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.silver_weather_data
[0m12:56:38.978760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:56:38.979414 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:56:38.980236 [debug] [MainThread]: On list_: Close
[0m12:56:38.980927 [debug] [MainThread]: Connection 'list__default' was left open.
[0m12:56:38.981168 [debug] [MainThread]: On list__default: Close
[0m12:56:38.981796 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.silver_weather_data' was left open.
[0m12:56:38.982337 [debug] [MainThread]: On model.ebay_weather_analytics.silver_weather_data: Close
[0m12:56:38.983160 [info ] [MainThread]: 
[0m12:56:38.983864 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 2.65 seconds (2.65s).
[0m12:56:38.985406 [debug] [MainThread]: Command end result
[0m12:56:39.024650 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:39.029407 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:39.034639 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:56:39.034961 [info ] [MainThread]: 
[0m12:56:39.035647 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:56:39.035992 [info ] [MainThread]: 
[0m12:56:39.036422 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:56:39.037216 [debug] [MainThread]: Command `dbt run` succeeded at 12:56:39.037113 after 4.50 seconds
[0m12:56:39.037486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA5F21270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA81FCA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CAA5F86650>]}
[0m12:56:39.037735 [debug] [MainThread]: Flushing usage events
[0m12:56:39.832847 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:56:51.143264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C72F27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C8044050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C865FC50>]}


============================== 12:56:51.150433 | 9a1f0145-9699-4830-a44a-bd2daa2faac4 ==============================
[0m12:56:51.150433 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:56:51.151560 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'use_colors': 'True', 'target_path': 'None', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select gold', 'printer_width': '80', 'write_json': 'True'}
[0m12:56:51.409828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C79EC8A0>]}
[0m12:56:51.494315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C5D9F680>]}
[0m12:56:51.495698 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:56:51.701862 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:56:51.887337 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:56:51.887959 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:56:51.895236 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- seeds.ebay_weather_analytics
- snapshots.ebay_weather_analytics
[0m12:56:51.958864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C9B33D50>]}
[0m12:56:52.063059 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:52.065036 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:52.099890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C73B4C80>]}
[0m12:56:52.100397 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:56:52.101025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C97A65F0>]}
[0m12:56:52.103025 [info ] [MainThread]: 
[0m12:56:52.103629 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:56:52.103937 [info ] [MainThread]: 
[0m12:56:52.104391 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:56:52.110897 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:56:52.119892 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:52.821203 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:56:52.872080 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:52.939106 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m12:56:52.948634 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:53.469123 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:56:53.538876 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:56:53.541105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m12:56:53.542886 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:56:53.593168 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:53.595709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBA47790>]}
[0m12:56:53.692611 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_location
[0m12:56:53.693587 [info ] [Thread-1 (]: 1 of 9 START sql table model `default`.`dim_location` .......................... [RUN]
[0m12:56:53.694600 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.dim_location'
[0m12:56:53.694950 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_location
[0m12:56:53.701880 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_location"
[0m12:56:53.703897 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_location
[0m12:56:53.734398 [debug] [Thread-1 (]: Creating new relation dim_location
[0m12:56:53.768585 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:56:54.327066 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_location: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

            

    
        create table `default`.`dim_location`
        
  
        
  engine = MergeTree()
        order by (location_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
          )
        
        ...
[0m12:56:54.389883 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

            

    
        create table `default`.`dim_location`
        
  
        
  engine = MergeTree()
        order by (location_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
          )
        
        
[0m12:56:54.402680 [debug] [Thread-1 (]: Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:54.404464 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C9747110>]}
[0m12:56:54.405398 [error] [Thread-1 (]: 1 of 9 ERROR creating sql table model `default`.`dim_location` ................. [[31mERROR[0m in 0.71s]
[0m12:56:54.406967 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_location
[0m12:56:54.407353 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_product
[0m12:56:54.408844 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.dim_location' to be skipped because of status 'error'.  Reason: Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:56:54.407711 [info ] [Thread-1 (]: 2 of 9 START sql table model `default`.`dim_product` ........................... [RUN]
[0m12:56:54.410619 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_location, now model.ebay_weather_analytics.dim_product)
[0m12:56:54.410916 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_product
[0m12:56:54.413827 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_product"
[0m12:56:54.414654 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_product
[0m12:56:54.416060 [debug] [Thread-1 (]: Creating new relation dim_product
[0m12:56:54.416900 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        order by (product_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
          )
        
        ...
[0m12:56:54.484621 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        order by (product_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
          )
        
        
[0m12:56:54.494233 [debug] [Thread-1 (]: Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:54.494952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBBEC520>]}
[0m12:56:54.495553 [error] [Thread-1 (]: 2 of 9 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.08s]
[0m12:56:54.496379 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_product
[0m12:56:54.496728 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_weather
[0m12:56:54.497255 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:56:54.497808 [info ] [Thread-1 (]: 3 of 9 START sql table model `default`.`dim_weather` ........................... [RUN]
[0m12:56:54.498527 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_product, now model.ebay_weather_analytics.dim_weather)
[0m12:56:54.498818 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_weather
[0m12:56:54.502039 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_weather"
[0m12:56:54.503423 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_weather
[0m12:56:54.505799 [debug] [Thread-1 (]: Creating new relation dim_weather
[0m12:56:54.506979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

            

    
        create table `default`.`dim_weather`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
          )
        
        ...
[0m12:56:54.592426 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:56:54.609743 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

    select name, type from system.columns where table = 'dim_weather'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:54.660966 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:54.668206 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_weather"
[0m12:56:54.670141 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

  
    
    
    
        
         


        insert into `default`.`dim_weather`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
  ...
[0m12:56:54.730256 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:54.746526 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C9912210>]}
[0m12:56:54.747084 [info ] [Thread-1 (]: 3 of 9 OK created sql table model `default`.`dim_weather` ...................... [[32mOK[0m in 0.25s]
[0m12:56:54.747854 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_weather
[0m12:56:54.748146 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.fact_listings
[0m12:56:54.748518 [info ] [Thread-1 (]: 4 of 9 START sql table model `default`.`fact_listings` ......................... [RUN]
[0m12:56:54.748997 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_weather, now model.ebay_weather_analytics.fact_listings)
[0m12:56:54.749234 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.fact_listings
[0m12:56:54.751686 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.fact_listings"
[0m12:56:54.753056 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.fact_listings
[0m12:56:54.755041 [debug] [Thread-1 (]: Creating new relation fact_listings
[0m12:56:54.756944 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

            

    
        create table `default`.`fact_listings`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
          )
        
        ...
[0m12:56:54.813849 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:54.817296 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

    select name, type from system.columns where table = 'fact_listings'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:54.864767 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:54.869031 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.fact_listings"
[0m12:56:54.871934 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

  
    
    
    
        
         


        insert into `default`.`fact_listings`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")-- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  ...
[0m12:56:54.934713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:56:54.937624 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBC5FD50>]}
[0m12:56:54.938548 [info ] [Thread-1 (]: 4 of 9 OK created sql table model `default`.`fact_listings` .................... [[32mOK[0m in 0.19s]
[0m12:56:54.939693 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.fact_listings
[0m12:56:54.940190 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:56:54.941149 [info ] [Thread-1 (]: 5 of 9 START sql table model `default`.`gold_daily_listings_summary` ........... [RUN]
[0m12:56:54.942020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.fact_listings, now model.ebay_weather_analytics.gold_daily_listings_summary)
[0m12:56:54.942353 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:56:54.945616 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.gold_daily_listings_summary"
[0m12:56:54.946716 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:56:54.948349 [debug] [Thread-1 (]: Creating new relation gold_daily_listings_summary
[0m12:56:54.949794 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_daily_listings_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_daily_listings_summary"} */

            

    
        create table `default`.`gold_daily_listings_summary`
        
  
        
  engine = MergeTree()
        order by ((date, weather_category, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer Models for dbt
-- These models create business-ready analytical tables

-- Gold: Daily eBay Listings Summary


SELECT 
    toDate(collection_timestamp) as date,
    weather_category,
    product_type,
    postal_code,
    country,
    COUNT(*) as total_listings,
    COUNT(DISTINCT item_id) as unique_items,
    AVG(price) as avg_price,
    MIN(price) as min_price,
    MAX(price) as max_price,
    STDDEV(price) as price_stddev,
    AVG(seller_feedback_percentage) as avg_seller_feedback,
    SUM(CASE WHEN free_shipping THEN 1 ELSE 0 END) as free_shipping_count,
    SUM(CASE WHEN free_shipping THEN 0 ELSE 1 END) as paid_shipping_count,
    AVG(CASE WHEN NOT free_shipping THEN shipping_cost END) as avg_paid_shipping_cost,
    AVG(title_length) as avg_title_length,
    SUM(price_quality_flag) as price_quality_issues,
    SUM(feedback_quality_flag) as feedback_quality_issues
FROM `default`.`silver_ebay_data`
GROUP BY 
    toDate(collection_timestamp),
    weather_category,
    product_type,
    postal_code,
    country
          )
        
        ...
[0m12:56:55.003995 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_daily_listings_summary"} */

            

    
        create table `default`.`gold_daily_listings_summary`
        
  
        
  engine = MergeTree()
        order by ((date, weather_category, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer Models for dbt
-- These models create business-ready analytical tables

-- Gold: Daily eBay Listings Summary


SELECT 
    toDate(collection_timestamp) as date,
    weather_category,
    product_type,
    postal_code,
    country,
    COUNT(*) as total_listings,
    COUNT(DISTINCT item_id) as unique_items,
    AVG(price) as avg_price,
    MIN(price) as min_price,
    MAX(price) as max_price,
    STDDEV(price) as price_stddev,
    AVG(seller_feedback_percentage) as avg_seller_feedback,
    SUM(CASE WHEN free_shipping THEN 1 ELSE 0 END) as free_shipping_count,
    SUM(CASE WHEN free_shipping THEN 0 ELSE 1 END) as paid_shipping_count,
    AVG(CASE WHEN NOT free_shipping THEN shipping_cost END) as avg_paid_shipping_cost,
    AVG(title_length) as avg_title_length,
    SUM(price_quality_flag) as price_quality_issues,
    SUM(feedback_quality_flag) as feedback_quality_issues
FROM `default`.`silver_ebay_data`
GROUP BY 
    toDate(collection_timestamp),
    weather_category,
    product_type,
    postal_code,
    country
          )
        
        
[0m12:56:55.012873 [debug] [Thread-1 (]: Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope SELECT toDate(collection_timestamp) AS date, weather_category, product_type, postal_code, country, count(*) AS total_listings, COUNTDistinct(item_id) AS unique_items, avg(price) AS avg_price, min(price) AS min_price, max(price) AS max_price, STDDEV(price) AS price_stddev, avg(seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(free_shipping, 0, 1)) AS paid_shipping_count, avg(multiIf(NOT free_shipping, shipping_cost, NULL)) AS avg_paid_shipping_cost, avg(title_length) AS avg_title_length, sum(price_quality_flag) AS price_quality_issues, sum(feedback_quality_flag) AS feedback_quality_issues FROM default.silver_ebay_data GROUP BY toDate(collection_timestamp), weather_category, product_type, postal_code, country. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74
[0m12:56:55.013512 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C9E51400>]}
[0m12:56:55.014145 [error] [Thread-1 (]: 5 of 9 ERROR creating sql table model `default`.`gold_daily_listings_summary` .. [[31mERROR[0m in 0.07s]
[0m12:56:55.014980 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:56:55.015246 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:56:55.016304 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.gold_daily_listings_summary' to be skipped because of status 'error'.  Reason: Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope SELECT toDate(collection_timestamp) AS date, weather_category, product_type, postal_code, country, count(*) AS total_listings, COUNTDistinct(item_id) AS unique_items, avg(price) AS avg_price, min(price) AS min_price, max(price) AS max_price, STDDEV(price) AS price_stddev, avg(seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(free_shipping, 0, 1)) AS paid_shipping_count, avg(multiIf(NOT free_shipping, shipping_cost, NULL)) AS avg_paid_shipping_cost, avg(title_length) AS avg_title_length, sum(price_quality_flag) AS price_quality_issues, sum(feedback_quality_flag) AS feedback_quality_issues FROM default.silver_ebay_data GROUP BY toDate(collection_timestamp), weather_category, product_type, postal_code, country. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74.
[0m12:56:55.016973 [info ] [Thread-1 (]: 6 of 9 START sql table model `default`.`gold_weather_impact_analysis` .......... [RUN]
[0m12:56:55.017662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.gold_daily_listings_summary, now model.ebay_weather_analytics.gold_weather_impact_analysis)
[0m12:56:55.017972 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:56:55.021055 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.gold_weather_impact_analysis"
[0m12:56:55.023421 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:56:55.025728 [debug] [Thread-1 (]: Creating new relation gold_weather_impact_analysis
[0m12:56:55.027421 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

            

    
        create table `default`.`gold_weather_impact_analysis`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m) as avg_temperature,
        SUM(rain) as total_rain,
        SUM(sunshine_duration) as total_sunshine,
        AVG(windspeed_10m) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m <= -5 THEN 'Extreme Cold'
            WHEN rain > 10 THEN 'Heavy Rain'
            WHEN rain > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
          )
        
        ...
[0m12:56:55.092517 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

            

    
        create table `default`.`gold_weather_impact_analysis`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m) as avg_temperature,
        SUM(rain) as total_rain,
        SUM(sunshine_duration) as total_sunshine,
        AVG(windspeed_10m) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m <= -5 THEN 'Extreme Cold'
            WHEN rain > 10 THEN 'Heavy Rain'
            WHEN rain > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
          )
        
        
[0m12:56:55.103072 [debug] [Thread-1 (]: Database Error in model gold_weather_impact_analysis (models\gold\gold_weather_impact_analysis.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `temperature_2m` in scope  weather_daily AS w. Maybe you meant: ['temperature_2m_c']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  11. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
  12. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
  13. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785c6a7
  14. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  15. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  16. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  17. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  18. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  19. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  20. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  21. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  22. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  23. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  24. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  25. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  26. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  27. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  28. DB::TCPHandler::run() @ 0x0000000019e4f119
  29. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  30. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  31. Poco::PooledThread::run() @ 0x000000001ef15b87
[0m12:56:55.103897 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBC907D0>]}
[0m12:56:55.104524 [error] [Thread-1 (]: 6 of 9 ERROR creating sql table model `default`.`gold_weather_impact_analysis` . [[31mERROR[0m in 0.09s]
[0m12:56:55.106750 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:56:55.107448 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:56:55.108363 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.gold_weather_impact_analysis' to be skipped because of status 'error'.  Reason: Database Error in model gold_weather_impact_analysis (models\gold\gold_weather_impact_analysis.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `temperature_2m` in scope  weather_daily AS w. Maybe you meant: ['temperature_2m_c']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  11. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
  12. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
  13. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785c6a7
  14. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  15. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  16. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  17. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  18. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  19. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  20. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  21. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  22. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  23. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  24. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  25. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  26. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  27. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  28. DB::TCPHandler::run() @ 0x0000000019e4f119
  29. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  30. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  31. Poco::PooledThread::run() @ 0x000000001ef15b87.
[0m12:56:55.109623 [info ] [Thread-1 (]: 7 of 9 START sql table model `default`.`analytics_pricing_behavior` ............ [RUN]
[0m12:56:55.110575 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.gold_weather_impact_analysis, now model.ebay_weather_analytics.analytics_pricing_behavior)
[0m12:56:55.110968 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:56:55.116762 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_pricing_behavior"
[0m12:56:55.117956 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:56:55.119840 [debug] [Thread-1 (]: Creating new relation analytics_pricing_behavior
[0m12:56:55.122243 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    f.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    STDDEV(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    STDDEV(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY f.product_type, wb.weather_bucket
ORDER BY f.product_type, wb.weather_bucket
          )
        
        ...
[0m12:56:55.189209 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    f.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    STDDEV(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    STDDEV(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY f.product_type, wb.weather_bucket
ORDER BY f.product_type, wb.weather_bucket
          )
        
        
[0m12:56:55.202674 [debug] [Thread-1 (]: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope WITH wx_bucket AS (SELECT weather_category, multiIf(weather_category = 'rain_products', 'Precipitation-Heavy', weather_category = 'heat_products', 'Extreme Heat', weather_category = 'cold_products', 'Extreme Cold', 'Normal') AS weather_bucket FROM (SELECT DISTINCT weather_category FROM default.fact_listings WHERE weather_category IS NOT NULL) AS w) SELECT f.product_type, wb.weather_bucket, avg(f.price) AS avg_price, min(f.price) AS min_price, max(f.price) AS max_price, count(*) AS listings, STDDEV(f.price) AS price_stddev, quantile(0.5)(f.price) AS median_price, quantile(0.25)(f.price) AS q1_price, quantile(0.75)(f.price) AS q3_price, max(f.price) - min(f.price) AS price_range, STDDEV(f.price) / avg(f.price) AS price_coefficient_variation, avg(f.seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(f.free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(f.free_shipping, 0, 1)) AS paid_shipping_count FROM default.fact_listings AS f INNER JOIN wx_bucket AS wb ON f.weather_category = wb.weather_category GROUP BY f.product_type, wb.weather_bucket ORDER BY f.product_type ASC, wb.weather_bucket ASC. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74
[0m12:56:55.204130 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBCAB5F0>]}
[0m12:56:55.209023 [error] [Thread-1 (]: 7 of 9 ERROR creating sql table model `default`.`analytics_pricing_behavior` ... [[31mERROR[0m in 0.09s]
[0m12:56:55.211099 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:56:55.211845 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_seller_performance
[0m12:56:55.212782 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_pricing_behavior' to be skipped because of status 'error'.  Reason: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope WITH wx_bucket AS (SELECT weather_category, multiIf(weather_category = 'rain_products', 'Precipitation-Heavy', weather_category = 'heat_products', 'Extreme Heat', weather_category = 'cold_products', 'Extreme Cold', 'Normal') AS weather_bucket FROM (SELECT DISTINCT weather_category FROM default.fact_listings WHERE weather_category IS NOT NULL) AS w) SELECT f.product_type, wb.weather_bucket, avg(f.price) AS avg_price, min(f.price) AS min_price, max(f.price) AS max_price, count(*) AS listings, STDDEV(f.price) AS price_stddev, quantile(0.5)(f.price) AS median_price, quantile(0.25)(f.price) AS q1_price, quantile(0.75)(f.price) AS q3_price, max(f.price) - min(f.price) AS price_range, STDDEV(f.price) / avg(f.price) AS price_coefficient_variation, avg(f.seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(f.free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(f.free_shipping, 0, 1)) AS paid_shipping_count FROM default.fact_listings AS f INNER JOIN wx_bucket AS wb ON f.weather_category = wb.weather_category GROUP BY f.product_type, wb.weather_bucket ORDER BY f.product_type ASC, wb.weather_bucket ASC. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74.
[0m12:56:55.213515 [info ] [Thread-1 (]: 8 of 9 START sql table model `default`.`analytics_seller_performance` .......... [RUN]
[0m12:56:55.214703 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_pricing_behavior, now model.ebay_weather_analytics.analytics_seller_performance)
[0m12:56:55.215366 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_seller_performance
[0m12:56:55.221567 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_seller_performance"
[0m12:56:55.224839 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_seller_performance
[0m12:56:55.230344 [debug] [Thread-1 (]: Creating new relation analytics_seller_performance
[0m12:56:55.234742 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH seller_tiers AS (
    SELECT
        item_id,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier,
        seller_feedback_score,
        seller_feedback_percentage
    FROM `default`.`fact_listings`
),
wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    st.feedback_score_tier,
    st.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(st.seller_feedback_score) AS avg_feedback_score,
    AVG(st.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN seller_tiers st ON f.item_id = st.item_id
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY st.feedback_score_tier, st.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        ...
[0m12:56:55.324115 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH seller_tiers AS (
    SELECT
        item_id,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier,
        seller_feedback_score,
        seller_feedback_percentage
    FROM `default`.`fact_listings`
),
wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    st.feedback_score_tier,
    st.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(st.seller_feedback_score) AS avg_feedback_score,
    AVG(st.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN seller_tiers st ON f.item_id = st.item_id
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY st.feedback_score_tier, st.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        
[0m12:56:55.332886 [debug] [Thread-1 (]: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:55.333992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBC90350>]}
[0m12:56:55.335621 [error] [Thread-1 (]: 8 of 9 ERROR creating sql table model `default`.`analytics_seller_performance` . [[31mERROR[0m in 0.12s]
[0m12:56:55.337821 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_seller_performance
[0m12:56:55.338488 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:56:55.340512 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_seller_performance' to be skipped because of status 'error'.  Reason: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:56:55.341762 [info ] [Thread-1 (]: 9 of 9 START sql table model `default`.`analytics_weather_impact` .............. [RUN]
[0m12:56:55.343375 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_seller_performance, now model.ebay_weather_analytics.analytics_weather_impact)
[0m12:56:55.344354 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_weather_impact
[0m12:56:55.347711 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:56:55.349199 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_weather_impact
[0m12:56:55.351840 [debug] [Thread-1 (]: Creating new relation analytics_weather_impact
[0m12:56:55.353929 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
          )
        
        ...
[0m12:56:55.426912 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:56:55.432131 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

    select name, type from system.columns where table = 'analytics_weather_impact'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:56:55.480317 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:56:55.481968 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:56:55.483406 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

  
    
    
    
        
         


        insert into `default`.`analytics_weather_impact`
        ("date", "weather_bucket", "listings", "unique_items", "avg_price", "avg_seller_feedback", "daily_market_share_percent", "avg_listings_7day")-- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
  ...
[0m12:56:55.552376 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:56:55.553966 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9a1f0145-9699-4830-a44a-bd2daa2faac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBCAAFF0>]}
[0m12:56:55.554869 [info ] [Thread-1 (]: 9 of 9 OK created sql table model `default`.`analytics_weather_impact` ......... [[32mOK[0m in 0.21s]
[0m12:56:55.555971 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:56:55.558184 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:56:55.558852 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:56:55.559373 [debug] [MainThread]: On list_: Close
[0m12:56:55.559737 [debug] [MainThread]: Connection 'list__default' was left open.
[0m12:56:55.560037 [debug] [MainThread]: On list__default: Close
[0m12:56:55.560904 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.analytics_weather_impact' was left open.
[0m12:56:55.561517 [debug] [MainThread]: On model.ebay_weather_analytics.analytics_weather_impact: Close
[0m12:56:55.563619 [info ] [MainThread]: 
[0m12:56:55.565172 [info ] [MainThread]: Finished running 9 table models in 0 hours 0 minutes and 3.46 seconds (3.46s).
[0m12:56:55.567108 [debug] [MainThread]: Command end result
[0m12:56:55.600219 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:56:55.602213 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:56:55.611038 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:56:55.611640 [info ] [MainThread]: 
[0m12:56:55.612359 [info ] [MainThread]: [31mCompleted with 6 errors, 0 partial successes, and 0 warnings:[0m
[0m12:56:55.612839 [info ] [MainThread]: 
[0m12:56:55.613395 [error] [MainThread]: [31mFailure in model dim_location (models\gold\dim_location.sql)[0m
[0m12:56:55.614038 [error] [MainThread]:   Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:55.614800 [info ] [MainThread]: 
[0m12:56:55.615267 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\dim_location.sql
[0m12:56:55.615915 [info ] [MainThread]: 
[0m12:56:55.616507 [error] [MainThread]: [31mFailure in model dim_product (models\gold\dim_product.sql)[0m
[0m12:56:55.617136 [error] [MainThread]:   Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:55.618014 [info ] [MainThread]: 
[0m12:56:55.618519 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\dim_product.sql
[0m12:56:55.619046 [info ] [MainThread]: 
[0m12:56:55.619657 [error] [MainThread]: [31mFailure in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)[0m
[0m12:56:55.620545 [error] [MainThread]:   Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope SELECT toDate(collection_timestamp) AS date, weather_category, product_type, postal_code, country, count(*) AS total_listings, COUNTDistinct(item_id) AS unique_items, avg(price) AS avg_price, min(price) AS min_price, max(price) AS max_price, STDDEV(price) AS price_stddev, avg(seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(free_shipping, 0, 1)) AS paid_shipping_count, avg(multiIf(NOT free_shipping, shipping_cost, NULL)) AS avg_paid_shipping_cost, avg(title_length) AS avg_title_length, sum(price_quality_flag) AS price_quality_issues, sum(feedback_quality_flag) AS feedback_quality_issues FROM default.silver_ebay_data GROUP BY toDate(collection_timestamp), weather_category, product_type, postal_code, country. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74
[0m12:56:55.621785 [info ] [MainThread]: 
[0m12:56:55.622703 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\gold_daily_listings_summary.sql
[0m12:56:55.623345 [info ] [MainThread]: 
[0m12:56:55.624229 [error] [MainThread]: [31mFailure in model gold_weather_impact_analysis (models\gold\gold_weather_impact_analysis.sql)[0m
[0m12:56:55.625608 [error] [MainThread]:   Database Error in model gold_weather_impact_analysis (models\gold\gold_weather_impact_analysis.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `temperature_2m` in scope  weather_daily AS w. Maybe you meant: ['temperature_2m_c']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  11. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
  12. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
  13. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785c6a7
  14. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  15. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  16. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  17. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  18. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  19. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  20. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  21. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  22. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  23. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  24. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  25. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  26. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  27. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  28. DB::TCPHandler::run() @ 0x0000000019e4f119
  29. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  30. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  31. Poco::PooledThread::run() @ 0x000000001ef15b87
[0m12:56:55.627184 [info ] [MainThread]: 
[0m12:56:55.627977 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\gold_weather_impact_analysis.sql
[0m12:56:55.628588 [info ] [MainThread]: 
[0m12:56:55.629267 [error] [MainThread]: [31mFailure in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)[0m
[0m12:56:55.630095 [error] [MainThread]:   Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 46.
  DB::Exception: Function with name `STDDEV` does not exist. In scope WITH wx_bucket AS (SELECT weather_category, multiIf(weather_category = 'rain_products', 'Precipitation-Heavy', weather_category = 'heat_products', 'Extreme Heat', weather_category = 'cold_products', 'Extreme Cold', 'Normal') AS weather_bucket FROM (SELECT DISTINCT weather_category FROM default.fact_listings WHERE weather_category IS NOT NULL) AS w) SELECT f.product_type, wb.weather_bucket, avg(f.price) AS avg_price, min(f.price) AS min_price, max(f.price) AS max_price, count(*) AS listings, STDDEV(f.price) AS price_stddev, quantile(0.5)(f.price) AS median_price, quantile(0.25)(f.price) AS q1_price, quantile(0.75)(f.price) AS q3_price, max(f.price) - min(f.price) AS price_range, STDDEV(f.price) / avg(f.price) AS price_coefficient_variation, avg(f.seller_feedback_percentage) AS avg_seller_feedback, sum(multiIf(f.free_shipping, 1, 0)) AS free_shipping_count, sum(multiIf(f.free_shipping, 0, 1)) AS paid_shipping_count FROM default.fact_listings AS f INNER JOIN wx_bucket AS wb ON f.weather_category = wb.weather_category GROUP BY f.product_type, wb.weather_bucket ORDER BY f.product_type ASC, wb.weather_bucket ASC. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String, String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&, String&&) @ 0x000000000cbc05eb
  4. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aae7d7
  5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  6. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  7. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017859ea7
  8. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d06b
  9. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  10. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  11. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  12. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  13. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  14. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  15. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  16. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  17. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  18. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  19. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  20. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  21. DB::TCPHandler::run() @ 0x0000000019e4f119
  22. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  23. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  24. Poco::PooledThread::run() @ 0x000000001ef15b87
  25. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  26. ? @ 0x0000000000094ac3
  27. ? @ 0x0000000000125a74
[0m12:56:55.631427 [info ] [MainThread]: 
[0m12:56:55.632054 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_pricing_behavior.sql
[0m12:56:55.632596 [info ] [MainThread]: 
[0m12:56:55.633188 [error] [MainThread]: [31mFailure in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)[0m
[0m12:56:55.633901 [error] [MainThread]:   Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:56:55.634823 [info ] [MainThread]: 
[0m12:56:55.635354 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_seller_performance.sql
[0m12:56:55.635834 [info ] [MainThread]: 
[0m12:56:55.636291 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=6 SKIP=0 NO-OP=0 TOTAL=9
[0m12:56:55.637831 [debug] [MainThread]: Command `dbt run` failed at 12:56:55.637553 after 4.68 seconds
[0m12:56:55.638712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBC90710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C5DE3410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2CBA159D0>]}
[0m12:56:55.639459 [debug] [MainThread]: Flushing usage events
[0m12:56:56.569059 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:23.375315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CA3127B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CB064050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CB67FC50>]}


============================== 12:57:23.380703 | b0b7ee28-26cc-4d25-b9cc-569e78239a84 ==============================
[0m12:57:23.380703 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:57:23.381637 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'write_json': 'True', 'printer_width': '80', 'log_format': 'default', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'partial_parse': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select gold', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m12:57:23.618007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CAA0C8A0>]}
[0m12:57:23.700495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6C8DBF680>]}
[0m12:57:23.701730 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:57:23.918897 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:57:24.064625 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m12:57:24.065213 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\gold_daily_listings_summary.sql
[0m12:57:24.065676 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\gold_weather_impact_analysis.sql
[0m12:57:24.065987 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_pricing_behavior.sql
[0m12:57:24.569152 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- seeds.ebay_weather_analytics
- snapshots.ebay_weather_analytics
[0m12:57:24.581524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CCBE7E50>]}
[0m12:57:24.684974 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:57:24.689471 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:57:24.716020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CC71E4E0>]}
[0m12:57:24.716526 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:57:24.717023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CC8FBE70>]}
[0m12:57:24.718598 [info ] [MainThread]: 
[0m12:57:24.719182 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:57:24.719529 [info ] [MainThread]: 
[0m12:57:24.720733 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:57:24.727078 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:57:24.736049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:25.474435 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:57:25.520509 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:25.574502 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m12:57:25.581079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:26.118894 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:57:26.189011 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:57:26.191376 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m12:57:26.192876 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:57:26.243423 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:26.247152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CCF976C0>]}
[0m12:57:26.252573 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_location
[0m12:57:26.254034 [info ] [Thread-1 (]: 1 of 9 START sql table model `default`.`dim_location` .......................... [RUN]
[0m12:57:26.255585 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.dim_location'
[0m12:57:26.256445 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_location
[0m12:57:26.265615 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_location"
[0m12:57:26.267772 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_location
[0m12:57:26.289930 [debug] [Thread-1 (]: Creating new relation dim_location
[0m12:57:26.325492 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:57:26.840594 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_location: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

            

    
        create table `default`.`dim_location`
        
  
        
  engine = MergeTree()
        order by (location_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
          )
        
        ...
[0m12:57:26.897804 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

            

    
        create table `default`.`dim_location`
        
  
        
  engine = MergeTree()
        order by (location_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
          )
        
        
[0m12:57:26.909608 [debug] [Thread-1 (]: Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:26.911046 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CED7C950>]}
[0m12:57:26.911762 [error] [Thread-1 (]: 1 of 9 ERROR creating sql table model `default`.`dim_location` ................. [[31mERROR[0m in 0.65s]
[0m12:57:26.912540 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_location
[0m12:57:26.912833 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_product
[0m12:57:26.913591 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.dim_location' to be skipped because of status 'error'.  Reason: Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:57:26.914332 [info ] [Thread-1 (]: 2 of 9 START sql table model `default`.`dim_product` ........................... [RUN]
[0m12:57:26.915841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_location, now model.ebay_weather_analytics.dim_product)
[0m12:57:26.916129 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_product
[0m12:57:26.919100 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_product"
[0m12:57:26.921094 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_product
[0m12:57:26.924217 [debug] [Thread-1 (]: Creating new relation dim_product
[0m12:57:26.928126 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        order by (product_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
          )
        
        ...
[0m12:57:26.981094 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        order by (product_key)
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
          )
        
        
[0m12:57:26.989833 [debug] [Thread-1 (]: Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:26.991031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CDF620A0>]}
[0m12:57:26.991836 [error] [Thread-1 (]: 2 of 9 ERROR creating sql table model `default`.`dim_product` .................. [[31mERROR[0m in 0.08s]
[0m12:57:26.992711 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_product
[0m12:57:26.993011 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_weather
[0m12:57:26.993420 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.dim_product' to be skipped because of status 'error'.  Reason: Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:57:26.993858 [info ] [Thread-1 (]: 3 of 9 START sql table model `default`.`dim_weather` ........................... [RUN]
[0m12:57:26.994399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_product, now model.ebay_weather_analytics.dim_weather)
[0m12:57:26.994639 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_weather
[0m12:57:26.998002 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_weather"
[0m12:57:26.999347 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_weather
[0m12:57:27.006980 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

            

    
        create table `default`.`dim_weather__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
          )
        
        ...
[0m12:57:27.098707 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m12:57:27.115905 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

    select name, type from system.columns where table = 'dim_weather__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:27.165864 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:27.171227 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_weather"
[0m12:57:27.172481 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

  
    
    
    
        
         


        insert into `default`.`dim_weather__dbt_backup`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
  ...
[0m12:57:27.236974 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:27.242149 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */
EXCHANGE TABLES `default`.`dim_weather__dbt_backup` AND `default`.`dim_weather` 
  
  ...
[0m12:57:27.287690 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:57:27.312556 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */
drop table if exists `default`.`dim_weather__dbt_backup` 
  ...
[0m12:57:27.358789 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:27.361880 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6C8439C70>]}
[0m12:57:27.362458 [info ] [Thread-1 (]: 3 of 9 OK created sql table model `default`.`dim_weather` ...................... [[32mOK[0m in 0.37s]
[0m12:57:27.363615 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_weather
[0m12:57:27.364213 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.fact_listings
[0m12:57:27.365129 [info ] [Thread-1 (]: 4 of 9 START sql table model `default`.`fact_listings` ......................... [RUN]
[0m12:57:27.367599 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_weather, now model.ebay_weather_analytics.fact_listings)
[0m12:57:27.368519 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.fact_listings
[0m12:57:27.374120 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.fact_listings"
[0m12:57:27.375927 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.fact_listings
[0m12:57:27.380239 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

            

    
        create table `default`.`fact_listings__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
          )
        
        ...
[0m12:57:27.452960 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:57:27.456012 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

    select name, type from system.columns where table = 'fact_listings__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:27.506145 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:27.509830 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.fact_listings"
[0m12:57:27.512053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

  
    
    
    
        
         


        insert into `default`.`fact_listings__dbt_backup`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")-- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  ...
[0m12:57:27.572193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:27.574646 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
EXCHANGE TABLES `default`.`fact_listings__dbt_backup` AND `default`.`fact_listings` 
  
  ...
[0m12:57:27.619144 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:57:27.626620 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
drop table if exists `default`.`fact_listings__dbt_backup` 
  ...
[0m12:57:27.671980 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:57:27.675474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CEC54C50>]}
[0m12:57:27.676681 [info ] [Thread-1 (]: 4 of 9 OK created sql table model `default`.`fact_listings` .................... [[32mOK[0m in 0.31s]
[0m12:57:27.678117 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.fact_listings
[0m12:57:27.678583 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:57:27.679198 [info ] [Thread-1 (]: 5 of 9 START sql table model `default`.`gold_daily_listings_summary` ........... [RUN]
[0m12:57:27.680398 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.fact_listings, now model.ebay_weather_analytics.gold_daily_listings_summary)
[0m12:57:27.681234 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:57:27.683913 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.gold_daily_listings_summary"
[0m12:57:27.685068 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:57:27.688526 [debug] [Thread-1 (]: Creating new relation gold_daily_listings_summary
[0m12:57:27.690731 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_daily_listings_summary: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_daily_listings_summary"} */

            

    
        create table `default`.`gold_daily_listings_summary`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, weather_category, product_type))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer Models for dbt
-- These models create business-ready analytical tables

-- Gold: Daily eBay Listings Summary


SELECT 
    toDate(collection_timestamp) as date,
    weather_category,
    product_type,
    postal_code,
    country,
    COUNT(*) as total_listings,
    COUNT(DISTINCT item_id) as unique_items,
    AVG(price) as avg_price,
    MIN(price) as min_price,
    MAX(price) as max_price,
    stddevPop(price) as price_stddev,
    AVG(seller_feedback_percentage) as avg_seller_feedback,
    SUM(CASE WHEN free_shipping THEN 1 ELSE 0 END) as free_shipping_count,
    SUM(CASE WHEN free_shipping THEN 0 ELSE 1 END) as paid_shipping_count,
    AVG(CASE WHEN NOT free_shipping THEN shipping_cost END) as avg_paid_shipping_cost,
    AVG(title_length) as avg_title_length,
    SUM(price_quality_flag) as price_quality_issues,
    SUM(feedback_quality_flag) as feedback_quality_issues
FROM `default`.`silver_ebay_data`
GROUP BY 
    toDate(collection_timestamp),
    weather_category,
    product_type,
    postal_code,
    country
          )
        
        ...
[0m12:57:27.742840 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_daily_listings_summary"} */

            

    
        create table `default`.`gold_daily_listings_summary`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, weather_category, product_type))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer Models for dbt
-- These models create business-ready analytical tables

-- Gold: Daily eBay Listings Summary


SELECT 
    toDate(collection_timestamp) as date,
    weather_category,
    product_type,
    postal_code,
    country,
    COUNT(*) as total_listings,
    COUNT(DISTINCT item_id) as unique_items,
    AVG(price) as avg_price,
    MIN(price) as min_price,
    MAX(price) as max_price,
    stddevPop(price) as price_stddev,
    AVG(seller_feedback_percentage) as avg_seller_feedback,
    SUM(CASE WHEN free_shipping THEN 1 ELSE 0 END) as free_shipping_count,
    SUM(CASE WHEN free_shipping THEN 0 ELSE 1 END) as paid_shipping_count,
    AVG(CASE WHEN NOT free_shipping THEN shipping_cost END) as avg_paid_shipping_cost,
    AVG(title_length) as avg_title_length,
    SUM(price_quality_flag) as price_quality_issues,
    SUM(feedback_quality_flag) as feedback_quality_issues
FROM `default`.`silver_ebay_data`
GROUP BY 
    toDate(collection_timestamp),
    weather_category,
    product_type,
    postal_code,
    country
          )
        
        
[0m12:57:27.750936 [debug] [Thread-1 (]: Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 47.
  DB::Exception: Missing columns: 'collection_timestamp' while processing: 'toYYYYMM(collection_timestamp)', required columns: 'collection_timestamp', available columns: 'avg_paid_shipping_cost.null' 'price_quality_issues' 'avg_title_length' 'paid_shipping_count' 'free_shipping_count' 'price_stddev' 'max_price' 'avg_paid_shipping_cost' 'avg_seller_feedback' 'avg_price' 'unique_items' 'min_price' 'country' 'postal_code' 'product_type' 'feedback_quality_issues' 'total_listings' 'weather_category' 'date'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:27.751524 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CEE8FA10>]}
[0m12:57:27.752008 [error] [Thread-1 (]: 5 of 9 ERROR creating sql table model `default`.`gold_daily_listings_summary` .. [[31mERROR[0m in 0.07s]
[0m12:57:27.753304 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.gold_daily_listings_summary
[0m12:57:27.754020 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:27.754693 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.gold_daily_listings_summary' to be skipped because of status 'error'.  Reason: Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 47.
  DB::Exception: Missing columns: 'collection_timestamp' while processing: 'toYYYYMM(collection_timestamp)', required columns: 'collection_timestamp', available columns: 'avg_paid_shipping_cost.null' 'price_quality_issues' 'avg_title_length' 'paid_shipping_count' 'free_shipping_count' 'price_stddev' 'max_price' 'avg_paid_shipping_cost' 'avg_seller_feedback' 'avg_price' 'unique_items' 'min_price' 'country' 'postal_code' 'product_type' 'feedback_quality_issues' 'total_listings' 'weather_category' 'date'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:57:27.755334 [info ] [Thread-1 (]: 6 of 9 START sql table model `default`.`gold_weather_impact_analysis` .......... [RUN]
[0m12:57:27.756446 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.gold_daily_listings_summary, now model.ebay_weather_analytics.gold_weather_impact_analysis)
[0m12:57:27.756943 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:27.759567 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.gold_weather_impact_analysis"
[0m12:57:27.760508 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:27.762454 [debug] [Thread-1 (]: Creating new relation gold_weather_impact_analysis
[0m12:57:27.763284 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

            

    
        create table `default`.`gold_weather_impact_analysis`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
            WHEN rain_mm > 10 THEN 'Heavy Rain'
            WHEN rain_mm > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
          )
        
        ...
[0m12:57:27.826539 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:27.835871 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

    select name, type from system.columns where table = 'gold_weather_impact_analysis'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:27.887118 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:27.891715 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.gold_weather_impact_analysis"
[0m12:57:27.893439 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

  
    
    
    
        
         


        insert into `default`.`gold_weather_impact_analysis`
        ("date", "weather_bucket", "avg_temperature", "total_rain", "total_sunshine", "avg_wind_speed", "weather_category", "product_type", "listings_count", "avg_price", "avg_seller_feedback", "weather_demand_alignment")-- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
            WHEN rain_mm > 10 THEN 'Heavy Rain'
            WHEN rain_mm > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
  ...
[0m12:57:27.960840 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:57:27.962720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CEE5FA10>]}
[0m12:57:27.963213 [info ] [Thread-1 (]: 6 of 9 OK created sql table model `default`.`gold_weather_impact_analysis` ..... [[32mOK[0m in 0.21s]
[0m12:57:27.963915 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:27.964209 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:57:27.964701 [info ] [Thread-1 (]: 7 of 9 START sql table model `default`.`analytics_pricing_behavior` ............ [RUN]
[0m12:57:27.965386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.gold_weather_impact_analysis, now model.ebay_weather_analytics.analytics_pricing_behavior)
[0m12:57:27.965972 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:57:27.968459 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_pricing_behavior"
[0m12:57:27.969327 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:57:27.972625 [debug] [Thread-1 (]: Creating new relation analytics_pricing_behavior
[0m12:57:27.973725 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    f.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY f.product_type, wb.weather_bucket
ORDER BY f.product_type, wb.weather_bucket
          )
        
        ...
[0m12:57:28.025795 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    f.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY f.product_type, wb.weather_bucket
ORDER BY f.product_type, wb.weather_bucket
          )
        
        
[0m12:57:28.034202 [debug] [Thread-1 (]: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'paid_shipping_count' 'price_coefficient_variation' 'q3_price' 'price_range' 'q1_price' 'median_price' 'avg_seller_feedback' 'avg_price' 'price_stddev' 'listings' 'max_price' 'weather_bucket' 'min_price' 'product_type'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.034844 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CED61130>]}
[0m12:57:28.035478 [error] [Thread-1 (]: 7 of 9 ERROR creating sql table model `default`.`analytics_pricing_behavior` ... [[31mERROR[0m in 0.07s]
[0m12:57:28.036827 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m12:57:28.037809 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_seller_performance
[0m12:57:28.038980 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_pricing_behavior' to be skipped because of status 'error'.  Reason: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'paid_shipping_count' 'price_coefficient_variation' 'q3_price' 'price_range' 'q1_price' 'median_price' 'avg_seller_feedback' 'avg_price' 'price_stddev' 'listings' 'max_price' 'weather_bucket' 'min_price' 'product_type'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:57:28.039832 [info ] [Thread-1 (]: 8 of 9 START sql table model `default`.`analytics_seller_performance` .......... [RUN]
[0m12:57:28.040600 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_pricing_behavior, now model.ebay_weather_analytics.analytics_seller_performance)
[0m12:57:28.040898 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_seller_performance
[0m12:57:28.044092 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_seller_performance"
[0m12:57:28.044944 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_seller_performance
[0m12:57:28.047280 [debug] [Thread-1 (]: Creating new relation analytics_seller_performance
[0m12:57:28.048568 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH seller_tiers AS (
    SELECT
        item_id,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier,
        seller_feedback_score,
        seller_feedback_percentage
    FROM `default`.`fact_listings`
),
wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    st.feedback_score_tier,
    st.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(st.seller_feedback_score) AS avg_feedback_score,
    AVG(st.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN seller_tiers st ON f.item_id = st.item_id
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY st.feedback_score_tier, st.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        ...
[0m12:57:28.124173 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH seller_tiers AS (
    SELECT
        item_id,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier,
        seller_feedback_score,
        seller_feedback_percentage
    FROM `default`.`fact_listings`
),
wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    st.feedback_score_tier,
    st.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(st.seller_feedback_score) AS avg_feedback_score,
    AVG(st.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN seller_tiers st ON f.item_id = st.item_id
JOIN wx_bucket wb ON f.weather_category = wb.weather_category
GROUP BY st.feedback_score_tier, st.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        
[0m12:57:28.136343 [debug] [Thread-1 (]: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.137622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CED619D0>]}
[0m12:57:28.138329 [error] [Thread-1 (]: 8 of 9 ERROR creating sql table model `default`.`analytics_seller_performance` . [[31mERROR[0m in 0.10s]
[0m12:57:28.139409 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_seller_performance
[0m12:57:28.139815 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:28.140367 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_seller_performance' to be skipped because of status 'error'.  Reason: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74.
[0m12:57:28.140940 [info ] [Thread-1 (]: 9 of 9 START sql table model `default`.`analytics_weather_impact` .............. [RUN]
[0m12:57:28.141656 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_seller_performance, now model.ebay_weather_analytics.analytics_weather_impact)
[0m12:57:28.141979 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:28.144970 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:57:28.146526 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:28.150356 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
          )
        
        ...
[0m12:57:28.244831 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m12:57:28.248887 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

    select name, type from system.columns where table = 'analytics_weather_impact__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:28.298075 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:28.301393 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:57:28.303413 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

  
    
    
    
        
         


        insert into `default`.`analytics_weather_impact__dbt_backup`
        ("date", "weather_bucket", "listings", "unique_items", "avg_price", "avg_seller_feedback", "daily_market_share_percent", "avg_listings_7day")-- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
  ...
[0m12:57:28.381834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:57:28.382876 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
EXCHANGE TABLES `default`.`analytics_weather_impact__dbt_backup` AND `default`.`analytics_weather_impact` 
  
  ...
[0m12:57:28.427875 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:57:28.433379 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
drop table if exists `default`.`analytics_weather_impact__dbt_backup` 
  ...
[0m12:57:28.479541 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:28.483383 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0b7ee28-26cc-4d25-b9cc-569e78239a84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CED61B50>]}
[0m12:57:28.484745 [info ] [Thread-1 (]: 9 of 9 OK created sql table model `default`.`analytics_weather_impact` ......... [[32mOK[0m in 0.34s]
[0m12:57:28.486606 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:28.489926 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:57:28.490566 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:57:28.490986 [debug] [MainThread]: On list_: Close
[0m12:57:28.491716 [debug] [MainThread]: Connection 'list__default' was left open.
[0m12:57:28.492456 [debug] [MainThread]: On list__default: Close
[0m12:57:28.493470 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.analytics_weather_impact' was left open.
[0m12:57:28.494104 [debug] [MainThread]: On model.ebay_weather_analytics.analytics_weather_impact: Close
[0m12:57:28.494965 [info ] [MainThread]: 
[0m12:57:28.495911 [info ] [MainThread]: Finished running 9 table models in 0 hours 0 minutes and 3.77 seconds (3.77s).
[0m12:57:28.499393 [debug] [MainThread]: Command end result
[0m12:57:28.535857 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:57:28.541073 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:57:28.548781 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:57:28.549634 [info ] [MainThread]: 
[0m12:57:28.550331 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:57:28.550824 [info ] [MainThread]: 
[0m12:57:28.551264 [error] [MainThread]: [31mFailure in model dim_location (models\gold\dim_location.sql)[0m
[0m12:57:28.551795 [error] [MainThread]:   Database Error in model dim_location (models\gold\dim_location.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'status' 'region' 'region_group' 'country_code' 'state_code' 'city' 'country' 'postal_code' 'updated_at' 'location_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.552398 [info ] [MainThread]: 
[0m12:57:28.552923 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\dim_location.sql
[0m12:57:28.553640 [info ] [MainThread]: 
[0m12:57:28.554343 [error] [MainThread]: [31mFailure in model dim_product (models\gold\dim_product.sql)[0m
[0m12:57:28.555114 [error] [MainThread]:   Database Error in model dim_product (models\gold\dim_product.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'created_at' 'weather_sensitivity' 'product_category' 'status' 'weather_bucket' 'weather_category' 'product_type' 'updated_at' 'product_key'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.556114 [info ] [MainThread]: 
[0m12:57:28.556762 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\dim_product.sql
[0m12:57:28.557434 [info ] [MainThread]: 
[0m12:57:28.558182 [error] [MainThread]: [31mFailure in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)[0m
[0m12:57:28.558894 [error] [MainThread]:   Database Error in model gold_daily_listings_summary (models\gold\gold_daily_listings_summary.sql)
  Code: 47.
  DB::Exception: Missing columns: 'collection_timestamp' while processing: 'toYYYYMM(collection_timestamp)', required columns: 'collection_timestamp', available columns: 'avg_paid_shipping_cost.null' 'price_quality_issues' 'avg_title_length' 'paid_shipping_count' 'free_shipping_count' 'price_stddev' 'max_price' 'avg_paid_shipping_cost' 'avg_seller_feedback' 'avg_price' 'unique_items' 'min_price' 'country' 'postal_code' 'product_type' 'feedback_quality_issues' 'total_listings' 'weather_category' 'date'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.559758 [info ] [MainThread]: 
[0m12:57:28.560163 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\gold_daily_listings_summary.sql
[0m12:57:28.560690 [info ] [MainThread]: 
[0m12:57:28.561127 [error] [MainThread]: [31mFailure in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)[0m
[0m12:57:28.561541 [error] [MainThread]:   Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'paid_shipping_count' 'price_coefficient_variation' 'q3_price' 'price_range' 'q1_price' 'median_price' 'avg_seller_feedback' 'avg_price' 'price_stddev' 'listings' 'max_price' 'weather_bucket' 'min_price' 'product_type'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.562164 [info ] [MainThread]: 
[0m12:57:28.562852 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_pricing_behavior.sql
[0m12:57:28.563529 [info ] [MainThread]: 
[0m12:57:28.564248 [error] [MainThread]: [31mFailure in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)[0m
[0m12:57:28.565002 [error] [MainThread]:   Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 47.
  DB::Exception: Missing columns: 'date' while processing: 'toYYYYMM(date)', required columns: 'date', available columns: 'free_shipping_count' 'market_share_percent' 'avg_feedback_score' 'avg_feedback_percentage' 'avg_price' 'unique_items' 'price_quality_issues' 'weather_bucket' 'avg_title_length' 'feedback_score_tier' 'feedback_percentage_tier' 'listings'. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::TreeRewriterResult::collectUsedColumns(std::shared_ptr<DB::IAST> const&, bool, bool) @ 0x00000000186dceb0
  4. DB::TreeRewriter::analyze(std::shared_ptr<DB::IAST>&, DB::NamesAndTypesList const&, std::shared_ptr<DB::IStorage const>, std::shared_ptr<DB::StorageSnapshot> const&, bool, bool, bool, bool) const @ 0x00000000186e7c97
  5. DB::KeyDescription::getSortingKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>, std::optional<String> const&) @ 0x0000000018dd3bc1
  6. DB::KeyDescription::getKeyFromAST(std::shared_ptr<DB::IAST> const&, DB::ColumnsDescription const&, std::shared_ptr<DB::Context const>) @ 0x0000000018dd47fa
  7. DB::create(DB::StorageFactory::Arguments const&) @ 0x0000000019a5eb5d
  8. DB::StorageFactory::get(DB::ASTCreateQuery const&, String const&, std::shared_ptr<DB::Context>, std::shared_ptr<DB::Context>, DB::ColumnsDescription const&, DB::ConstraintsDescription const&, DB::LoadingStrictnessLevel, bool) const @ 0x0000000018e40d7b
  9. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fb075
  10. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
  11. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  14. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  15. DB::TCPHandler::run() @ 0x0000000019e4f119
  16. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  17. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  18. Poco::PooledThread::run() @ 0x000000001ef15b87
  19. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  20. ? @ 0x0000000000094ac3
  21. ? @ 0x0000000000125a74
[0m12:57:28.566198 [info ] [MainThread]: 
[0m12:57:28.566823 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_seller_performance.sql
[0m12:57:28.567156 [info ] [MainThread]: 
[0m12:57:28.567521 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=5 SKIP=0 NO-OP=0 TOTAL=9
[0m12:57:28.568384 [debug] [MainThread]: Command `dbt run` failed at 12:57:28.568285 after 5.38 seconds
[0m12:57:28.568681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CB51B6B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CEE7B8F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E6CEE7BB30>]}
[0m12:57:28.568948 [debug] [MainThread]: Flushing usage events
[0m12:57:29.489802 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:41.512574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204851827B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020485EE4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204864FFC50>]}


============================== 12:57:41.518638 | 377a0265-82a7-4225-b736-d6f395eb345a ==============================
[0m12:57:41.518638 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:57:41.519553 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'write_json': 'True', 'invocation_command': 'dbt run --select fact_listings dim_weather analytics_weather_impact gold_weather_impact_analysis', 'printer_width': '80', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m12:57:41.796679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048588C8A0>]}
[0m12:57:41.890740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020483C2F680>]}
[0m12:57:41.892527 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:57:42.139700 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:57:42.283362 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:57:42.284148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020487A5F750>]}
[0m12:57:44.200436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020487BC95E0>]}
[0m12:57:44.319053 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:57:44.323006 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:57:44.360058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020487F8A270>]}
[0m12:57:44.361185 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:57:44.361839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048815BD40>]}
[0m12:57:44.364188 [info ] [MainThread]: 
[0m12:57:44.364660 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:57:44.365240 [info ] [MainThread]: 
[0m12:57:44.365882 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:57:44.373040 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:57:44.384416 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:45.108944 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:57:45.154893 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:45.281638 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m12:57:45.301778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:45.845465 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:57:45.909170 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:45.911113 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m12:57:45.913368 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:57:45.963432 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:45.969557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048911A810>]}
[0m12:57:45.976073 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_weather
[0m12:57:45.976906 [info ] [Thread-1 (]: 1 of 4 START sql table model `default`.`dim_weather` ........................... [RUN]
[0m12:57:45.978413 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.dim_weather'
[0m12:57:45.978839 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_weather
[0m12:57:45.986283 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_weather"
[0m12:57:45.989126 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_weather
[0m12:57:46.048605 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:57:46.548969 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

            

    
        create table `default`.`dim_weather__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
          )
        
        ...
[0m12:57:46.605359 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:46.622909 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

    select name, type from system.columns where table = 'dim_weather__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:46.670213 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:46.674323 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_weather"
[0m12:57:46.676043 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */

  
    
    
    
        
         


        insert into `default`.`dim_weather__dbt_backup`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Weather
-- Weather dimension with daily aggregations


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        MIN(temperature_2m_c) as min_temperature,
        MAX(temperature_2m_c) as max_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        AVG(relative_humidity_2m_percent) as avg_humidity,
        AVG(cloudcover_percent) as avg_cloudcover,
        MAX(weather_code_wmo_code) as weather_code
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
)

SELECT 
    -- Surrogate Key
    cityHash64(date) as weather_key,
    
    -- Natural Key
    date,
    
    -- Weather Bucket
    CASE 
        WHEN avg_temperature >= 32 THEN 'Extreme Heat'
        WHEN avg_temperature <= -5 THEN 'Extreme Cold'
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'Normal'
    END AS weather_bucket,
    
    -- Temperature attributes
    avg_temperature,
    min_temperature,
    max_temperature,
    CASE 
        WHEN avg_temperature >= 30 THEN 'Hot'
        WHEN avg_temperature >= 20 THEN 'Warm'
        WHEN avg_temperature >= 10 THEN 'Mild'
        WHEN avg_temperature >= 0 THEN 'Cool'
        ELSE 'Cold'
    END AS temperature_category,
    
    -- Precipitation attributes
    total_rain,
    CASE 
        WHEN total_rain > 10 THEN 'Heavy Rain'
        WHEN total_rain > 5 THEN 'Moderate Rain'
        WHEN total_rain > 0 THEN 'Light Rain'
        ELSE 'No Rain'
    END AS rain_category,
    
    -- Other weather attributes
    total_sunshine,
    avg_wind_speed,
    avg_humidity,
    avg_cloudcover,
    weather_code,
    
    -- Seasonal attributes
    CASE 
        WHEN EXTRACT(MONTH FROM date) IN (12, 1, 2) THEN 'Winter'
        WHEN EXTRACT(MONTH FROM date) IN (3, 4, 5) THEN 'Spring'
        WHEN EXTRACT(MONTH FROM date) IN (6, 7, 8) THEN 'Summer'
        ELSE 'Fall'
    END AS season,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM weather_daily
  ...
[0m12:57:46.736739 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:46.741643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */
EXCHANGE TABLES `default`.`dim_weather__dbt_backup` AND `default`.`dim_weather` 
  
  ...
[0m12:57:46.789710 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:46.813760 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_weather: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_weather"} */
drop table if exists `default`.`dim_weather__dbt_backup` 
  ...
[0m12:57:46.861010 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:46.864656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020489126990>]}
[0m12:57:46.865246 [info ] [Thread-1 (]: 1 of 4 OK created sql table model `default`.`dim_weather` ...................... [[32mOK[0m in 0.89s]
[0m12:57:46.866306 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_weather
[0m12:57:46.866864 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.fact_listings
[0m12:57:46.867632 [info ] [Thread-1 (]: 2 of 4 START sql table model `default`.`fact_listings` ......................... [RUN]
[0m12:57:46.868252 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_weather, now model.ebay_weather_analytics.fact_listings)
[0m12:57:46.868691 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.fact_listings
[0m12:57:46.873082 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.fact_listings"
[0m12:57:46.874010 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.fact_listings
[0m12:57:46.877576 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

            

    
        create table `default`.`fact_listings__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
          )
        
        ...
[0m12:57:46.941757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:46.944925 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

    select name, type from system.columns where table = 'fact_listings__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:46.992369 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:46.996273 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.fact_listings"
[0m12:57:46.997899 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

  
    
    
    
        
         


        insert into `default`.`fact_listings__dbt_backup`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")-- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (will be replaced with dimension keys)
    product_type,
    postal_code,
    weather_category,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  ...
[0m12:57:47.052622 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.053831 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
EXCHANGE TABLES `default`.`fact_listings__dbt_backup` AND `default`.`fact_listings` 
  
  ...
[0m12:57:47.101505 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.108119 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
drop table if exists `default`.`fact_listings__dbt_backup` 
  ...
[0m12:57:47.154100 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.157141 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048A05E8F0>]}
[0m12:57:47.157923 [info ] [Thread-1 (]: 2 of 4 OK created sql table model `default`.`fact_listings` .................... [[32mOK[0m in 0.29s]
[0m12:57:47.159110 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.fact_listings
[0m12:57:47.159862 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:47.161154 [info ] [Thread-1 (]: 3 of 4 START sql table model `default`.`gold_weather_impact_analysis` .......... [RUN]
[0m12:57:47.162213 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.fact_listings, now model.ebay_weather_analytics.gold_weather_impact_analysis)
[0m12:57:47.162722 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:47.166803 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.gold_weather_impact_analysis"
[0m12:57:47.167971 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:47.171872 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

            

    
        create table `default`.`gold_weather_impact_analysis__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket, product_type))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
            WHEN rain_mm > 10 THEN 'Heavy Rain'
            WHEN rain_mm > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
          )
        
        ...
[0m12:57:47.231717 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:47.235931 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

    select name, type from system.columns where table = 'gold_weather_impact_analysis__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:47.283299 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.286400 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.gold_weather_impact_analysis"
[0m12:57:47.288330 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */

  
    
    
    
        
         


        insert into `default`.`gold_weather_impact_analysis__dbt_backup`
        ("date", "weather_bucket", "avg_temperature", "total_rain", "total_sunshine", "avg_wind_speed", "weather_category", "product_type", "listings_count", "avg_price", "avg_seller_feedback", "weather_demand_alignment")-- Gold: Weather Impact Analysis


WITH weather_daily AS (
    SELECT 
        toDate(time) as date,
        AVG(temperature_2m_c) as avg_temperature,
        SUM(rain_mm) as total_rain,
        SUM(sunshine_duration_s) as total_sunshine,
        AVG(windspeed_10m_kmh) as avg_wind_speed,
        MAX(CASE 
            WHEN temperature_2m_c >= 32 THEN 'Extreme Heat'
            WHEN temperature_2m_c <= -5 THEN 'Extreme Cold'
            WHEN rain_mm > 10 THEN 'Heavy Rain'
            WHEN rain_mm > 0 THEN 'Light Rain'
            ELSE 'Normal'
        END) as weather_bucket
    FROM `default`.`silver_weather_data`
    GROUP BY toDate(time)
),
ebay_daily AS (
    SELECT 
        toDate(collection_timestamp) as date,
        weather_category,
        product_type,
        COUNT(*) as listings_count,
        AVG(price) as avg_price,
        AVG(seller_feedback_percentage) as avg_seller_feedback
    FROM `default`.`silver_ebay_data`
    GROUP BY 
        toDate(collection_timestamp),
        weather_category,
        product_type
)
SELECT 
    e.date,
    w.weather_bucket,
    w.avg_temperature,
    w.total_rain,
    w.total_sunshine,
    w.avg_wind_speed,
    e.weather_category,
    e.product_type,
    e.listings_count,
    e.avg_price,
    e.avg_seller_feedback,
    -- Calculate weather impact metrics
    CASE 
        WHEN w.weather_bucket = 'Extreme Heat' AND e.weather_category = 'heat_products' THEN 1
        WHEN w.weather_bucket = 'Extreme Cold' AND e.weather_category = 'cold_products' THEN 1
        WHEN w.weather_bucket = 'Heavy Rain' AND e.weather_category = 'rain_products' THEN 1
        ELSE 0
    END as weather_demand_alignment
FROM ebay_daily e
LEFT JOIN weather_daily w ON e.date = w.date
  ...
[0m12:57:47.350600 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:47.352393 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */
EXCHANGE TABLES `default`.`gold_weather_impact_analysis__dbt_backup` AND `default`.`gold_weather_impact_analysis` 
  
  ...
[0m12:57:47.397387 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:57:47.401437 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.gold_weather_impact_analysis: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.gold_weather_impact_analysis"} */
drop table if exists `default`.`gold_weather_impact_analysis__dbt_backup` 
  ...
[0m12:57:47.449129 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.452699 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020489F266D0>]}
[0m12:57:47.453818 [info ] [Thread-1 (]: 3 of 4 OK created sql table model `default`.`gold_weather_impact_analysis` ..... [[32mOK[0m in 0.29s]
[0m12:57:47.454920 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.gold_weather_impact_analysis
[0m12:57:47.455791 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:47.456556 [info ] [Thread-1 (]: 4 of 4 START sql table model `default`.`analytics_weather_impact` .............. [RUN]
[0m12:57:47.457334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.gold_weather_impact_analysis, now model.ebay_weather_analytics.analytics_weather_impact)
[0m12:57:47.457669 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:47.461842 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:57:47.462995 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:47.465590 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
          )
        
        ...
[0m12:57:47.531176 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:57:47.534598 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

    select name, type from system.columns where table = 'analytics_weather_impact__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:57:47.583909 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.587710 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m12:57:47.590739 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

  
    
    
    
        
         


        insert into `default`.`analytics_weather_impact__dbt_backup`
        ("date", "weather_bucket", "listings", "unique_items", "avg_price", "avg_seller_feedback", "daily_market_share_percent", "avg_listings_7day")-- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        date_key AS date,
        weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT item_id) AS unique_items,
        AVG(price) AS avg_price,
        AVG(seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings`
    GROUP BY date_key, weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
  ...
[0m12:57:47.669547 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:57:47.670856 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
EXCHANGE TABLES `default`.`analytics_weather_impact__dbt_backup` AND `default`.`analytics_weather_impact` 
  
  ...
[0m12:57:47.716735 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.722151 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
drop table if exists `default`.`analytics_weather_impact__dbt_backup` 
  ...
[0m12:57:47.769138 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:57:47.772568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '377a0265-82a7-4225-b736-d6f395eb345a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048A4BC050>]}
[0m12:57:47.773898 [info ] [Thread-1 (]: 4 of 4 OK created sql table model `default`.`analytics_weather_impact` ......... [[32mOK[0m in 0.32s]
[0m12:57:47.775207 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_weather_impact
[0m12:57:47.778076 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:57:47.778635 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:57:47.779255 [debug] [MainThread]: On list_: Close
[0m12:57:47.780185 [debug] [MainThread]: Connection 'list__default' was left open.
[0m12:57:47.780770 [debug] [MainThread]: On list__default: Close
[0m12:57:47.781783 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.analytics_weather_impact' was left open.
[0m12:57:47.782593 [debug] [MainThread]: On model.ebay_weather_analytics.analytics_weather_impact: Close
[0m12:57:47.784207 [info ] [MainThread]: 
[0m12:57:47.785440 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 3.42 seconds (3.42s).
[0m12:57:47.788087 [debug] [MainThread]: Command end result
[0m12:57:47.817987 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:57:47.821450 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:57:47.827854 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:57:47.828279 [info ] [MainThread]: 
[0m12:57:47.828767 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:57:47.829140 [info ] [MainThread]: 
[0m12:57:47.829490 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m12:57:47.830372 [debug] [MainThread]: Command `dbt run` succeeded at 12:57:47.830262 after 6.51 seconds
[0m12:57:47.830685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204881390D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020485EDF470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002048786BEF0>]}
[0m12:57:47.830950 [debug] [MainThread]: Flushing usage events
[0m12:57:48.595527 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:59.987224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91B7327B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91C484050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91CA9FC50>]}


============================== 12:57:59.993407 | 02cb1692-6f7f-410a-8308-6b02fe9a6c53 ==============================
[0m12:57:59.993407 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:57:59.994448 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'write_json': 'True', 'use_colors': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'cache_selected_only': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt test --select fact_listings', 'printer_width': '80', 'target_path': 'None'}
[0m12:58:00.264142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91BE2C8A0>]}
[0m12:58:00.362852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91A1DF680>]}
[0m12:58:00.364343 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:58:00.595628 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:58:00.791145 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:58:00.791636 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:58:00.853383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91DFE0750>]}
[0m12:58:00.941998 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:58:00.944219 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:58:01.000717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91E348230>]}
[0m12:58:01.001482 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:58:01.002967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91E33D8D0>]}
[0m12:58:01.006575 [info ] [MainThread]: 
[0m12:58:01.008732 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:58:01.009657 [info ] [MainThread]: 
[0m12:58:01.010531 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:58:01.017082 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:58:01.033984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:58:01.714247 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:58:01.764420 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:01.944585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_dbt_test__audit)
[0m12:58:01.946035 [debug] [ThreadPool]: Creating schema "schema: "default_dbt_test__audit"
"
[0m12:58:01.958902 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "create__default_dbt_test__audit"} */
create database if not exists `default_dbt_test__audit`
        
  
        
  ...
[0m12:58:02.013351 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:02.018453 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m12:58:02.025724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:58:02.550384 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:58:02.651537 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.10 seconds
[0m12:58:02.653366 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m12:58:02.655004 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:58:02.708210 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:02.713295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02cb1692-6f7f-410a-8308-6b02fe9a6c53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91E403BA0>]}
[0m12:58:02.717138 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m12:58:02.717542 [info ] [Thread-1 (]: 1 of 9 START test not_null_fact_listings_collection_timestamp .................. [RUN]
[0m12:58:02.718914 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3'
[0m12:58:02.719272 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m12:58:02.732947 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"
[0m12:58:02.734542 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m12:58:02.750634 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
[0m12:58:02.773829 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:58:03.292702 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where collection_timestamp is null



  
  
          )
        
        ...
[0m12:58:03.381030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m12:58:03.402154 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

    select name, type from system.columns where table = 'not_null_fact_listings_collection_timestamp'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:03.448883 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.453585 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where collection_timestamp is null



  
  
  
    ...
[0m12:58:03.503546 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.510359 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"
[0m12:58:03.512910 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
    
    ) dbt_internal_test...
[0m12:58:03.561545 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.565835 [info ] [Thread-1 (]: 1 of 9 PASS not_null_fact_listings_collection_timestamp ........................ [[32mPASS[0m in 0.85s]
[0m12:58:03.566759 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m12:58:03.567254 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m12:58:03.567887 [info ] [Thread-1 (]: 2 of 9 START test not_null_fact_listings_date_key .............................. [RUN]
[0m12:58:03.568497 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3, now test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85)
[0m12:58:03.568762 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m12:58:03.574008 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"
[0m12:58:03.575845 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m12:58:03.577773 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_date_key`
[0m12:58:03.579634 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_date_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where date_key is null



  
  
          )
        
        ...
[0m12:58:03.636172 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:03.640753 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

    select name, type from system.columns where table = 'not_null_fact_listings_date_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:03.688762 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.690697 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_date_key`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where date_key is null



  
  
  
    ...
[0m12:58:03.744069 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.746386 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"
[0m12:58:03.747886 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_date_key`
    
    ) dbt_internal_test...
[0m12:58:03.797442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.800053 [info ] [Thread-1 (]: 2 of 9 PASS not_null_fact_listings_date_key .................................... [[32mPASS[0m in 0.23s]
[0m12:58:03.802172 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m12:58:03.802733 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m12:58:03.803572 [info ] [Thread-1 (]: 3 of 9 START test not_null_fact_listings_item_id ............................... [RUN]
[0m12:58:03.804411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85, now test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a)
[0m12:58:03.804891 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m12:58:03.809565 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"
[0m12:58:03.811359 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m12:58:03.813641 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_item_id`
[0m12:58:03.814942 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_item_id`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where item_id is null



  
  
          )
        
        ...
[0m12:58:03.874998 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:03.881568 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

    select name, type from system.columns where table = 'not_null_fact_listings_item_id'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:03.928922 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.931594 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_item_id`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where item_id is null



  
  
  
    ...
[0m12:58:03.982961 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:03.985835 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"
[0m12:58:03.988724 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_item_id`
    
    ) dbt_internal_test...
[0m12:58:04.044237 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.046992 [info ] [Thread-1 (]: 3 of 9 PASS not_null_fact_listings_item_id ..................................... [[32mPASS[0m in 0.24s]
[0m12:58:04.048514 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m12:58:04.049086 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m12:58:04.049707 [info ] [Thread-1 (]: 4 of 9 START test not_null_fact_listings_price ................................. [RUN]
[0m12:58:04.050958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a, now test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad)
[0m12:58:04.052147 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m12:58:04.058166 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"
[0m12:58:04.059262 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m12:58:04.061190 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_price`
[0m12:58:04.062199 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_price`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where price is null



  
  
          )
        
        ...
[0m12:58:04.114719 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.119589 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

    select name, type from system.columns where table = 'not_null_fact_listings_price'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:04.169541 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.172979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_price`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where price is null



  
  
  
    ...
[0m12:58:04.225315 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.229148 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"
[0m12:58:04.231997 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_price`
    
    ) dbt_internal_test...
[0m12:58:04.280683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.282648 [info ] [Thread-1 (]: 4 of 9 PASS not_null_fact_listings_price ....................................... [[32mPASS[0m in 0.23s]
[0m12:58:04.283725 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m12:58:04.284380 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e
[0m12:58:04.285011 [info ] [Thread-1 (]: 5 of 9 START test not_null_fact_listings_product_type .......................... [RUN]
[0m12:58:04.285832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad, now test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e)
[0m12:58:04.286333 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e
[0m12:58:04.291459 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"
[0m12:58:04.293131 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e
[0m12:58:04.295444 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_product_type`
[0m12:58:04.297200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_product_type`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where product_type is null



  
  
          )
        
        ...
[0m12:58:04.350197 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.355708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"} */

    select name, type from system.columns where table = 'not_null_fact_listings_product_type'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:04.404854 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.410122 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_product_type`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where product_type is null



  
  
  
    ...
[0m12:58:04.468903 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:04.471775 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"
[0m12:58:04.475461 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_product_type`
    
    ) dbt_internal_test...
[0m12:58:04.524926 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.526763 [info ] [Thread-1 (]: 5 of 9 PASS not_null_fact_listings_product_type ................................ [[32mPASS[0m in 0.24s]
[0m12:58:04.527640 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e
[0m12:58:04.528012 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb
[0m12:58:04.528404 [info ] [Thread-1 (]: 6 of 9 START test not_null_fact_listings_weather_category ...................... [RUN]
[0m12:58:04.529023 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_product_type.30b746cf1e, now test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb)
[0m12:58:04.529321 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb
[0m12:58:04.532533 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"
[0m12:58:04.533540 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb
[0m12:58:04.542151 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_weather_category`
[0m12:58:04.543684 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_weather_category`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where weather_category is null



  
  
          )
        
        ...
[0m12:58:04.602365 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:04.609987 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"} */

    select name, type from system.columns where table = 'not_null_fact_listings_weather_category'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:04.657455 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.659583 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_weather_category`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where weather_category is null



  
  
  
    ...
[0m12:58:04.711980 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.713341 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"
[0m12:58:04.714513 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_weather_category`
    
    ) dbt_internal_test...
[0m12:58:04.764969 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.766892 [info ] [Thread-1 (]: 6 of 9 PASS not_null_fact_listings_weather_category ............................ [[32mPASS[0m in 0.24s]
[0m12:58:04.768026 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb
[0m12:58:04.768639 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_fact_listings_not_null
[0m12:58:04.769155 [info ] [Thread-1 (]: 7 of 9 START test test_fact_listings_not_null .................................. [RUN]
[0m12:58:04.769970 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_weather_category.02aa62adbb, now test.ebay_weather_analytics.test_fact_listings_not_null)
[0m12:58:04.770426 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_fact_listings_not_null
[0m12:58:04.775018 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_fact_listings_not_null"
[0m12:58:04.776500 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_fact_listings_not_null
[0m12:58:04.778087 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_fact_listings_not_null`
[0m12:58:04.779077 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

            

    
        create table `default_dbt_test__audit`.`test_fact_listings_not_null`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Fact Listings - Not Null Critical Fields
-- Ensures critical fields are not null
SELECT *
FROM `default`.`fact_listings`
WHERE item_id IS NULL
   OR collection_timestamp IS NULL
   OR price IS NULL
   OR product_type IS NULL
   OR weather_category IS NULL
  
  
          )
        
        ...
[0m12:58:04.834881 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:04.842513 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

    select name, type from system.columns where table = 'test_fact_listings_not_null'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:04.894628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.896562 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_fact_listings_not_null`
        ("item_id", "product_type", "postal_code", "weather_category", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  -- Test: Fact Listings - Not Null Critical Fields
-- Ensures critical fields are not null
SELECT *
FROM `default`.`fact_listings`
WHERE item_id IS NULL
   OR collection_timestamp IS NULL
   OR price IS NULL
   OR product_type IS NULL
   OR weather_category IS NULL
  
  
  
    ...
[0m12:58:04.948130 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:04.950279 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_fact_listings_not_null"
[0m12:58:04.952691 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_fact_listings_not_null`
    
    ) dbt_internal_test...
[0m12:58:05.002367 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:05.005814 [info ] [Thread-1 (]: 7 of 9 PASS test_fact_listings_not_null ........................................ [[32mPASS[0m in 0.23s]
[0m12:58:05.007636 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_fact_listings_not_null
[0m12:58:05.008362 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m12:58:05.008914 [info ] [Thread-1 (]: 8 of 9 START test test_fact_listings_unique_item_id ............................ [RUN]
[0m12:58:05.009569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_fact_listings_not_null, now test.ebay_weather_analytics.test_fact_listings_unique_item_id)
[0m12:58:05.009958 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m12:58:05.012566 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_fact_listings_unique_item_id"
[0m12:58:05.013675 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m12:58:05.016175 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
[0m12:58:05.018583 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

            

    
        create table `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Fact Listings - Unique Item IDs
-- Ensures each item_id appears only once in the fact table
SELECT item_id
FROM `default`.`fact_listings`
GROUP BY item_id
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m12:58:05.078417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:05.084152 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

    select name, type from system.columns where table = 'test_fact_listings_unique_item_id'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:05.132639 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:05.134465 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
        ("item_id")
    
  -- Test: Fact Listings - Unique Item IDs
-- Ensures each item_id appears only once in the fact table
SELECT item_id
FROM `default`.`fact_listings`
GROUP BY item_id
HAVING COUNT(*) > 1
  
  
  
    ...
[0m12:58:05.194447 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:05.197065 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_fact_listings_unique_item_id"
[0m12:58:05.198762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
    
    ) dbt_internal_test...
[0m12:58:05.258565 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:05.261100 [error] [Thread-1 (]: 8 of 9 FAIL 113 test_fact_listings_unique_item_id .............................. [[31mFAIL 113[0m in 0.25s]
[0m12:58:05.262722 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m12:58:05.263227 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b
[0m12:58:05.263827 [info ] [Thread-1 (]: 9 of 9 START test unique_fact_listings_item_id ................................. [RUN]
[0m12:58:05.264890 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_fact_listings_unique_item_id, now test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b)
[0m12:58:05.265425 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b
[0m12:58:05.275575 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"
[0m12:58:05.277162 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b
[0m12:58:05.281160 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_fact_listings_item_id`
[0m12:58:05.283307 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"} */

            

    
        create table `default_dbt_test__audit`.`unique_fact_listings_item_id`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    item_id as unique_field,
    count(*) as n_records

from `default`.`fact_listings`
where item_id is not null
group by item_id
having count(*) > 1



  
  
          )
        
        ...
[0m12:58:05.354419 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:58:05.364617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"} */

    select name, type from system.columns where table = 'unique_fact_listings_item_id'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m12:58:05.416396 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:05.418876 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_fact_listings_item_id`
        ("unique_field", "n_records")
    
  
    
    

select
    item_id as unique_field,
    count(*) as n_records

from `default`.`fact_listings`
where item_id is not null
group by item_id
having count(*) > 1



  
  
  
    ...
[0m12:58:05.484332 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:05.486867 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"
[0m12:58:05.488739 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_fact_listings_item_id`
    
    ) dbt_internal_test...
[0m12:58:05.539111 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:05.542686 [error] [Thread-1 (]: 9 of 9 FAIL 113 unique_fact_listings_item_id ................................... [[31mFAIL 113[0m in 0.28s]
[0m12:58:05.544066 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b
[0m12:58:05.546927 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:58:05.547470 [debug] [MainThread]: Connection 'create__default_dbt_test__audit' was left open.
[0m12:58:05.547767 [debug] [MainThread]: On create__default_dbt_test__audit: Close
[0m12:58:05.548368 [debug] [MainThread]: Connection 'list__default' was left open.
[0m12:58:05.548802 [debug] [MainThread]: On list__default: Close
[0m12:58:05.549924 [debug] [MainThread]: Connection 'test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b' was left open.
[0m12:58:05.551195 [debug] [MainThread]: On test.ebay_weather_analytics.unique_fact_listings_item_id.b00874361b: Close
[0m12:58:05.552882 [info ] [MainThread]: 
[0m12:58:05.554599 [info ] [MainThread]: Finished running 9 data tests in 0 hours 0 minutes and 4.54 seconds (4.54s).
[0m12:58:05.560115 [debug] [MainThread]: Command end result
[0m12:58:05.587346 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:58:05.592092 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:58:05.601704 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:58:05.602266 [info ] [MainThread]: 
[0m12:58:05.603051 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m12:58:05.603992 [info ] [MainThread]: 
[0m12:58:05.604856 [error] [MainThread]: [31mFailure in test test_fact_listings_unique_item_id (tests\test_fact_listings_unique_item_id.sql)[0m
[0m12:58:05.605589 [error] [MainThread]:   Got 113 results, configured to fail if != 0
[0m12:58:05.606500 [info ] [MainThread]: 
[0m12:58:05.607185 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\tests\test_fact_listings_unique_item_id.sql
[0m12:58:05.607602 [info ] [MainThread]: 
[0m12:58:05.608196 [info ] [MainThread]:   See test failures:
  ---------------------------------------------------------------------------
  select * from `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
  ---------------------------------------------------------------------------
[0m12:58:05.608687 [info ] [MainThread]: 
[0m12:58:05.609114 [error] [MainThread]: [31mFailure in test unique_fact_listings_item_id (models\schema.yml)[0m
[0m12:58:05.609612 [error] [MainThread]:   Got 113 results, configured to fail if != 0
[0m12:58:05.610104 [info ] [MainThread]: 
[0m12:58:05.610811 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\schema.yml\unique_fact_listings_item_id.sql
[0m12:58:05.611291 [info ] [MainThread]: 
[0m12:58:05.611759 [info ] [MainThread]:   See test failures:
  ----------------------------------------------------------------------
  select * from `default_dbt_test__audit`.`unique_fact_listings_item_id`
  ----------------------------------------------------------------------
[0m12:58:05.612292 [info ] [MainThread]: 
[0m12:58:05.612843 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=9
[0m12:58:05.614145 [debug] [MainThread]: Command `dbt test` failed at 12:58:05.613980 after 5.81 seconds
[0m12:58:05.614626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91C936BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91F30BB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91F30BE30>]}
[0m12:58:05.615051 [debug] [MainThread]: Flushing usage events
[0m12:58:09.666730 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:58:23.610817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174F9BD67B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FA934050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FAF4FC50>]}


============================== 12:58:23.616107 | ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0 ==============================
[0m12:58:23.616107 [info ] [MainThread]: Running with dbt=1.10.13
[0m12:58:23.617024 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'invocation_command': 'dbt run --select dim_product dim_location', 'no_print': 'None', 'printer_width': '80', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m12:58:23.863719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FA2DC8A0>]}
[0m12:58:23.957021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174F868F680>]}
[0m12:58:23.958864 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m12:58:24.154611 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m12:58:24.323075 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:58:24.323453 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:58:24.379425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FC423D50>]}
[0m12:58:24.487937 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:58:24.493539 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:58:24.529749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174F9CA8C80>]}
[0m12:58:24.530224 [info ] [MainThread]: Found 11 models, 28 data tests, 2 sources, 485 macros
[0m12:58:24.530827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FB0C4670>]}
[0m12:58:24.532634 [info ] [MainThread]: 
[0m12:58:24.533145 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:58:24.533769 [info ] [MainThread]: 
[0m12:58:24.535009 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:58:24.540202 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:58:24.549479 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:58:25.209281 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:58:25.262204 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:25.375624 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m12:58:25.385563 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:58:25.900827 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m12:58:25.951893 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:25.953609 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default, now list__default_dbt_test__audit)
[0m12:58:25.958025 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m12:58:26.109977 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m12:58:26.115667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FE33B6C0>]}
[0m12:58:26.122502 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_location
[0m12:58:26.123404 [info ] [Thread-1 (]: 1 of 2 START sql table model `default`.`dim_location` .......................... [RUN]
[0m12:58:26.124424 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.dim_location'
[0m12:58:26.124904 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_location
[0m12:58:26.136082 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_location"
[0m12:58:26.137738 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_location
[0m12:58:26.161429 [debug] [Thread-1 (]: Creating new relation dim_location
[0m12:58:26.189011 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:58:26.712930 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_location: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

            

    
        create table `default`.`dim_location`
        
  
        
  engine = MergeTree()
        order by (location_key)
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
          )
        
        ...
[0m12:58:26.775726 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:26.794843 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_location: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

    select name, type from system.columns where table = 'dim_location'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:58:26.843978 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:26.849957 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_location"
[0m12:58:26.853562 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_location: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_location"} */

  
    
    
    
        
         


        insert into `default`.`dim_location`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Locations
-- Location dimension with East Coast mapping


WITH location_data AS (
    SELECT DISTINCT
        postal_code,
        country,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' THEN 'New York'
            WHEN postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'New York'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'Miami'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'Boston'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'Philadelphia'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'Washington DC'
            ELSE 'Other East Coast'
        END AS city,
        CASE 
            WHEN postal_code LIKE '100%' OR postal_code LIKE '101%' OR postal_code LIKE '102%' OR postal_code LIKE '103%' OR postal_code LIKE '104%' OR
                 postal_code LIKE '111%' OR postal_code LIKE '112%' OR postal_code LIKE '113%' OR postal_code LIKE '114%' THEN 'NY'
            WHEN postal_code LIKE '331%' OR postal_code LIKE '332%' THEN 'FL'
            WHEN postal_code LIKE '021%' OR postal_code LIKE '022%' THEN 'MA'
            WHEN postal_code LIKE '191%' OR postal_code LIKE '192%' THEN 'PA'
            WHEN postal_code LIKE '200%' OR postal_code LIKE '202%' THEN 'DC'
            ELSE 'EC'
        END AS state_code
    FROM `default`.`silver_ebay_data`
    WHERE postal_code IS NOT NULL
      AND postal_code != ''
)

SELECT 
    -- Surrogate Key
    cityHash64(postal_code, country) as location_key,
    
    -- Natural Keys
    postal_code,
    country,
    
    -- Attributes
    city,
    state_code,
    'US' as country_code,
    'East Coast' as region,
    
    -- Geographic attributes
    CASE 
        WHEN state_code IN ('NY', 'NJ', 'CT', 'MA', 'RI', 'VT', 'NH', 'ME') THEN 'Northeast'
        WHEN state_code IN ('PA', 'DE', 'MD', 'DC', 'VA', 'WV') THEN 'Mid-Atlantic'
        WHEN state_code IN ('NC', 'SC', 'GA', 'FL') THEN 'Southeast'
        ELSE 'Other'
    END AS region_group,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM location_data
  ...
[0m12:58:26.910233 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:58:26.929835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FB066F90>]}
[0m12:58:26.930434 [info ] [Thread-1 (]: 1 of 2 OK created sql table model `default`.`dim_location` ..................... [[32mOK[0m in 0.81s]
[0m12:58:26.931690 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_location
[0m12:58:26.932372 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_product
[0m12:58:26.933243 [info ] [Thread-1 (]: 2 of 2 START sql table model `default`.`dim_product` ........................... [RUN]
[0m12:58:26.934243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.dim_location, now model.ebay_weather_analytics.dim_product)
[0m12:58:26.934948 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_product
[0m12:58:26.939315 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_product"
[0m12:58:26.940717 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_product
[0m12:58:26.943049 [debug] [Thread-1 (]: Creating new relation dim_product
[0m12:58:26.944175 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

            

    
        create table `default`.`dim_product`
        
  
        
  engine = MergeTree()
        order by (product_key)
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
          )
        
        ...
[0m12:58:27.016882 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m12:58:27.020986 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

    select name, type from system.columns where table = 'dim_product'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m12:58:27.073122 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:27.077021 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_product"
[0m12:58:27.078961 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_product: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_product"} */

  
    
    
    
        
         


        insert into `default`.`dim_product`
        ("product_key", "product_type", "weather_category", "weather_bucket", "product_category", "weather_sensitivity", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Products
-- Product dimension with weather category mapping


WITH product_data AS (
    SELECT DISTINCT
        product_type,
        weather_category,
        CASE 
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM `default`.`silver_ebay_data`
    WHERE product_type IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(product_type, weather_category) as product_key,
    
    -- Natural Keys
    product_type,
    weather_category,
    weather_bucket,
    
    -- Attributes
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket') THEN 'Rain Protection'
        WHEN product_type IN ('air conditioner', 'sunscreen') THEN 'Heat Protection'
        WHEN product_type IN ('winter coat', 'thermal gloves') THEN 'Cold Protection'
        WHEN product_type IN ('beach towel', 'snow shovel', 'outdoor furniture') THEN 'Seasonal'
        ELSE 'Other'
    END AS product_category,
    
    CASE 
        WHEN product_type IN ('umbrella', 'rain jacket', 'air conditioner', 'sunscreen', 'winter coat', 'thermal gloves') THEN 'Weather-Sensitive'
        ELSE 'General'
    END AS weather_sensitivity,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM product_data
  ...
[0m12:58:27.133904 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:58:27.137547 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebb224a8-6fcb-4fb4-92bc-b5d86cac87a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FE568470>]}
[0m12:58:27.138094 [info ] [Thread-1 (]: 2 of 2 OK created sql table model `default`.`dim_product` ...................... [[32mOK[0m in 0.20s]
[0m12:58:27.138641 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_product
[0m12:58:27.139706 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:58:27.139917 [debug] [MainThread]: Connection 'list_' was left open.
[0m12:58:27.140133 [debug] [MainThread]: On list_: Close
[0m12:58:27.140508 [debug] [MainThread]: Connection 'list__default_dbt_test__audit' was left open.
[0m12:58:27.140690 [debug] [MainThread]: On list__default_dbt_test__audit: Close
[0m12:58:27.140953 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.dim_product' was left open.
[0m12:58:27.141624 [debug] [MainThread]: On model.ebay_weather_analytics.dim_product: Close
[0m12:58:27.142839 [info ] [MainThread]: 
[0m12:58:27.143741 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 2.61 seconds (2.61s).
[0m12:58:27.144829 [debug] [MainThread]: Command end result
[0m12:58:27.174453 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m12:58:27.177327 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m12:58:27.182655 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m12:58:27.183283 [info ] [MainThread]: 
[0m12:58:27.184347 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:58:27.185218 [info ] [MainThread]: 
[0m12:58:27.186616 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:58:27.189141 [debug] [MainThread]: Command `dbt run` succeeded at 12:58:27.188824 after 3.75 seconds
[0m12:58:27.189980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FC1B28F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FC76B530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174FC526050>]}
[0m12:58:27.191927 [debug] [MainThread]: Flushing usage events
[0m12:58:27.953880 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:06:24.177891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB975227B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB98274050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9888FC50>]}


============================== 13:06:24.184531 | ca256278-ba3e-4dda-a6cb-34d9dd10bb34 ==============================
[0m13:06:24.184531 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:06:24.185249 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'log_format': 'default', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'invocation_command': 'dbt run --select dim_seller', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m13:06:24.422891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB97C1C8A0>]}
[0m13:06:24.503294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB95FCF680>]}
[0m13:06:24.504884 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:06:24.686211 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:06:24.831919 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 5 files changed.
[0m13:06:24.832451 [debug] [MainThread]: Partial parsing: added file: ebay_weather_analytics://models\gold\dim_seller.sql
[0m13:06:24.832839 [debug] [MainThread]: Partial parsing: added file: ebay_weather_analytics://tests\test_dim_seller_unique_key.sql
[0m13:06:24.833520 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\schema.yml
[0m13:06:24.833742 [debug] [MainThread]: Partial parsing: deleted file: ebay_weather_analytics://models\gold\gold_daily_listings_summary.sql
[0m13:06:24.833910 [debug] [MainThread]: Partial parsing: deleted file: ebay_weather_analytics://models\gold\gold_weather_impact_analysis.sql
[0m13:06:24.834160 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_seller_performance.sql
[0m13:06:24.834417 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_pricing_behavior.sql
[0m13:06:24.834664 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\fact_listings.sql
[0m13:06:24.834901 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_weather_impact.sql
[0m13:06:25.665999 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ebay_weather_analytics.gold.gold_weather_impact_analysis
- models.ebay_weather_analytics.gold.gold_daily_listings_summary
[0m13:06:25.690633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB99D62350>]}
[0m13:06:25.858628 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:06:25.862115 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:06:25.904331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB99E22300>]}
[0m13:06:25.904768 [info ] [MainThread]: Found 10 models, 35 data tests, 2 sources, 485 macros
[0m13:06:25.905283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9A246510>]}
[0m13:06:25.907414 [info ] [MainThread]: 
[0m13:06:25.908003 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:06:25.908374 [info ] [MainThread]: 
[0m13:06:25.908869 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:06:25.909824 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:06:25.918324 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:26.604514 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:06:26.654707 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:26.718101 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m13:06:26.722514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:27.214836 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m13:06:27.265167 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:27.268151 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m13:06:27.276161 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m13:06:27.327878 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:27.332620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9BF91D90>]}
[0m13:06:27.339778 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.dim_seller
[0m13:06:27.341142 [info ] [Thread-1 (]: 1 of 1 START sql table model `default`.`dim_seller` ............................ [RUN]
[0m13:06:27.342445 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.dim_seller'
[0m13:06:27.343168 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.dim_seller
[0m13:06:27.362319 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.dim_seller"
[0m13:06:27.367227 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.dim_seller
[0m13:06:27.396445 [debug] [Thread-1 (]: Creating new relation dim_seller
[0m13:06:27.440575 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:06:27.951477 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_seller: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_seller"} */

            

    
        create table `default`.`dim_seller`
        
  
        
  engine = MergeTree()
        order by (seller_key)
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Dimension Table - Sellers
-- Seller dimension with performance tiers


WITH seller_data AS (
    SELECT DISTINCT
        seller_feedback_score,
        seller_feedback_percentage,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier
    FROM `default`.`silver_ebay_data`
    WHERE seller_feedback_score IS NOT NULL
      AND seller_feedback_percentage IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(seller_feedback_score, seller_feedback_percentage) as seller_key,
    
    -- Natural Keys
    seller_feedback_score,
    seller_feedback_percentage,
    
    -- Attributes
    feedback_score_tier,
    feedback_percentage_tier,
    
    -- Seller classification
    CASE 
        WHEN feedback_score_tier = 'Very High (5000+)' AND feedback_percentage_tier = 'Excellent (99%+)' THEN 'Premium'
        WHEN feedback_score_tier IN ('High (1000-4999)', 'Very High (5000+)') AND feedback_percentage_tier IN ('Good (97-99%)', 'Excellent (99%+)') THEN 'High Quality'
        WHEN feedback_score_tier IN ('Medium (100-999)', 'High (1000-4999)') AND feedback_percentage_tier IN ('Fair (95-97%)', 'Good (97-99%)') THEN 'Standard'
        ELSE 'Basic'
    END AS seller_tier,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM seller_data
          )
        
        ...
[0m13:06:28.012309 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:06:28.027904 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_seller: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_seller"} */

    select name, type from system.columns where table = 'dim_seller'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m13:06:28.077334 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:28.082411 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.dim_seller"
[0m13:06:28.084205 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.dim_seller: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.dim_seller"} */

  
    
    
    
        
         


        insert into `default`.`dim_seller`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")-- Gold Layer: Dimension Table - Sellers
-- Seller dimension with performance tiers


WITH seller_data AS (
    SELECT DISTINCT
        seller_feedback_score,
        seller_feedback_percentage,
        CASE
            WHEN seller_feedback_score < 100 THEN 'Low (0-99)'
            WHEN seller_feedback_score < 1000 THEN 'Medium (100-999)'
            WHEN seller_feedback_score < 5000 THEN 'High (1000-4999)'
            ELSE 'Very High (5000+)'
        END AS feedback_score_tier,
        CASE
            WHEN seller_feedback_percentage < 95 THEN 'Poor (<95%)'
            WHEN seller_feedback_percentage < 97 THEN 'Fair (95-97%)'
            WHEN seller_feedback_percentage < 99 THEN 'Good (97-99%)'
            ELSE 'Excellent (99%+)'
        END AS feedback_percentage_tier
    FROM `default`.`silver_ebay_data`
    WHERE seller_feedback_score IS NOT NULL
      AND seller_feedback_percentage IS NOT NULL
)

SELECT 
    -- Surrogate Key
    cityHash64(seller_feedback_score, seller_feedback_percentage) as seller_key,
    
    -- Natural Keys
    seller_feedback_score,
    seller_feedback_percentage,
    
    -- Attributes
    feedback_score_tier,
    feedback_percentage_tier,
    
    -- Seller classification
    CASE 
        WHEN feedback_score_tier = 'Very High (5000+)' AND feedback_percentage_tier = 'Excellent (99%+)' THEN 'Premium'
        WHEN feedback_score_tier IN ('High (1000-4999)', 'Very High (5000+)') AND feedback_percentage_tier IN ('Good (97-99%)', 'Excellent (99%+)') THEN 'High Quality'
        WHEN feedback_score_tier IN ('Medium (100-999)', 'High (1000-4999)') AND feedback_percentage_tier IN ('Fair (95-97%)', 'Good (97-99%)') THEN 'Standard'
        ELSE 'Basic'
    END AS seller_tier,
    
    -- Metadata
    'active' as status,
    now() as created_at,
    now() as updated_at
    
FROM seller_data
  ...
[0m13:06:28.141252 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:06:28.160550 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca256278-ba3e-4dda-a6cb-34d9dd10bb34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9BFD4F50>]}
[0m13:06:28.161839 [info ] [Thread-1 (]: 1 of 1 OK created sql table model `default`.`dim_seller` ....................... [[32mOK[0m in 0.82s]
[0m13:06:28.164203 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.dim_seller
[0m13:06:28.166866 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:06:28.167776 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:06:28.168159 [debug] [MainThread]: On list_: Close
[0m13:06:28.168930 [debug] [MainThread]: Connection 'list__default' was left open.
[0m13:06:28.169194 [debug] [MainThread]: On list__default: Close
[0m13:06:28.170356 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.dim_seller' was left open.
[0m13:06:28.170900 [debug] [MainThread]: On model.ebay_weather_analytics.dim_seller: Close
[0m13:06:28.171502 [info ] [MainThread]: 
[0m13:06:28.172171 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.26 seconds (2.26s).
[0m13:06:28.173835 [debug] [MainThread]: Command end result
[0m13:06:28.200356 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:06:28.203101 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:06:28.208423 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m13:06:28.208996 [info ] [MainThread]: 
[0m13:06:28.211775 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:06:28.214272 [info ] [MainThread]: 
[0m13:06:28.215010 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m13:06:28.218578 [debug] [MainThread]: Command `dbt run` succeeded at 13:06:28.218208 after 4.35 seconds
[0m13:06:28.219067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9B2C7CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9C1C6CB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BB9C1C7B10>]}
[0m13:06:28.219535 [debug] [MainThread]: Flushing usage events
[0m13:06:29.012379 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:06:37.665338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D2FC27B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D3D24050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D433FC50>]}


============================== 13:06:37.671951 | 1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6 ==============================
[0m13:06:37.671951 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:06:37.672678 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'use_colors': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'write_json': 'True', 'log_format': 'default', 'warn_error': 'None', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'fail_fast': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select fact_listings', 'printer_width': '80', 'target_path': 'None'}
[0m13:06:37.903105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D36CC8A0>]}
[0m13:06:37.984221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D1A6F680>]}
[0m13:06:37.985947 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:06:38.169968 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:06:38.393654 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:06:38.394063 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:06:38.401218 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ebay_weather_analytics.gold.gold_weather_impact_analysis
- models.ebay_weather_analytics.gold.gold_daily_listings_summary
[0m13:06:38.449254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D58DFD50>]}
[0m13:06:38.569008 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:06:38.571262 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:06:38.694105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D0257980>]}
[0m13:06:38.694997 [info ] [MainThread]: Found 10 models, 35 data tests, 2 sources, 485 macros
[0m13:06:38.696228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D5485B70>]}
[0m13:06:38.700742 [info ] [MainThread]: 
[0m13:06:38.702112 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:06:38.702908 [info ] [MainThread]: 
[0m13:06:38.704183 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:06:38.706322 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:06:38.722336 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:39.404176 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:06:39.452711 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:39.516747 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m13:06:39.522639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:40.009069 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m13:06:40.065109 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:06:40.068755 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default, now list__default_dbt_test__audit)
[0m13:06:40.073958 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m13:06:40.123544 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:40.127243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D7868A10>]}
[0m13:06:40.131737 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.fact_listings
[0m13:06:40.132392 [info ] [Thread-1 (]: 1 of 1 START sql table model `default`.`fact_listings` ......................... [RUN]
[0m13:06:40.133208 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.fact_listings'
[0m13:06:40.133499 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.fact_listings
[0m13:06:40.139706 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.fact_listings"
[0m13:06:40.141120 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.fact_listings
[0m13:06:40.191804 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:06:40.729875 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

            

    
        create table `default`.`fact_listings__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((collection_timestamp, item_id))
        
        partition by (toYYYYMM(collection_timestamp))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (surrogate keys from dimensions)
    cityHash64(product_type, weather_category) as product_key,
    cityHash64(postal_code, country) as location_key,
    cityHash64(seller_feedback_score, seller_feedback_percentage) as seller_key,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  AND seller_feedback_score IS NOT NULL
  AND seller_feedback_percentage IS NOT NULL
          )
        
        ...
[0m13:06:40.787075 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:06:40.801588 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

    select name, type from system.columns where table = 'fact_listings__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m13:06:40.852043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:40.859914 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.fact_listings"
[0m13:06:40.861438 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */

  
    
    
    
        
         


        insert into `default`.`fact_listings__dbt_backup`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")-- Gold Layer: Fact Table - eBay Listings
-- This is the main fact table that connects all dimensions


SELECT 
    -- Primary Key
    item_id,
    
    -- Foreign Keys (surrogate keys from dimensions)
    cityHash64(product_type, weather_category) as product_key,
    cityHash64(postal_code, country) as location_key,
    cityHash64(seller_feedback_score, seller_feedback_percentage) as seller_key,
    
    -- Date Dimension
    collection_timestamp,
    toDate(collection_timestamp) as date_key,
    
    -- Measures
    price,
    shipping_cost,
    seller_feedback_percentage,
    seller_feedback_score,
    title_length,
    
    -- Flags
    free_shipping,
    price_quality_flag,
    feedback_quality_flag,
    
    -- Metadata
    condition,
    buying_options,
    marketplace_id,
    data_source,
    created_at,
    updated_at
    
FROM `default`.`silver_ebay_data`
WHERE collection_timestamp IS NOT NULL
  AND item_id IS NOT NULL
  AND price > 0
  AND seller_feedback_score IS NOT NULL
  AND seller_feedback_percentage IS NOT NULL
  ...
[0m13:06:40.921383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:06:40.926208 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
EXCHANGE TABLES `default`.`fact_listings__dbt_backup` AND `default`.`fact_listings` 
  
  ...
[0m13:06:40.972422 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:40.994433 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.fact_listings: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.fact_listings"} */
drop table if exists `default`.`fact_listings__dbt_backup` 
  ...
[0m13:06:41.040371 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:06:41.046507 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c6f0ad3-7d69-41e1-a8f8-02c51e5b8ab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D7A60DD0>]}
[0m13:06:41.048512 [info ] [Thread-1 (]: 1 of 1 OK created sql table model `default`.`fact_listings` .................... [[32mOK[0m in 0.91s]
[0m13:06:41.050210 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.fact_listings
[0m13:06:41.052422 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:06:41.052819 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:06:41.053101 [debug] [MainThread]: On list_: Close
[0m13:06:41.053792 [debug] [MainThread]: Connection 'list__default_dbt_test__audit' was left open.
[0m13:06:41.054685 [debug] [MainThread]: On list__default_dbt_test__audit: Close
[0m13:06:41.055462 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.fact_listings' was left open.
[0m13:06:41.056313 [debug] [MainThread]: On model.ebay_weather_analytics.fact_listings: Close
[0m13:06:41.057158 [info ] [MainThread]: 
[0m13:06:41.058131 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 2.35 seconds (2.35s).
[0m13:06:41.060121 [debug] [MainThread]: Command end result
[0m13:06:41.091128 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:06:41.094287 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:06:41.099938 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m13:06:41.100293 [info ] [MainThread]: 
[0m13:06:41.100861 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:06:41.101604 [info ] [MainThread]: 
[0m13:06:41.101971 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m13:06:41.103286 [debug] [MainThread]: Command `dbt run` succeeded at 13:06:41.103163 after 3.61 seconds
[0m13:06:41.103594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D5BBBC20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D78F1C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190D78F1EF0>]}
[0m13:06:41.103846 [debug] [MainThread]: Flushing usage events
[0m13:06:41.965233 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:01.775849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A55A027B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A56764050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A56D7FC50>]}


============================== 13:07:01.783374 | 6da00fe6-b073-4f86-86c2-5a64b919df02 ==============================
[0m13:07:01.783374 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:07:01.784267 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'no_print': 'None', 'target_path': 'None', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'printer_width': '80', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select analytics_pricing_behavior analytics_seller_performance analytics_weather_impact', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m13:07:02.017605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A5610C8A0>]}
[0m13:07:02.098537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A544AF680>]}
[0m13:07:02.100103 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:07:02.272897 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:07:02.407980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:07:02.408312 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:07:02.418431 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ebay_weather_analytics.gold.gold_weather_impact_analysis
- models.ebay_weather_analytics.gold.gold_daily_listings_summary
[0m13:07:02.465939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A58253D50>]}
[0m13:07:02.557329 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:02.559321 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:02.685275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A52C97980>]}
[0m13:07:02.686181 [info ] [MainThread]: Found 10 models, 35 data tests, 2 sources, 485 macros
[0m13:07:02.688114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A56EF9B70>]}
[0m13:07:02.692113 [info ] [MainThread]: 
[0m13:07:02.692973 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:07:02.693633 [info ] [MainThread]: 
[0m13:07:02.695186 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:07:02.701724 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:07:02.711964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:03.385340 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:07:03.434961 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:03.489327 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m13:07:03.493500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:04.020386 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m13:07:04.069445 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:04.071772 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default, now list__default_dbt_test__audit)
[0m13:07:04.075641 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m13:07:04.122778 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:04.125220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A582B0940>]}
[0m13:07:04.129328 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:04.129956 [info ] [Thread-1 (]: 1 of 3 START sql table model `default`.`analytics_pricing_behavior` ............ [RUN]
[0m13:07:04.131213 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.analytics_pricing_behavior'
[0m13:07:04.131792 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:04.139539 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_pricing_behavior"
[0m13:07:04.140539 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:04.159751 [debug] [Thread-1 (]: Creating new relation analytics_pricing_behavior
[0m13:07:04.188957 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:07:04.689581 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    p.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
JOIN wx_bucket wb ON p.weather_category = wb.weather_category
GROUP BY p.product_type, wb.weather_bucket
ORDER BY p.product_type, wb.weather_bucket
          )
        
        ...
[0m13:07:04.741180 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    p.product_type,
    wb.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
JOIN wx_bucket wb ON p.weather_category = wb.weather_category
GROUP BY p.product_type, wb.weather_bucket
ORDER BY p.product_type, wb.weather_bucket
          )
        
        
[0m13:07:04.755261 [debug] [Thread-1 (]: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.757305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A5A408590>]}
[0m13:07:04.757878 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model `default`.`analytics_pricing_behavior` ... [[31mERROR[0m in 0.63s]
[0m13:07:04.758991 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:04.759307 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:04.759704 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_pricing_behavior' to be skipped because of status 'error'.  Reason: Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74.
[0m13:07:04.760111 [info ] [Thread-1 (]: 2 of 3 START sql table model `default`.`analytics_seller_performance` .......... [RUN]
[0m13:07:04.762813 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_pricing_behavior, now model.ebay_weather_analytics.analytics_seller_performance)
[0m13:07:04.763725 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:04.769781 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_seller_performance"
[0m13:07:04.771084 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:04.773052 [debug] [Thread-1 (]: Creating new relation analytics_seller_performance
[0m13:07:04.774116 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    s.feedback_score_tier,
    s.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(s.seller_feedback_score) AS avg_feedback_score,
    AVG(s.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN `default`.`dim_seller` s ON f.seller_key = s.seller_key
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
JOIN wx_bucket wb ON p.weather_category = wb.weather_category
GROUP BY s.feedback_score_tier, s.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        ...
[0m13:07:04.831042 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
)
SELECT
    s.feedback_score_tier,
    s.feedback_percentage_tier,
    wb.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(s.seller_feedback_score) AS avg_feedback_score,
    AVG(s.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY wb.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN `default`.`dim_seller` s ON f.seller_key = s.seller_key
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
JOIN wx_bucket wb ON p.weather_category = wb.weather_category
GROUP BY s.feedback_score_tier, s.feedback_percentage_tier, wb.weather_bucket
ORDER BY wb.weather_bucket, listings DESC
          )
        
        
[0m13:07:04.841953 [debug] [Thread-1 (]: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.843034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A5A300B50>]}
[0m13:07:04.843883 [error] [Thread-1 (]: 2 of 3 ERROR creating sql table model `default`.`analytics_seller_performance` . [[31mERROR[0m in 0.08s]
[0m13:07:04.845425 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:04.846070 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:04.847140 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_seller_performance' to be skipped because of status 'error'.  Reason: Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74.
[0m13:07:04.847889 [info ] [Thread-1 (]: 3 of 3 START sql table model `default`.`analytics_weather_impact` .............. [RUN]
[0m13:07:04.849054 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_seller_performance, now model.ebay_weather_analytics.analytics_weather_impact)
[0m13:07:04.849451 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:04.854053 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m13:07:04.855511 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:04.861720 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        f.date_key AS date,
        p.weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT f.item_id) AS unique_items,
        AVG(f.price) AS avg_price,
        AVG(f.seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings` f
    JOIN `default`.`dim_product` p ON f.product_key = p.product_key
    GROUP BY f.date_key, p.weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
          )
        
        ...
[0m13:07:04.915065 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


WITH wx_bucket AS (
    SELECT
        weather_category,
        CASE
            WHEN weather_category = 'rain_products' THEN 'Precipitation-Heavy'
            WHEN weather_category = 'heat_products' THEN 'Extreme Heat'
            WHEN weather_category = 'cold_products' THEN 'Extreme Cold'
            ELSE 'Normal'
        END AS weather_bucket
    FROM (
        SELECT DISTINCT weather_category 
        FROM `default`.`fact_listings`
        WHERE weather_category IS NOT NULL
    ) w
),
daily_listings AS (
    SELECT
        f.date_key AS date,
        p.weather_category,
        COUNT(*) AS listings,
        COUNT(DISTINCT f.item_id) AS unique_items,
        AVG(f.price) AS avg_price,
        AVG(f.seller_feedback_percentage) AS avg_seller_feedback
    FROM `default`.`fact_listings` f
    JOIN `default`.`dim_product` p ON f.product_key = p.product_key
    GROUP BY f.date_key, p.weather_category
)
SELECT
    dl.date,
    wb.weather_bucket,
    dl.listings,
    dl.unique_items,
    dl.avg_price,
    dl.avg_seller_feedback,
    -- Additional metrics
    dl.listings * 100.0 / SUM(dl.listings) OVER (PARTITION BY dl.date) AS daily_market_share_percent,
    AVG(dl.listings) OVER (PARTITION BY wb.weather_bucket ORDER BY dl.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM daily_listings dl
JOIN wx_bucket wb ON dl.weather_category = wb.weather_category
ORDER BY dl.date, wb.weather_bucket
          )
        
        
[0m13:07:04.925280 [debug] [Thread-1 (]: Database Error in model analytics_weather_impact (models\gold\analytics_weather_impact.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.925852 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6da00fe6-b073-4f86-86c2-5a64b919df02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A5A3CE990>]}
[0m13:07:04.926345 [error] [Thread-1 (]: 3 of 3 ERROR creating sql table model `default`.`analytics_weather_impact` ..... [[31mERROR[0m in 0.08s]
[0m13:07:04.927149 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:04.927849 [debug] [Thread-4 (]: Marking all children of 'model.ebay_weather_analytics.analytics_weather_impact' to be skipped because of status 'error'.  Reason: Database Error in model analytics_weather_impact (models\gold\analytics_weather_impact.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74.
[0m13:07:04.929529 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:07:04.930181 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:07:04.930397 [debug] [MainThread]: On list_: Close
[0m13:07:04.931554 [debug] [MainThread]: Connection 'list__default_dbt_test__audit' was left open.
[0m13:07:04.932024 [debug] [MainThread]: On list__default_dbt_test__audit: Close
[0m13:07:04.932740 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.analytics_weather_impact' was left open.
[0m13:07:04.933303 [debug] [MainThread]: On model.ebay_weather_analytics.analytics_weather_impact: Close
[0m13:07:04.934220 [info ] [MainThread]: 
[0m13:07:04.934992 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 2.24 seconds (2.24s).
[0m13:07:04.937098 [debug] [MainThread]: Command end result
[0m13:07:04.972406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:04.974579 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:04.982825 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m13:07:04.983628 [info ] [MainThread]: 
[0m13:07:04.984617 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m13:07:04.985225 [info ] [MainThread]: 
[0m13:07:04.986093 [error] [MainThread]: [31mFailure in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)[0m
[0m13:07:04.986831 [error] [MainThread]:   Database Error in model analytics_pricing_behavior (models\gold\analytics_pricing_behavior.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.987696 [info ] [MainThread]: 
[0m13:07:04.988242 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_pricing_behavior.sql
[0m13:07:04.988658 [info ] [MainThread]: 
[0m13:07:04.989119 [error] [MainThread]: [31mFailure in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)[0m
[0m13:07:04.989668 [error] [MainThread]:   Database Error in model analytics_seller_performance (models\gold\analytics_seller_performance.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.990654 [info ] [MainThread]: 
[0m13:07:04.991797 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_seller_performance.sql
[0m13:07:04.992554 [info ] [MainThread]: 
[0m13:07:04.993249 [error] [MainThread]: [31mFailure in model analytics_weather_impact (models\gold\analytics_weather_impact.sql)[0m
[0m13:07:04.993881 [error] [MainThread]:   Database Error in model analytics_weather_impact (models\gold\analytics_weather_impact.sql)
  Code: 48.
  DB::Exception: Correlated subqueries are not supported in JOINs yet, but found in expression:  wx_bucket AS wb. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x000000000cae74ab
  4. DB::QueryAnalyzer::resolveJoin(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785f3e8
  5. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785a8f8
  6. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
  7. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  8. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  9. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  10. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  11. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  12. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  13. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  14. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  15. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  16. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  17. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  18. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  19. DB::TCPHandler::run() @ 0x0000000019e4f119
  20. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  21. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  22. Poco::PooledThread::run() @ 0x000000001ef15b87
  23. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  24. ? @ 0x0000000000094ac3
  25. ? @ 0x0000000000125a74
[0m13:07:04.997539 [info ] [MainThread]: 
[0m13:07:04.998639 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\models\gold\analytics_weather_impact.sql
[0m13:07:05.002737 [info ] [MainThread]: 
[0m13:07:05.003670 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=3
[0m13:07:05.005661 [debug] [MainThread]: Command `dbt run` failed at 13:07:05.005490 after 3.40 seconds
[0m13:07:05.006495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A584E4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A560924D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A56E38590>]}
[0m13:07:05.008002 [debug] [MainThread]: Flushing usage events
[0m13:07:05.760678 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:29.799366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE89A527B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8A7A4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8ADBFC50>]}


============================== 13:07:29.804185 | 885236be-74af-4450-924c-0b95bb0239af ==============================
[0m13:07:29.804185 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:07:29.805119 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'log_format': 'default', 'use_colors': 'True', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'False', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'invocation_command': 'dbt run --select analytics_pricing_behavior analytics_seller_performance analytics_weather_impact', 'cache_selected_only': 'False', 'write_json': 'True'}
[0m13:07:30.058831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8A14C8A0>]}
[0m13:07:30.148245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE884FF680>]}
[0m13:07:30.150819 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:07:30.379084 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:07:30.539945 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m13:07:30.540560 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_seller_performance.sql
[0m13:07:30.541313 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_pricing_behavior.sql
[0m13:07:30.541606 [debug] [MainThread]: Partial parsing: updated file: ebay_weather_analytics://models\gold\analytics_weather_impact.sql
[0m13:07:31.041644 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ebay_weather_analytics.gold.gold_weather_impact_analysis
- models.ebay_weather_analytics.gold.gold_daily_listings_summary
[0m13:07:31.057319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8C71CB50>]}
[0m13:07:31.166879 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:31.169726 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:31.211714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8C3BA210>]}
[0m13:07:31.213211 [info ] [MainThread]: Found 10 models, 35 data tests, 2 sources, 485 macros
[0m13:07:31.214104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8AEC66D0>]}
[0m13:07:31.216651 [info ] [MainThread]: 
[0m13:07:31.217391 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:07:31.217939 [info ] [MainThread]: 
[0m13:07:31.218459 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:07:31.222757 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:07:31.232235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:31.911850 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:07:31.960920 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:32.007951 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default'
[0m13:07:32.014687 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:32.515171 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m13:07:32.566462 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:32.569612 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default, now list__default_dbt_test__audit)
[0m13:07:32.577583 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m13:07:32.628718 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:32.634069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8C7331E0>]}
[0m13:07:32.639103 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:32.639825 [info ] [Thread-1 (]: 1 of 3 START sql table model `default`.`analytics_pricing_behavior` ............ [RUN]
[0m13:07:32.640869 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'model.ebay_weather_analytics.analytics_pricing_behavior'
[0m13:07:32.641339 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:32.651136 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_pricing_behavior"
[0m13:07:32.653593 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:32.667787 [debug] [Thread-1 (]: Creating new relation analytics_pricing_behavior
[0m13:07:32.699993 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:07:33.212275 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

            

    
        create table `default`.`analytics_pricing_behavior`
        
  
        
  engine = MergeTree()
        order by ((product_type, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


SELECT
    p.product_type,
    p.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY p.product_type, p.weather_bucket
ORDER BY p.product_type, p.weather_bucket
          )
        
        ...
[0m13:07:33.271787 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:33.290133 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

    select name, type from system.columns where table = 'analytics_pricing_behavior'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m13:07:33.338442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:33.343990 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_pricing_behavior"
[0m13:07:33.345790 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_pricing_behavior: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_pricing_behavior"} */

  
    
    
    
        
         


        insert into `default`.`analytics_pricing_behavior`
        ("product_type", "weather_bucket", "avg_price", "min_price", "max_price", "listings", "price_stddev", "median_price", "q1_price", "q3_price", "price_range", "price_coefficient_variation", "avg_seller_feedback", "free_shipping_count", "paid_shipping_count")-- Gold Layer: Analytical Model - Pricing Behavior by Weather and Product
-- Based on sql_queries/pricing_behavior_by_weather_and_product.sql


SELECT
    p.product_type,
    p.weather_bucket,
    AVG(f.price) AS avg_price,
    MIN(f.price) AS min_price,
    MAX(f.price) AS max_price,
    COUNT(*) AS listings,
    stddevPop(f.price) AS price_stddev,
    quantile(0.5)(f.price) AS median_price,
    quantile(0.25)(f.price) AS q1_price,
    quantile(0.75)(f.price) AS q3_price,
    -- Price range analysis
    MAX(f.price) - MIN(f.price) AS price_range,
    stddevPop(f.price) / AVG(f.price) AS price_coefficient_variation,
    -- Additional metrics
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.free_shipping THEN 0 ELSE 1 END) AS paid_shipping_count
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY p.product_type, p.weather_bucket
ORDER BY p.product_type, p.weather_bucket
  ...
[0m13:07:33.405995 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:33.422926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8D752D50>]}
[0m13:07:33.423550 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `default`.`analytics_pricing_behavior` ....... [[32mOK[0m in 0.78s]
[0m13:07:33.424391 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_pricing_behavior
[0m13:07:33.424662 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:33.424967 [info ] [Thread-1 (]: 2 of 3 START sql table model `default`.`analytics_seller_performance` .......... [RUN]
[0m13:07:33.425477 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_pricing_behavior, now model.ebay_weather_analytics.analytics_seller_performance)
[0m13:07:33.425897 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:33.432411 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_seller_performance"
[0m13:07:33.433329 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:33.435604 [debug] [Thread-1 (]: Creating new relation analytics_seller_performance
[0m13:07:33.436659 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

            

    
        create table `default`.`analytics_seller_performance`
        
  
        
  engine = MergeTree()
        order by ((feedback_score_tier, weather_bucket))
        
        
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


SELECT
    s.feedback_score_tier,
    s.feedback_percentage_tier,
    p.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(s.seller_feedback_score) AS avg_feedback_score,
    AVG(s.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY p.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN `default`.`dim_seller` s ON f.seller_key = s.seller_key
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY s.feedback_score_tier, s.feedback_percentage_tier, p.weather_bucket
ORDER BY p.weather_bucket, listings DESC
          )
        
        ...
[0m13:07:33.493708 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:33.496894 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

    select name, type from system.columns where table = 'analytics_seller_performance'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m13:07:33.548713 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:33.552623 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_seller_performance"
[0m13:07:33.554251 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_seller_performance: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_seller_performance"} */

  
    
    
    
        
         


        insert into `default`.`analytics_seller_performance`
        ("feedback_score_tier", "feedback_percentage_tier", "weather_bucket", "listings", "unique_items", "avg_price", "avg_feedback_score", "avg_feedback_percentage", "market_share_percent", "avg_title_length", "free_shipping_count", "price_quality_issues")-- Gold Layer: Analytical Model - Seller Performance vs Weather
-- Based on sql_queries/seller_performance_vs_weather.sql


SELECT
    s.feedback_score_tier,
    s.feedback_percentage_tier,
    p.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(s.seller_feedback_score) AS avg_feedback_score,
    AVG(s.seller_feedback_percentage) AS avg_feedback_percentage,
    -- Market share by weather condition
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY p.weather_bucket) AS market_share_percent,
    -- Additional seller metrics
    AVG(f.title_length) AS avg_title_length,
    SUM(CASE WHEN f.free_shipping THEN 1 ELSE 0 END) AS free_shipping_count,
    SUM(CASE WHEN f.price_quality_flag = 1 THEN 1 ELSE 0 END) AS price_quality_issues
FROM `default`.`fact_listings` f
JOIN `default`.`dim_seller` s ON f.seller_key = s.seller_key
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY s.feedback_score_tier, s.feedback_percentage_tier, p.weather_bucket
ORDER BY p.weather_bucket, listings DESC
  ...
[0m13:07:33.709150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m13:07:33.711404 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8D759D30>]}
[0m13:07:33.712606 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `default`.`analytics_seller_performance` ..... [[32mOK[0m in 0.29s]
[0m13:07:33.714200 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_seller_performance
[0m13:07:33.714609 [debug] [Thread-1 (]: Began running node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:33.715092 [info ] [Thread-1 (]: 3 of 3 START sql table model `default`.`analytics_weather_impact` .............. [RUN]
[0m13:07:33.715637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.ebay_weather_analytics.analytics_seller_performance, now model.ebay_weather_analytics.analytics_weather_impact)
[0m13:07:33.716066 [debug] [Thread-1 (]: Began compiling node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:33.718888 [debug] [Thread-1 (]: Writing injected SQL for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m13:07:33.719848 [debug] [Thread-1 (]: Began executing node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:33.730093 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

            

    
        create table `default`.`analytics_weather_impact__dbt_backup`
        
  
        
  engine = MergeTree()
        order by ((date, weather_bucket))
        
        partition by (toYYYYMM(date))
        
        
                    -- end_of_sql
                    SETTINGS replicated_deduplication_window='0'

                    
            empty
          as (
            -- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


SELECT
    f.date_key AS date,
    p.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    -- Additional metrics
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY f.date_key) AS daily_market_share_percent,
    AVG(COUNT(*)) OVER (PARTITION BY p.weather_bucket ORDER BY f.date_key ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY f.date_key, p.weather_bucket
ORDER BY f.date_key, p.weather_bucket
          )
        
        ...
[0m13:07:33.788495 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:33.791291 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

    select name, type from system.columns where table = 'analytics_weather_impact__dbt_backup'
    
      
        and database = 'default'
      
    
    order by position
  ...
[0m13:07:33.838699 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:33.841215 [debug] [Thread-1 (]: Writing runtime sql for node "model.ebay_weather_analytics.analytics_weather_impact"
[0m13:07:33.842573 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */

  
    
    
    
        
         


        insert into `default`.`analytics_weather_impact__dbt_backup`
        ("date", "weather_bucket", "listings", "unique_items", "avg_price", "avg_seller_feedback", "daily_market_share_percent", "avg_listings_7day")-- Gold Layer: Analytical Model - Impact of Weather on Listings
-- Based on sql_queries/impact_listings_by_weather.sql


SELECT
    f.date_key AS date,
    p.weather_bucket,
    COUNT(*) AS listings,
    COUNT(DISTINCT f.item_id) AS unique_items,
    AVG(f.price) AS avg_price,
    AVG(f.seller_feedback_percentage) AS avg_seller_feedback,
    -- Additional metrics
    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (PARTITION BY f.date_key) AS daily_market_share_percent,
    AVG(COUNT(*)) OVER (PARTITION BY p.weather_bucket ORDER BY f.date_key ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS avg_listings_7day
FROM `default`.`fact_listings` f
JOIN `default`.`dim_product` p ON f.product_key = p.product_key
GROUP BY f.date_key, p.weather_bucket
ORDER BY f.date_key, p.weather_bucket
  ...
[0m13:07:33.940349 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.10 seconds
[0m13:07:33.946240 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
EXCHANGE TABLES `default`.`analytics_weather_impact__dbt_backup` AND `default`.`analytics_weather_impact` 
  
  ...
[0m13:07:33.991724 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m13:07:34.004815 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.ebay_weather_analytics.analytics_weather_impact: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "model.ebay_weather_analytics.analytics_weather_impact"} */
drop table if exists `default`.`analytics_weather_impact__dbt_backup` 
  ...
[0m13:07:34.051024 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:34.053151 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '885236be-74af-4450-924c-0b95bb0239af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8E6BD810>]}
[0m13:07:34.053928 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `default`.`analytics_weather_impact` ......... [[32mOK[0m in 0.34s]
[0m13:07:34.055056 [debug] [Thread-1 (]: Finished running node model.ebay_weather_analytics.analytics_weather_impact
[0m13:07:34.056746 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:07:34.057094 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:07:34.057382 [debug] [MainThread]: On list_: Close
[0m13:07:34.057919 [debug] [MainThread]: Connection 'list__default_dbt_test__audit' was left open.
[0m13:07:34.058236 [debug] [MainThread]: On list__default_dbt_test__audit: Close
[0m13:07:34.059236 [debug] [MainThread]: Connection 'model.ebay_weather_analytics.analytics_weather_impact' was left open.
[0m13:07:34.060302 [debug] [MainThread]: On model.ebay_weather_analytics.analytics_weather_impact: Close
[0m13:07:34.061221 [info ] [MainThread]: 
[0m13:07:34.062839 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 2.84 seconds (2.84s).
[0m13:07:34.064810 [debug] [MainThread]: Command end result
[0m13:07:34.096995 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:34.100104 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:34.104946 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m13:07:34.105242 [info ] [MainThread]: 
[0m13:07:34.105862 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:07:34.106280 [info ] [MainThread]: 
[0m13:07:34.106662 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m13:07:34.107522 [debug] [MainThread]: Command `dbt run` succeeded at 13:07:34.107432 after 4.49 seconds
[0m13:07:34.107784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8C741F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8A0D5DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8AE78590>]}
[0m13:07:34.108016 [debug] [MainThread]: Flushing usage events
[0m13:07:34.942778 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:44.142089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A433D127B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A434A74050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A43508FC50>]}


============================== 13:07:44.149794 | 039171e7-d3f7-4514-ad96-53e5624c53ca ==============================
[0m13:07:44.149794 [info ] [MainThread]: Running with dbt=1.10.13
[0m13:07:44.150786 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'profiles_dir': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt', 'log_format': 'default', 'invocation_command': 'dbt test', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': 'C:\\Users\\ayeshaateeq\\Desktop\\Masters\\Semester-1\\DE\\project\\data_eng_2025_group2\\clickhouse_setup\\dbt\\logs', 'version_check': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'introspect': 'True', 'empty': 'None', 'log_cache_events': 'False', 'debug': 'False', 'no_print': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m13:07:44.370669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A43441C8A0>]}
[0m13:07:44.451811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4327BF680>]}
[0m13:07:44.453214 [info ] [MainThread]: Registered adapter: clickhouse=1.9.5
[0m13:07:44.619832 [debug] [MainThread]: checksum: 9f0c81e2574b4ff463f3d16d080df83c6982fc0372c9feeacae0504ac9ea3ffe, vars: {}, profile: , target: , version: 1.10.13
[0m13:07:44.801066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:07:44.801399 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:07:44.807384 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.ebay_weather_analytics.gold.gold_daily_listings_summary
- models.ebay_weather_analytics.gold.gold_weather_impact_analysis
[0m13:07:44.850078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4365CC750>]}
[0m13:07:44.937972 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:44.940630 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:45.075163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4369A0050>]}
[0m13:07:45.076696 [info ] [MainThread]: Found 10 models, 35 data tests, 2 sources, 485 macros
[0m13:07:45.077492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A436309390>]}
[0m13:07:45.081186 [info ] [MainThread]: 
[0m13:07:45.084658 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:07:45.085686 [info ] [MainThread]: 
[0m13:07:45.086723 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:07:45.096324 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:07:45.104469 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:45.820373 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:07:45.869450 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:45.953033 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list__default_dbt_test__audit'
[0m13:07:45.961278 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:46.456971 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_dbt_test__audit: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default_dbt_test__audit"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_dbt_test__audit'
      

  ...
[0m13:07:46.510396 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:46.513331 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_dbt_test__audit, now list__default)
[0m13:07:46.518564 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "connection_name": "list__default"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default'
      

  ...
[0m13:07:46.568753 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:46.572698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '039171e7-d3f7-4514-ad96-53e5624c53ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4369AA340>]}
[0m13:07:46.580284 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_location_city.9914acb951
[0m13:07:46.581123 [info ] [Thread-1 (]: 1 of 35 START test not_null_dim_location_city .................................. [RUN]
[0m13:07:46.581980 [debug] [Thread-1 (]: Acquiring new clickhouse connection 'test.ebay_weather_analytics.not_null_dim_location_city.9914acb951'
[0m13:07:46.582418 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_location_city.9914acb951
[0m13:07:46.604900 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"
[0m13:07:46.607281 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_location_city.9914acb951
[0m13:07:46.628215 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_location_city`
[0m13:07:46.663179 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:07:47.188412 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_city.9914acb951: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_location_city`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_location`
where city is null



  
  
          )
        
        ...
[0m13:07:47.248279 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:47.265432 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_city.9914acb951: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"} */

    select name, type from system.columns where table = 'not_null_dim_location_city'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:47.315641 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.319166 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_city.9914acb951: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_location_city`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_location`
where city is null



  
  
  
    ...
[0m13:07:47.371412 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.381576 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"
[0m13:07:47.382837 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_city.9914acb951: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_city.9914acb951"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_location_city`
    
    ) dbt_internal_test...
[0m13:07:47.434194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.439540 [info ] [Thread-1 (]: 1 of 35 PASS not_null_dim_location_city ........................................ [[32mPASS[0m in 0.86s]
[0m13:07:47.440463 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_location_city.9914acb951
[0m13:07:47.440755 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e
[0m13:07:47.441259 [info ] [Thread-1 (]: 2 of 35 START test not_null_dim_location_country ............................... [RUN]
[0m13:07:47.442606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_location_city.9914acb951, now test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e)
[0m13:07:47.443266 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e
[0m13:07:47.448492 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"
[0m13:07:47.449976 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e
[0m13:07:47.452556 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_location_country`
[0m13:07:47.455504 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_location_country`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_location`
where country is null



  
  
          )
        
        ...
[0m13:07:47.511552 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.522220 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"} */

    select name, type from system.columns where table = 'not_null_dim_location_country'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:47.572335 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.575740 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_location_country`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_location`
where country is null



  
  
  
    ...
[0m13:07:47.629932 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.633036 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"
[0m13:07:47.634977 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_location_country`
    
    ) dbt_internal_test...
[0m13:07:47.685760 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.688293 [info ] [Thread-1 (]: 2 of 35 PASS not_null_dim_location_country ..................................... [[32mPASS[0m in 0.25s]
[0m13:07:47.689452 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e
[0m13:07:47.689899 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c
[0m13:07:47.690455 [info ] [Thread-1 (]: 3 of 35 START test not_null_dim_location_location_key .......................... [RUN]
[0m13:07:47.691266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_location_country.a3161a472e, now test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c)
[0m13:07:47.691815 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c
[0m13:07:47.697831 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"
[0m13:07:47.699780 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c
[0m13:07:47.702608 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_location_location_key`
[0m13:07:47.704869 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_location_location_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_location`
where location_key is null



  
  
          )
        
        ...
[0m13:07:47.772826 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m13:07:47.779267 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"} */

    select name, type from system.columns where table = 'not_null_dim_location_location_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:47.826947 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.829331 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_location_location_key`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_location`
where location_key is null



  
  
  
    ...
[0m13:07:47.879536 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.880850 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"
[0m13:07:47.881917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_location_location_key`
    
    ) dbt_internal_test...
[0m13:07:47.931777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:47.933428 [info ] [Thread-1 (]: 3 of 35 PASS not_null_dim_location_location_key ................................ [[32mPASS[0m in 0.24s]
[0m13:07:47.934172 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c
[0m13:07:47.934565 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae
[0m13:07:47.935041 [info ] [Thread-1 (]: 4 of 35 START test not_null_dim_location_postal_code ........................... [RUN]
[0m13:07:47.936076 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_location_location_key.c1a2c0b86c, now test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae)
[0m13:07:47.936627 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae
[0m13:07:47.942608 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"
[0m13:07:47.944069 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae
[0m13:07:47.950998 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_location_postal_code`
[0m13:07:47.952083 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_location_postal_code`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_location`
where postal_code is null



  
  
          )
        
        ...
[0m13:07:48.096084 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m13:07:48.103085 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"} */

    select name, type from system.columns where table = 'not_null_dim_location_postal_code'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:48.151487 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.153393 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_location_postal_code`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_location`
where postal_code is null



  
  
  
    ...
[0m13:07:48.203035 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.205554 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"
[0m13:07:48.207270 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_location_postal_code`
    
    ) dbt_internal_test...
[0m13:07:48.256093 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.259914 [info ] [Thread-1 (]: 4 of 35 PASS not_null_dim_location_postal_code ................................. [[32mPASS[0m in 0.32s]
[0m13:07:48.261290 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae
[0m13:07:48.262039 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218
[0m13:07:48.262857 [info ] [Thread-1 (]: 5 of 35 START test not_null_dim_location_state_code ............................ [RUN]
[0m13:07:48.263832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_location_postal_code.d60e5889ae, now test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218)
[0m13:07:48.264167 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218
[0m13:07:48.267819 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"
[0m13:07:48.268809 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218
[0m13:07:48.270282 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_location_state_code`
[0m13:07:48.271460 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_location_state_code`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_location`
where state_code is null



  
  
          )
        
        ...
[0m13:07:48.332142 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:48.338014 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"} */

    select name, type from system.columns where table = 'not_null_dim_location_state_code'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:48.387481 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.389613 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_location_state_code`
        ("location_key", "postal_code", "country", "city", "state_code", "country_code", "region", "region_group", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_location`
where state_code is null



  
  
  
    ...
[0m13:07:48.440392 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.442768 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"
[0m13:07:48.445096 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_location_state_code`
    
    ) dbt_internal_test...
[0m13:07:48.501152 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:48.504144 [info ] [Thread-1 (]: 5 of 35 PASS not_null_dim_location_state_code .................................. [[32mPASS[0m in 0.24s]
[0m13:07:48.505445 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218
[0m13:07:48.505894 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3
[0m13:07:48.506442 [info ] [Thread-1 (]: 6 of 35 START test not_null_dim_product_product_key ............................ [RUN]
[0m13:07:48.507118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_location_state_code.992808b218, now test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3)
[0m13:07:48.507487 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3
[0m13:07:48.514272 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"
[0m13:07:48.515760 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3
[0m13:07:48.517882 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_product_product_key`
[0m13:07:48.519507 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_product_product_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_product`
where product_key is null



  
  
          )
        
        ...
[0m13:07:48.572936 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.578531 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"} */

    select name, type from system.columns where table = 'not_null_dim_product_product_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:48.627946 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.630076 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_product_product_key`
        ("product_key", "product_type", "weather_category", "weather_bucket", "product_category", "weather_sensitivity", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_product`
where product_key is null



  
  
  
    ...
[0m13:07:48.679126 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.680748 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"
[0m13:07:48.682046 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_product_product_key`
    
    ) dbt_internal_test...
[0m13:07:48.732301 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.735130 [info ] [Thread-1 (]: 6 of 35 PASS not_null_dim_product_product_key .................................. [[32mPASS[0m in 0.23s]
[0m13:07:48.735916 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3
[0m13:07:48.736235 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4
[0m13:07:48.736623 [info ] [Thread-1 (]: 7 of 35 START test not_null_dim_product_product_type ........................... [RUN]
[0m13:07:48.737168 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_product_product_key.f0e1d838d3, now test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4)
[0m13:07:48.737490 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4
[0m13:07:48.741565 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"
[0m13:07:48.743615 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4
[0m13:07:48.746942 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_product_product_type`
[0m13:07:48.748094 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_product_product_type`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_product`
where product_type is null



  
  
          )
        
        ...
[0m13:07:48.802039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.807896 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"} */

    select name, type from system.columns where table = 'not_null_dim_product_product_type'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:48.854845 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.857803 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_product_product_type`
        ("product_key", "product_type", "weather_category", "weather_bucket", "product_category", "weather_sensitivity", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_product`
where product_type is null



  
  
  
    ...
[0m13:07:48.910407 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.913286 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"
[0m13:07:48.915708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_product_product_type`
    
    ) dbt_internal_test...
[0m13:07:48.965561 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:48.968641 [info ] [Thread-1 (]: 7 of 35 PASS not_null_dim_product_product_type ................................. [[32mPASS[0m in 0.23s]
[0m13:07:48.969789 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4
[0m13:07:48.970310 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a
[0m13:07:48.970910 [info ] [Thread-1 (]: 8 of 35 START test not_null_dim_product_weather_bucket ......................... [RUN]
[0m13:07:48.971978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_product_product_type.26040facd4, now test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a)
[0m13:07:48.972454 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a
[0m13:07:48.978794 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"
[0m13:07:48.980958 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a
[0m13:07:48.983162 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_product_weather_bucket`
[0m13:07:48.984308 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_product_weather_bucket`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_product`
where weather_bucket is null



  
  
          )
        
        ...
[0m13:07:49.038722 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.043598 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"} */

    select name, type from system.columns where table = 'not_null_dim_product_weather_bucket'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:49.090431 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.092887 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_product_weather_bucket`
        ("product_key", "product_type", "weather_category", "weather_bucket", "product_category", "weather_sensitivity", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_product`
where weather_bucket is null



  
  
  
    ...
[0m13:07:49.145779 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.148198 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"
[0m13:07:49.150637 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_product_weather_bucket`
    
    ) dbt_internal_test...
[0m13:07:49.199790 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.201563 [info ] [Thread-1 (]: 8 of 35 PASS not_null_dim_product_weather_bucket ............................... [[32mPASS[0m in 0.23s]
[0m13:07:49.202669 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a
[0m13:07:49.203057 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f
[0m13:07:49.203462 [info ] [Thread-1 (]: 9 of 35 START test not_null_dim_product_weather_category ....................... [RUN]
[0m13:07:49.204015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_product_weather_bucket.ae39be2b6a, now test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f)
[0m13:07:49.204266 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f
[0m13:07:49.208546 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"
[0m13:07:49.209606 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f
[0m13:07:49.213311 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_product_weather_category`
[0m13:07:49.214491 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_product_weather_category`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_product`
where weather_category is null



  
  
          )
        
        ...
[0m13:07:49.273346 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:49.279807 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"} */

    select name, type from system.columns where table = 'not_null_dim_product_weather_category'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:49.331669 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.336028 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_product_weather_category`
        ("product_key", "product_type", "weather_category", "weather_bucket", "product_category", "weather_sensitivity", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_product`
where weather_category is null



  
  
  
    ...
[0m13:07:49.388494 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.389667 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"
[0m13:07:49.392618 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_product_weather_category`
    
    ) dbt_internal_test...
[0m13:07:49.444943 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.448076 [info ] [Thread-1 (]: 9 of 35 PASS not_null_dim_product_weather_category ............................. [[32mPASS[0m in 0.24s]
[0m13:07:49.449006 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f
[0m13:07:49.449361 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c
[0m13:07:49.449749 [info ] [Thread-1 (]: 10 of 35 START test not_null_dim_seller_feedback_percentage_tier ............... [RUN]
[0m13:07:49.450387 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_product_weather_category.384f5a852f, now test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c)
[0m13:07:49.450906 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c
[0m13:07:49.456702 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"
[0m13:07:49.458550 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c
[0m13:07:49.460549 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_seller_feedback_percentage_tier`
[0m13:07:49.461650 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_seller_feedback_percentage_tier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_seller`
where feedback_percentage_tier is null



  
  
          )
        
        ...
[0m13:07:49.521753 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:49.529603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"} */

    select name, type from system.columns where table = 'not_null_dim_seller_feedback_percentage_tier'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:49.580720 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.584472 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_seller_feedback_percentage_tier`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_seller`
where feedback_percentage_tier is null



  
  
  
    ...
[0m13:07:49.636927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.639115 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"
[0m13:07:49.640472 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_seller_feedback_percentage_tier`
    
    ) dbt_internal_test...
[0m13:07:49.693745 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.696737 [info ] [Thread-1 (]: 10 of 35 PASS not_null_dim_seller_feedback_percentage_tier ..................... [[32mPASS[0m in 0.25s]
[0m13:07:49.698002 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c
[0m13:07:49.698669 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84
[0m13:07:49.699191 [info ] [Thread-1 (]: 11 of 35 START test not_null_dim_seller_feedback_score_tier .................... [RUN]
[0m13:07:49.700100 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_seller_feedback_percentage_tier.18d84ee83c, now test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84)
[0m13:07:49.700961 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84
[0m13:07:49.705317 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"
[0m13:07:49.706536 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84
[0m13:07:49.711527 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_seller_feedback_score_tier`
[0m13:07:49.713841 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_seller_feedback_score_tier`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_seller`
where feedback_score_tier is null



  
  
          )
        
        ...
[0m13:07:49.772834 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:49.781247 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"} */

    select name, type from system.columns where table = 'not_null_dim_seller_feedback_score_tier'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:49.831606 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.834276 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_seller_feedback_score_tier`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_seller`
where feedback_score_tier is null



  
  
  
    ...
[0m13:07:49.886251 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.887946 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"
[0m13:07:49.889512 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_seller_feedback_score_tier`
    
    ) dbt_internal_test...
[0m13:07:49.941606 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:49.945102 [info ] [Thread-1 (]: 11 of 35 PASS not_null_dim_seller_feedback_score_tier .......................... [[32mPASS[0m in 0.24s]
[0m13:07:49.946621 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84
[0m13:07:49.947290 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167
[0m13:07:49.947775 [info ] [Thread-1 (]: 12 of 35 START test not_null_dim_seller_seller_feedback_percentage ............. [RUN]
[0m13:07:49.948594 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_seller_feedback_score_tier.df647c7d84, now test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167)
[0m13:07:49.949054 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167
[0m13:07:49.953433 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"
[0m13:07:49.954464 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167
[0m13:07:49.956561 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_percentage`
[0m13:07:49.957669 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_percentage`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_seller`
where seller_feedback_percentage is null



  
  
          )
        
        ...
[0m13:07:50.016569 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:50.020902 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"} */

    select name, type from system.columns where table = 'not_null_dim_seller_seller_feedback_percentage'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:50.070984 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.072412 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_percentage`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_seller`
where seller_feedback_percentage is null



  
  
  
    ...
[0m13:07:50.119527 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.121334 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"
[0m13:07:50.122795 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_percentage`
    
    ) dbt_internal_test...
[0m13:07:50.172350 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.174637 [info ] [Thread-1 (]: 12 of 35 PASS not_null_dim_seller_seller_feedback_percentage ................... [[32mPASS[0m in 0.23s]
[0m13:07:50.175819 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167
[0m13:07:50.176842 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1
[0m13:07:50.177601 [info ] [Thread-1 (]: 13 of 35 START test not_null_dim_seller_seller_feedback_score .................. [RUN]
[0m13:07:50.178475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_percentage.c4ec0fe167, now test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1)
[0m13:07:50.178972 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1
[0m13:07:50.186022 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"
[0m13:07:50.187350 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1
[0m13:07:50.189796 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_score`
[0m13:07:50.193244 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_score`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_seller`
where seller_feedback_score is null



  
  
          )
        
        ...
[0m13:07:50.252610 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:50.256837 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"} */

    select name, type from system.columns where table = 'not_null_dim_seller_seller_feedback_score'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:50.306324 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.309582 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_score`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_seller`
where seller_feedback_score is null



  
  
  
    ...
[0m13:07:50.361817 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.363629 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"
[0m13:07:50.365354 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_seller_seller_feedback_score`
    
    ) dbt_internal_test...
[0m13:07:50.418282 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.421143 [info ] [Thread-1 (]: 13 of 35 PASS not_null_dim_seller_seller_feedback_score ........................ [[32mPASS[0m in 0.24s]
[0m13:07:50.422408 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1
[0m13:07:50.423206 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980
[0m13:07:50.424073 [info ] [Thread-1 (]: 14 of 35 START test not_null_dim_seller_seller_key ............................. [RUN]
[0m13:07:50.425684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_seller_seller_feedback_score.6a26d28cd1, now test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980)
[0m13:07:50.426438 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980
[0m13:07:50.432657 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"
[0m13:07:50.434054 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980
[0m13:07:50.436516 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_seller_seller_key`
[0m13:07:50.439166 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_seller_seller_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_seller`
where seller_key is null



  
  
          )
        
        ...
[0m13:07:50.498239 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:50.502999 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"} */

    select name, type from system.columns where table = 'not_null_dim_seller_seller_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:50.550760 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.552497 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_seller_seller_key`
        ("seller_key", "seller_feedback_score", "seller_feedback_percentage", "feedback_score_tier", "feedback_percentage_tier", "seller_tier", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_seller`
where seller_key is null



  
  
  
    ...
[0m13:07:50.599529 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.601097 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"
[0m13:07:50.601989 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_seller_seller_key`
    
    ) dbt_internal_test...
[0m13:07:50.651643 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.653673 [info ] [Thread-1 (]: 14 of 35 PASS not_null_dim_seller_seller_key ................................... [[32mPASS[0m in 0.23s]
[0m13:07:50.654534 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980
[0m13:07:50.654888 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e
[0m13:07:50.655239 [info ] [Thread-1 (]: 15 of 35 START test not_null_dim_weather_date .................................. [RUN]
[0m13:07:50.655990 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_seller_seller_key.eb5ea08980, now test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e)
[0m13:07:50.656350 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e
[0m13:07:50.659694 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"
[0m13:07:50.660627 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e
[0m13:07:50.662872 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_weather_date`
[0m13:07:50.664326 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_weather_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_weather`
where date is null



  
  
          )
        
        ...
[0m13:07:50.720561 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:50.725013 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"} */

    select name, type from system.columns where table = 'not_null_dim_weather_date'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:50.773369 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.775192 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_weather_date`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_weather`
where date is null



  
  
  
    ...
[0m13:07:50.829168 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.830479 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"
[0m13:07:50.831830 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_weather_date`
    
    ) dbt_internal_test...
[0m13:07:50.880007 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:50.882485 [info ] [Thread-1 (]: 15 of 35 PASS not_null_dim_weather_date ........................................ [[32mPASS[0m in 0.23s]
[0m13:07:50.883467 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e
[0m13:07:50.883917 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692
[0m13:07:50.884378 [info ] [Thread-1 (]: 16 of 35 START test not_null_dim_weather_weather_bucket ........................ [RUN]
[0m13:07:50.885079 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_weather_date.fab520af4e, now test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692)
[0m13:07:50.885420 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692
[0m13:07:50.889954 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"
[0m13:07:50.892666 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692
[0m13:07:50.896097 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_weather_weather_bucket`
[0m13:07:50.897274 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_weather_weather_bucket`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_weather`
where weather_bucket is null



  
  
          )
        
        ...
[0m13:07:50.955704 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:50.963993 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"} */

    select name, type from system.columns where table = 'not_null_dim_weather_weather_bucket'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:51.011235 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.013657 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_weather_weather_bucket`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_weather`
where weather_bucket is null



  
  
  
    ...
[0m13:07:51.066503 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.068082 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"
[0m13:07:51.069509 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_weather_weather_bucket`
    
    ) dbt_internal_test...
[0m13:07:51.121188 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.124041 [info ] [Thread-1 (]: 16 of 35 PASS not_null_dim_weather_weather_bucket .............................. [[32mPASS[0m in 0.24s]
[0m13:07:51.125774 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692
[0m13:07:51.126411 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b
[0m13:07:51.127281 [info ] [Thread-1 (]: 17 of 35 START test not_null_dim_weather_weather_key ........................... [RUN]
[0m13:07:51.127997 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_weather_weather_bucket.d458067692, now test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b)
[0m13:07:51.128502 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b
[0m13:07:51.133334 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"
[0m13:07:51.134546 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b
[0m13:07:51.137023 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_dim_weather_weather_key`
[0m13:07:51.138511 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"} */

            

    
        create table `default_dbt_test__audit`.`not_null_dim_weather_weather_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`dim_weather`
where weather_key is null



  
  
          )
        
        ...
[0m13:07:51.197723 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:51.202358 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"} */

    select name, type from system.columns where table = 'not_null_dim_weather_weather_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:51.251237 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.253926 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_dim_weather_weather_key`
        ("weather_key", "date", "weather_bucket", "avg_temperature", "min_temperature", "max_temperature", "temperature_category", "total_rain", "rain_category", "total_sunshine", "avg_wind_speed", "avg_humidity", "avg_cloudcover", "weather_code", "season", "status", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`dim_weather`
where weather_key is null



  
  
  
    ...
[0m13:07:51.304437 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.306443 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"
[0m13:07:51.308999 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_dim_weather_weather_key`
    
    ) dbt_internal_test...
[0m13:07:51.359270 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.361410 [info ] [Thread-1 (]: 17 of 35 PASS not_null_dim_weather_weather_key ................................. [[32mPASS[0m in 0.23s]
[0m13:07:51.362529 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b
[0m13:07:51.362824 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m13:07:51.363267 [info ] [Thread-1 (]: 18 of 35 START test not_null_fact_listings_collection_timestamp ................ [RUN]
[0m13:07:51.363925 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_dim_weather_weather_key.a28481207b, now test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3)
[0m13:07:51.364166 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m13:07:51.367505 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"
[0m13:07:51.368471 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m13:07:51.374888 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */
drop table if exists `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp` 
  ...
[0m13:07:51.419559 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m13:07:51.420861 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
[0m13:07:51.422234 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where collection_timestamp is null



  
  
          )
        
        ...
[0m13:07:51.484621 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:51.490544 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

    select name, type from system.columns where table = 'not_null_fact_listings_collection_timestamp'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:51.539540 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.542670 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where collection_timestamp is null



  
  
  
    ...
[0m13:07:51.595790 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.597918 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"
[0m13:07:51.599546 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_collection_timestamp`
    
    ) dbt_internal_test...
[0m13:07:51.648635 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.650935 [info ] [Thread-1 (]: 18 of 35 PASS not_null_fact_listings_collection_timestamp ...................... [[32mPASS[0m in 0.29s]
[0m13:07:51.652125 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3
[0m13:07:51.652591 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m13:07:51.653259 [info ] [Thread-1 (]: 19 of 35 START test not_null_fact_listings_date_key ............................ [RUN]
[0m13:07:51.653927 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_collection_timestamp.eb26cfa8e3, now test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85)
[0m13:07:51.654324 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m13:07:51.659053 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"
[0m13:07:51.660223 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m13:07:51.664176 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */
drop table if exists `default_dbt_test__audit`.`not_null_fact_listings_date_key` 
  ...
[0m13:07:51.709043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m13:07:51.710956 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_date_key`
[0m13:07:51.713223 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_date_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where date_key is null



  
  
          )
        
        ...
[0m13:07:51.772244 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:51.779363 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

    select name, type from system.columns where table = 'not_null_fact_listings_date_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:51.827813 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.831654 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_date_key`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where date_key is null



  
  
  
    ...
[0m13:07:51.885012 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.886925 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"
[0m13:07:51.888036 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_date_key`
    
    ) dbt_internal_test...
[0m13:07:51.936655 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:51.938574 [info ] [Thread-1 (]: 19 of 35 PASS not_null_fact_listings_date_key .................................. [[32mPASS[0m in 0.28s]
[0m13:07:51.939482 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85
[0m13:07:51.939862 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m13:07:51.940303 [info ] [Thread-1 (]: 20 of 35 START test not_null_fact_listings_item_id ............................. [RUN]
[0m13:07:51.941012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_date_key.f22a0e9a85, now test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a)
[0m13:07:51.941484 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m13:07:51.947230 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"
[0m13:07:51.948208 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m13:07:51.951828 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */
drop table if exists `default_dbt_test__audit`.`not_null_fact_listings_item_id` 
  ...
[0m13:07:51.996933 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m13:07:51.998785 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_item_id`
[0m13:07:52.000641 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_item_id`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where item_id is null



  
  
          )
        
        ...
[0m13:07:52.080656 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m13:07:52.086107 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

    select name, type from system.columns where table = 'not_null_fact_listings_item_id'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:52.136472 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.142399 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_item_id`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where item_id is null



  
  
  
    ...
[0m13:07:52.194150 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.196038 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"
[0m13:07:52.197311 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_item_id`
    
    ) dbt_internal_test...
[0m13:07:52.248724 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.252546 [info ] [Thread-1 (]: 20 of 35 PASS not_null_fact_listings_item_id ................................... [[32mPASS[0m in 0.31s]
[0m13:07:52.253596 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a
[0m13:07:52.254434 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178
[0m13:07:52.254895 [info ] [Thread-1 (]: 21 of 35 START test not_null_fact_listings_location_key ........................ [RUN]
[0m13:07:52.255550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_item_id.322f32009a, now test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178)
[0m13:07:52.255868 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178
[0m13:07:52.263444 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"
[0m13:07:52.264750 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178
[0m13:07:52.266467 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_location_key`
[0m13:07:52.267415 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_location_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where location_key is null



  
  
          )
        
        ...
[0m13:07:52.348052 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m13:07:52.353349 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"} */

    select name, type from system.columns where table = 'not_null_fact_listings_location_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:52.401135 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.402889 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_location_key`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where location_key is null



  
  
  
    ...
[0m13:07:52.451827 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.453359 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"
[0m13:07:52.454459 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_location_key`
    
    ) dbt_internal_test...
[0m13:07:52.503214 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.504979 [info ] [Thread-1 (]: 21 of 35 PASS not_null_fact_listings_location_key .............................. [[32mPASS[0m in 0.25s]
[0m13:07:52.506147 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178
[0m13:07:52.506661 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m13:07:52.507104 [info ] [Thread-1 (]: 22 of 35 START test not_null_fact_listings_price ............................... [RUN]
[0m13:07:52.507775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_location_key.40fcebd178, now test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad)
[0m13:07:52.508259 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m13:07:52.513500 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"
[0m13:07:52.514677 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m13:07:52.518909 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */
drop table if exists `default_dbt_test__audit`.`not_null_fact_listings_price` 
  ...
[0m13:07:52.564362 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m13:07:52.566180 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_price`
[0m13:07:52.568065 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_price`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where price is null



  
  
          )
        
        ...
[0m13:07:52.626306 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:52.632886 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

    select name, type from system.columns where table = 'not_null_fact_listings_price'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:52.683562 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.685903 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_price`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where price is null



  
  
  
    ...
[0m13:07:52.737000 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.738732 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"
[0m13:07:52.740158 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_price`
    
    ) dbt_internal_test...
[0m13:07:52.788982 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.792432 [info ] [Thread-1 (]: 22 of 35 PASS not_null_fact_listings_price ..................................... [[32mPASS[0m in 0.28s]
[0m13:07:52.793845 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad
[0m13:07:52.794526 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f
[0m13:07:52.795105 [info ] [Thread-1 (]: 23 of 35 START test not_null_fact_listings_product_key ......................... [RUN]
[0m13:07:52.796177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_price.6ecd9511ad, now test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f)
[0m13:07:52.796650 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f
[0m13:07:52.802000 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"
[0m13:07:52.803225 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f
[0m13:07:52.805054 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_product_key`
[0m13:07:52.807006 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_product_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where product_key is null



  
  
          )
        
        ...
[0m13:07:52.884972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m13:07:52.891387 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"} */

    select name, type from system.columns where table = 'not_null_fact_listings_product_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:52.938794 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.942803 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_product_key`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where product_key is null



  
  
  
    ...
[0m13:07:52.992875 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:52.994348 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"
[0m13:07:52.995754 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_product_key`
    
    ) dbt_internal_test...
[0m13:07:53.044108 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.047000 [info ] [Thread-1 (]: 23 of 35 PASS not_null_fact_listings_product_key ............................... [[32mPASS[0m in 0.25s]
[0m13:07:53.047916 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f
[0m13:07:53.048437 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8
[0m13:07:53.048865 [info ] [Thread-1 (]: 24 of 35 START test not_null_fact_listings_seller_key .......................... [RUN]
[0m13:07:53.049508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_product_key.2d6b285e0f, now test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8)
[0m13:07:53.049825 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8
[0m13:07:53.053276 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"
[0m13:07:53.054298 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8
[0m13:07:53.055951 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`not_null_fact_listings_seller_key`
[0m13:07:53.057581 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"} */

            

    
        create table `default_dbt_test__audit`.`not_null_fact_listings_seller_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    



select *
from `default`.`fact_listings`
where seller_key is null



  
  
          )
        
        ...
[0m13:07:53.118478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:53.125709 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"} */

    select name, type from system.columns where table = 'not_null_fact_listings_seller_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:53.174132 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.176813 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`not_null_fact_listings_seller_key`
        ("item_id", "product_key", "location_key", "seller_key", "collection_timestamp", "date_key", "price", "shipping_cost", "seller_feedback_percentage", "seller_feedback_score", "title_length", "free_shipping", "price_quality_flag", "feedback_quality_flag", "condition", "buying_options", "marketplace_id", "data_source", "created_at", "updated_at")
    
  
    
    



select *
from `default`.`fact_listings`
where seller_key is null



  
  
  
    ...
[0m13:07:53.232884 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:53.234001 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"
[0m13:07:53.235299 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`not_null_fact_listings_seller_key`
    
    ) dbt_internal_test...
[0m13:07:53.285465 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.287395 [info ] [Thread-1 (]: 24 of 35 PASS not_null_fact_listings_seller_key ................................ [[32mPASS[0m in 0.24s]
[0m13:07:53.288398 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8
[0m13:07:53.288955 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_dim_location_unique_key
[0m13:07:53.289389 [info ] [Thread-1 (]: 25 of 35 START test test_dim_location_unique_key ............................... [RUN]
[0m13:07:53.290002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.not_null_fact_listings_seller_key.46282a4ef8, now test.ebay_weather_analytics.test_dim_location_unique_key)
[0m13:07:53.290289 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_dim_location_unique_key
[0m13:07:53.295909 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_dim_location_unique_key"
[0m13:07:53.297927 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_dim_location_unique_key
[0m13:07:53.300607 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_dim_location_unique_key`
[0m13:07:53.301848 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_location_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_location_unique_key"} */

            

    
        create table `default_dbt_test__audit`.`test_dim_location_unique_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Dimension Location - Unique Location Keys
-- Ensures each location_key appears only once
SELECT location_key
FROM `default`.`dim_location`
GROUP BY location_key
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m13:07:53.357303 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.363200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_location_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_location_unique_key"} */

    select name, type from system.columns where table = 'test_dim_location_unique_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:53.410374 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.412199 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_location_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_location_unique_key"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_dim_location_unique_key`
        ("location_key")
    
  -- Test: Dimension Location - Unique Location Keys
-- Ensures each location_key appears only once
SELECT location_key
FROM `default`.`dim_location`
GROUP BY location_key
HAVING COUNT(*) > 1
  
  
  
    ...
[0m13:07:53.461009 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.463459 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_dim_location_unique_key"
[0m13:07:53.465123 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_location_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_location_unique_key"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_dim_location_unique_key`
    
    ) dbt_internal_test...
[0m13:07:53.516330 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.518664 [info ] [Thread-1 (]: 25 of 35 PASS test_dim_location_unique_key ..................................... [[32mPASS[0m in 0.23s]
[0m13:07:53.520043 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_dim_location_unique_key
[0m13:07:53.520518 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_dim_product_unique_key
[0m13:07:53.521371 [info ] [Thread-1 (]: 26 of 35 START test test_dim_product_unique_key ................................ [RUN]
[0m13:07:53.522429 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_dim_location_unique_key, now test.ebay_weather_analytics.test_dim_product_unique_key)
[0m13:07:53.523054 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_dim_product_unique_key
[0m13:07:53.528223 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_dim_product_unique_key"
[0m13:07:53.530172 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_dim_product_unique_key
[0m13:07:53.532636 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_dim_product_unique_key`
[0m13:07:53.534283 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_product_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_product_unique_key"} */

            

    
        create table `default_dbt_test__audit`.`test_dim_product_unique_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Dimension Product - Unique Product Keys
-- Ensures each product_key appears only once
SELECT product_key
FROM `default`.`dim_product`
GROUP BY product_key
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m13:07:53.596321 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:53.602143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_product_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_product_unique_key"} */

    select name, type from system.columns where table = 'test_dim_product_unique_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:53.651614 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.653968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_product_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_product_unique_key"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_dim_product_unique_key`
        ("product_key")
    
  -- Test: Dimension Product - Unique Product Keys
-- Ensures each product_key appears only once
SELECT product_key
FROM `default`.`dim_product`
GROUP BY product_key
HAVING COUNT(*) > 1
  
  
  
    ...
[0m13:07:53.706815 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.708723 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_dim_product_unique_key"
[0m13:07:53.710340 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_product_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_product_unique_key"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_dim_product_unique_key`
    
    ) dbt_internal_test...
[0m13:07:53.759854 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.762295 [info ] [Thread-1 (]: 26 of 35 PASS test_dim_product_unique_key ...................................... [[32mPASS[0m in 0.24s]
[0m13:07:53.763682 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_dim_product_unique_key
[0m13:07:53.764085 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_dim_seller_unique_key
[0m13:07:53.764520 [info ] [Thread-1 (]: 27 of 35 START test test_dim_seller_unique_key ................................. [RUN]
[0m13:07:53.765158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_dim_product_unique_key, now test.ebay_weather_analytics.test_dim_seller_unique_key)
[0m13:07:53.765572 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_dim_seller_unique_key
[0m13:07:53.768323 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_dim_seller_unique_key"
[0m13:07:53.769326 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_dim_seller_unique_key
[0m13:07:53.770973 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_dim_seller_unique_key`
[0m13:07:53.772445 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_seller_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_seller_unique_key"} */

            

    
        create table `default_dbt_test__audit`.`test_dim_seller_unique_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Dimension Seller - Unique Seller Keys
-- Ensures each seller_key appears only once
SELECT seller_key
FROM `default`.`dim_seller`
GROUP BY seller_key
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m13:07:53.827136 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.833934 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_seller_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_seller_unique_key"} */

    select name, type from system.columns where table = 'test_dim_seller_unique_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:53.883067 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.885218 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_seller_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_seller_unique_key"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_dim_seller_unique_key`
        ("seller_key")
    
  -- Test: Dimension Seller - Unique Seller Keys
-- Ensures each seller_key appears only once
SELECT seller_key
FROM `default`.`dim_seller`
GROUP BY seller_key
HAVING COUNT(*) > 1
  
  
  
    ...
[0m13:07:53.938143 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.940028 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_dim_seller_unique_key"
[0m13:07:53.942854 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_seller_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_seller_unique_key"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_dim_seller_unique_key`
    
    ) dbt_internal_test...
[0m13:07:53.992920 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:53.995410 [info ] [Thread-1 (]: 27 of 35 PASS test_dim_seller_unique_key ....................................... [[32mPASS[0m in 0.23s]
[0m13:07:53.996725 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_dim_seller_unique_key
[0m13:07:53.997390 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_dim_weather_unique_key
[0m13:07:53.997764 [info ] [Thread-1 (]: 28 of 35 START test test_dim_weather_unique_key ................................ [RUN]
[0m13:07:53.998336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_dim_seller_unique_key, now test.ebay_weather_analytics.test_dim_weather_unique_key)
[0m13:07:53.998642 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_dim_weather_unique_key
[0m13:07:54.000828 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_dim_weather_unique_key"
[0m13:07:54.001980 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_dim_weather_unique_key
[0m13:07:54.003875 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_dim_weather_unique_key`
[0m13:07:54.004794 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_weather_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_weather_unique_key"} */

            

    
        create table `default_dbt_test__audit`.`test_dim_weather_unique_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Dimension Weather - Unique Weather Keys
-- Ensures each weather_key appears only once
SELECT weather_key
FROM `default`.`dim_weather`
GROUP BY weather_key
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m13:07:54.065267 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:54.071041 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_weather_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_weather_unique_key"} */

    select name, type from system.columns where table = 'test_dim_weather_unique_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:54.118598 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.121350 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_weather_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_weather_unique_key"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_dim_weather_unique_key`
        ("weather_key")
    
  -- Test: Dimension Weather - Unique Weather Keys
-- Ensures each weather_key appears only once
SELECT weather_key
FROM `default`.`dim_weather`
GROUP BY weather_key
HAVING COUNT(*) > 1
  
  
  
    ...
[0m13:07:54.174193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.176393 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_dim_weather_unique_key"
[0m13:07:54.178618 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_dim_weather_unique_key: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_dim_weather_unique_key"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_dim_weather_unique_key`
    
    ) dbt_internal_test...
[0m13:07:54.229047 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.233625 [info ] [Thread-1 (]: 28 of 35 PASS test_dim_weather_unique_key ...................................... [[32mPASS[0m in 0.24s]
[0m13:07:54.234695 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_dim_weather_unique_key
[0m13:07:54.235119 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_fact_listings_not_null
[0m13:07:54.235792 [info ] [Thread-1 (]: 29 of 35 START test test_fact_listings_not_null ................................ [RUN]
[0m13:07:54.236639 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_dim_weather_unique_key, now test.ebay_weather_analytics.test_fact_listings_not_null)
[0m13:07:54.236986 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_fact_listings_not_null
[0m13:07:54.240011 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_fact_listings_not_null"
[0m13:07:54.241214 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_fact_listings_not_null
[0m13:07:54.246589 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */
drop table if exists `default_dbt_test__audit`.`test_fact_listings_not_null` 
  ...
[0m13:07:54.292669 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.295133 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_fact_listings_not_null`
[0m13:07:54.297983 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_not_null: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

            

    
        create table `default_dbt_test__audit`.`test_fact_listings_not_null`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Fact Listings - Not Null Critical Fields
-- Ensures critical fields are not null
SELECT *
FROM `default`.`fact_listings`
WHERE item_id IS NULL
   OR collection_timestamp IS NULL
   OR price IS NULL
   OR product_type IS NULL
   OR weather_category IS NULL
  
  
          )
        
        ...
[0m13:07:54.348665 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_not_null"} */

            

    
        create table `default_dbt_test__audit`.`test_fact_listings_not_null`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Fact Listings - Not Null Critical Fields
-- Ensures critical fields are not null
SELECT *
FROM `default`.`fact_listings`
WHERE item_id IS NULL
   OR collection_timestamp IS NULL
   OR price IS NULL
   OR product_type IS NULL
   OR weather_category IS NULL
  
  
          )
        
        
[0m13:07:54.367581 [debug] [Thread-1 (]: Database Error in test test_fact_listings_not_null (tests\test_fact_listings_not_null.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `product_type` in scope SELECT * FROM default.fact_listings WHERE (item_id IS NULL) OR (collection_timestamp IS NULL) OR (price IS NULL) OR (product_type IS NULL) OR (weather_category IS NULL). Maybe you meant: ['product_key']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  10. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  11. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d283
  12. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  13. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  14. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  15. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  16. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  17. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  18. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  19. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  20. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  21. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  22. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  23. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  24. DB::TCPHandler::run() @ 0x0000000019e4f119
  25. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  26. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  27. Poco::PooledThread::run() @ 0x000000001ef15b87
  28. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  29. ? @ 0x0000000000094ac3
  30. ? @ 0x0000000000125a74
[0m13:07:54.368300 [error] [Thread-1 (]: 29 of 35 ERROR test_fact_listings_not_null ..................................... [[31mERROR[0m in 0.13s]
[0m13:07:54.369540 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_fact_listings_not_null
[0m13:07:54.370050 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m13:07:54.370929 [debug] [Thread-4 (]: Marking all children of 'test.ebay_weather_analytics.test_fact_listings_not_null' to be skipped because of status 'error'.  Reason: Database Error in test test_fact_listings_not_null (tests\test_fact_listings_not_null.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `product_type` in scope SELECT * FROM default.fact_listings WHERE (item_id IS NULL) OR (collection_timestamp IS NULL) OR (price IS NULL) OR (product_type IS NULL) OR (weather_category IS NULL). Maybe you meant: ['product_key']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  10. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  11. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d283
  12. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  13. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  14. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  15. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  16. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  17. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  18. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  19. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  20. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  21. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  22. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  23. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  24. DB::TCPHandler::run() @ 0x0000000019e4f119
  25. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  26. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  27. Poco::PooledThread::run() @ 0x000000001ef15b87
  28. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  29. ? @ 0x0000000000094ac3
  30. ? @ 0x0000000000125a74.
[0m13:07:54.371893 [info ] [Thread-1 (]: 30 of 35 START test test_fact_listings_unique_item_id .......................... [RUN]
[0m13:07:54.373670 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_fact_listings_not_null, now test.ebay_weather_analytics.test_fact_listings_unique_item_id)
[0m13:07:54.374110 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m13:07:54.377523 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.test_fact_listings_unique_item_id"
[0m13:07:54.378933 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m13:07:54.382330 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */
drop table if exists `default_dbt_test__audit`.`test_fact_listings_unique_item_id` 
  ...
[0m13:07:54.452265 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m13:07:54.453529 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
[0m13:07:54.455109 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

            

    
        create table `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  -- Test: Fact Listings - Unique Item IDs
-- Ensures each item_id appears only once in the fact table
SELECT item_id
FROM `default`.`fact_listings`
GROUP BY item_id
HAVING COUNT(*) > 1
  
  
          )
        
        ...
[0m13:07:54.512696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:54.518301 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

    select name, type from system.columns where table = 'test_fact_listings_unique_item_id'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:54.567469 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.570095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
        ("item_id")
    
  -- Test: Fact Listings - Unique Item IDs
-- Ensures each item_id appears only once in the fact table
SELECT item_id
FROM `default`.`fact_listings`
GROUP BY item_id
HAVING COUNT(*) > 1
  
  
  
    ...
[0m13:07:54.625034 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.627496 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.test_fact_listings_unique_item_id"
[0m13:07:54.629039 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.test_fact_listings_unique_item_id: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.test_fact_listings_unique_item_id"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
    
    ) dbt_internal_test...
[0m13:07:54.682502 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.684944 [error] [Thread-1 (]: 30 of 35 FAIL 113 test_fact_listings_unique_item_id ............................ [[31mFAIL 113[0m in 0.31s]
[0m13:07:54.686672 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.test_fact_listings_unique_item_id
[0m13:07:54.687424 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6
[0m13:07:54.688128 [info ] [Thread-1 (]: 31 of 35 START test unique_dim_location_location_key ........................... [RUN]
[0m13:07:54.688978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.test_fact_listings_unique_item_id, now test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6)
[0m13:07:54.689461 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6
[0m13:07:54.697081 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"
[0m13:07:54.698342 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6
[0m13:07:54.699856 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_dim_location_location_key`
[0m13:07:54.701597 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"} */

            

    
        create table `default_dbt_test__audit`.`unique_dim_location_location_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    location_key as unique_field,
    count(*) as n_records

from `default`.`dim_location`
where location_key is not null
group by location_key
having count(*) > 1



  
  
          )
        
        ...
[0m13:07:54.762464 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:54.767893 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"} */

    select name, type from system.columns where table = 'unique_dim_location_location_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:54.814375 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.816488 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_dim_location_location_key`
        ("unique_field", "n_records")
    
  
    
    

select
    location_key as unique_field,
    count(*) as n_records

from `default`.`dim_location`
where location_key is not null
group by location_key
having count(*) > 1



  
  
  
    ...
[0m13:07:54.865371 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.867329 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"
[0m13:07:54.869427 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_dim_location_location_key`
    
    ) dbt_internal_test...
[0m13:07:54.919189 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:54.921300 [info ] [Thread-1 (]: 31 of 35 PASS unique_dim_location_location_key ................................. [[32mPASS[0m in 0.23s]
[0m13:07:54.922374 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6
[0m13:07:54.922915 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0
[0m13:07:54.923510 [info ] [Thread-1 (]: 32 of 35 START test unique_dim_product_product_key ............................. [RUN]
[0m13:07:54.924406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.unique_dim_location_location_key.b5757d64b6, now test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0)
[0m13:07:54.924855 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0
[0m13:07:54.929989 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"
[0m13:07:54.931437 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0
[0m13:07:54.933589 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_dim_product_product_key`
[0m13:07:54.935454 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"} */

            

    
        create table `default_dbt_test__audit`.`unique_dim_product_product_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    product_key as unique_field,
    count(*) as n_records

from `default`.`dim_product`
where product_key is not null
group by product_key
having count(*) > 1



  
  
          )
        
        ...
[0m13:07:54.992636 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:54.997651 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"} */

    select name, type from system.columns where table = 'unique_dim_product_product_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:55.045815 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.047694 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_dim_product_product_key`
        ("unique_field", "n_records")
    
  
    
    

select
    product_key as unique_field,
    count(*) as n_records

from `default`.`dim_product`
where product_key is not null
group by product_key
having count(*) > 1



  
  
  
    ...
[0m13:07:55.099526 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.101320 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"
[0m13:07:55.102822 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_dim_product_product_key`
    
    ) dbt_internal_test...
[0m13:07:55.151567 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.153230 [info ] [Thread-1 (]: 32 of 35 PASS unique_dim_product_product_key ................................... [[32mPASS[0m in 0.23s]
[0m13:07:55.153955 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0
[0m13:07:55.154295 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7
[0m13:07:55.154669 [info ] [Thread-1 (]: 33 of 35 START test unique_dim_seller_seller_key ............................... [RUN]
[0m13:07:55.155188 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.unique_dim_product_product_key.1753236bd0, now test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7)
[0m13:07:55.155568 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7
[0m13:07:55.160563 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"
[0m13:07:55.162330 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7
[0m13:07:55.165610 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_dim_seller_seller_key`
[0m13:07:55.166968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"} */

            

    
        create table `default_dbt_test__audit`.`unique_dim_seller_seller_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    seller_key as unique_field,
    count(*) as n_records

from `default`.`dim_seller`
where seller_key is not null
group by seller_key
having count(*) > 1



  
  
          )
        
        ...
[0m13:07:55.220901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.226831 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"} */

    select name, type from system.columns where table = 'unique_dim_seller_seller_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:55.274677 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.278204 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_dim_seller_seller_key`
        ("unique_field", "n_records")
    
  
    
    

select
    seller_key as unique_field,
    count(*) as n_records

from `default`.`dim_seller`
where seller_key is not null
group by seller_key
having count(*) > 1



  
  
  
    ...
[0m13:07:55.329402 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.331143 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"
[0m13:07:55.332521 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_dim_seller_seller_key`
    
    ) dbt_internal_test...
[0m13:07:55.390283 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:55.394019 [info ] [Thread-1 (]: 33 of 35 PASS unique_dim_seller_seller_key ..................................... [[32mPASS[0m in 0.24s]
[0m13:07:55.395541 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7
[0m13:07:55.396206 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43
[0m13:07:55.396720 [info ] [Thread-1 (]: 34 of 35 START test unique_dim_weather_date .................................... [RUN]
[0m13:07:55.397513 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.unique_dim_seller_seller_key.4caf4ed3c7, now test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43)
[0m13:07:55.398445 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43
[0m13:07:55.403292 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"
[0m13:07:55.404449 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43
[0m13:07:55.406209 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_dim_weather_date`
[0m13:07:55.407858 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"} */

            

    
        create table `default_dbt_test__audit`.`unique_dim_weather_date`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    date as unique_field,
    count(*) as n_records

from `default`.`dim_weather`
where date is not null
group by date
having count(*) > 1



  
  
          )
        
        ...
[0m13:07:55.474044 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.07 seconds
[0m13:07:55.482442 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"} */

    select name, type from system.columns where table = 'unique_dim_weather_date'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:55.530706 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.534505 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_dim_weather_date`
        ("unique_field", "n_records")
    
  
    
    

select
    date as unique_field,
    count(*) as n_records

from `default`.`dim_weather`
where date is not null
group by date
having count(*) > 1



  
  
  
    ...
[0m13:07:55.584728 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.587078 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"
[0m13:07:55.590199 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_dim_weather_date`
    
    ) dbt_internal_test...
[0m13:07:55.641073 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.645451 [info ] [Thread-1 (]: 34 of 35 PASS unique_dim_weather_date .......................................... [[32mPASS[0m in 0.25s]
[0m13:07:55.647134 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43
[0m13:07:55.648020 [debug] [Thread-1 (]: Began running node test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c
[0m13:07:55.648994 [info ] [Thread-1 (]: 35 of 35 START test unique_dim_weather_weather_key ............................. [RUN]
[0m13:07:55.650148 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.ebay_weather_analytics.unique_dim_weather_date.4d82e80e43, now test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c)
[0m13:07:55.650868 [debug] [Thread-1 (]: Began compiling node test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c
[0m13:07:55.655072 [debug] [Thread-1 (]: Writing injected SQL for node "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"
[0m13:07:55.658286 [debug] [Thread-1 (]: Began executing node test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c
[0m13:07:55.663850 [debug] [Thread-1 (]: Applying CREATE to: `default_dbt_test__audit`.`unique_dim_weather_weather_key`
[0m13:07:55.667569 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"} */

            

    
        create table `default_dbt_test__audit`.`unique_dim_weather_weather_key`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    
                    
            empty
          as (
            
    
  
    
    

select
    weather_key as unique_field,
    count(*) as n_records

from `default`.`dim_weather`
where weather_key is not null
group by weather_key
having count(*) > 1



  
  
          )
        
        ...
[0m13:07:55.728479 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:55.734106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"} */

    select name, type from system.columns where table = 'unique_dim_weather_weather_key'
    
      
        and database = 'default_dbt_test__audit'
      
    
    order by position
  ...
[0m13:07:55.786009 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.788346 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"} */

        
  
    
    
    
        
         


        insert into `default_dbt_test__audit`.`unique_dim_weather_weather_key`
        ("unique_field", "n_records")
    
  
    
    

select
    weather_key as unique_field,
    count(*) as n_records

from `default`.`dim_weather`
where weather_key is not null
group by weather_key
having count(*) > 1



  
  
  
    ...
[0m13:07:55.845165 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m13:07:55.847635 [debug] [Thread-1 (]: Writing runtime sql for node "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"
[0m13:07:55.849368 [debug] [Thread-1 (]: dbt_clickhouse adapter: On test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "clickhouse_profile", "target_name": "dev", "node_id": "test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c"} */

    
    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
        select *
        from `default_dbt_test__audit`.`unique_dim_weather_weather_key`
    
    ) dbt_internal_test...
[0m13:07:55.901239 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m13:07:55.902891 [info ] [Thread-1 (]: 35 of 35 PASS unique_dim_weather_weather_key ................................... [[32mPASS[0m in 0.25s]
[0m13:07:55.904106 [debug] [Thread-1 (]: Finished running node test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c
[0m13:07:55.906621 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:07:55.908043 [debug] [MainThread]: Connection 'list_' was left open.
[0m13:07:55.909086 [debug] [MainThread]: On list_: Close
[0m13:07:55.909962 [debug] [MainThread]: Connection 'list__default' was left open.
[0m13:07:55.910643 [debug] [MainThread]: On list__default: Close
[0m13:07:55.911718 [debug] [MainThread]: Connection 'test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c' was left open.
[0m13:07:55.912431 [debug] [MainThread]: On test.ebay_weather_analytics.unique_dim_weather_weather_key.74dbf3874c: Close
[0m13:07:55.913667 [info ] [MainThread]: 
[0m13:07:55.914732 [info ] [MainThread]: Finished running 35 data tests in 0 hours 0 minutes and 10.83 seconds (10.83s).
[0m13:07:55.920377 [debug] [MainThread]: Command end result
[0m13:07:55.954089 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\manifest.json
[0m13:07:55.956857 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\semantic_manifest.json
[0m13:07:55.965501 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ayeshaateeq\Desktop\Masters\Semester-1\DE\project\data_eng_2025_group2\clickhouse_setup\dbt\target\run_results.json
[0m13:07:55.966078 [info ] [MainThread]: 
[0m13:07:55.966682 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m13:07:55.967022 [info ] [MainThread]: 
[0m13:07:55.967386 [error] [MainThread]: [31mFailure in test test_fact_listings_not_null (tests\test_fact_listings_not_null.sql)[0m
[0m13:07:55.967888 [error] [MainThread]:   Database Error in test test_fact_listings_not_null (tests\test_fact_listings_not_null.sql)
  Code: 47.
  DB::Exception: Unknown expression or function identifier `product_type` in scope SELECT * FROM default.fact_listings WHERE (item_id IS NULL) OR (collection_timestamp IS NULL) OR (price IS NULL) OR (product_type IS NULL) OR (weather_category IS NULL). Maybe you meant: ['product_key']. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
  1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
  2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
  3. DB::Exception::Exception<char const*, String&, String, String, String>(int, FormatStringHelperImpl<std::type_identity<char const*>::type, std::type_identity<String&>::type, std::type_identity<String>::type, std::type_identity<String>::type, std::type_identity<String>::type>, char const*&&, String&, String&&, String&&, String&&) @ 0x0000000017859102
  4. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178395e5
  5. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  6. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  7. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  8. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000178366c0
  9. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x0000000017aa66c7
  10. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000178372f3
  11. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d283
  12. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
  13. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
  14. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
  15. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
  16. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
  17. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
  18. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
  19. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
  20. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
  21. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
  22. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
  23. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
  24. DB::TCPHandler::run() @ 0x0000000019e4f119
  25. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
  26. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
  27. Poco::PooledThread::run() @ 0x000000001ef15b87
  28. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
  29. ? @ 0x0000000000094ac3
  30. ? @ 0x0000000000125a74
[0m13:07:55.968543 [info ] [MainThread]: 
[0m13:07:55.968924 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\tests\test_fact_listings_not_null.sql
[0m13:07:55.969230 [info ] [MainThread]: 
[0m13:07:55.969584 [info ] [MainThread]:   See test failures:
  ---------------------------------------------------------------------
  select * from `default_dbt_test__audit`.`test_fact_listings_not_null`
  ---------------------------------------------------------------------
[0m13:07:55.969855 [info ] [MainThread]: 
[0m13:07:55.970191 [error] [MainThread]: [31mFailure in test test_fact_listings_unique_item_id (tests\test_fact_listings_unique_item_id.sql)[0m
[0m13:07:55.970498 [error] [MainThread]:   Got 113 results, configured to fail if != 0
[0m13:07:55.971003 [info ] [MainThread]: 
[0m13:07:55.971408 [info ] [MainThread]:   compiled code at target\compiled\ebay_weather_analytics\tests\test_fact_listings_unique_item_id.sql
[0m13:07:55.971870 [info ] [MainThread]: 
[0m13:07:55.972512 [info ] [MainThread]:   See test failures:
  ---------------------------------------------------------------------------
  select * from `default_dbt_test__audit`.`test_fact_listings_unique_item_id`
  ---------------------------------------------------------------------------
[0m13:07:55.973072 [info ] [MainThread]: 
[0m13:07:55.973450 [info ] [MainThread]: Done. PASS=33 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=35
[0m13:07:55.974340 [debug] [MainThread]: Command `dbt test` failed at 13:07:55.974212 after 11.99 seconds
[0m13:07:55.974639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A434F26BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4378F35F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A4378F1440>]}
[0m13:07:55.974883 [debug] [MainThread]: Flushing usage events
[0m13:07:56.781911 [debug] [MainThread]: An error was encountered while trying to flush usage events
